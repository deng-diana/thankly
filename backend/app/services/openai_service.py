"""
AI æœåŠ¡ - æ··åˆæ¨¡å‹ä¼˜åŒ–ç‰ˆæœ¬
ä½œè€…çµæ„Ÿæ¥æºï¼šä¹”å¸ƒæ–¯çš„ç®€çº¦å“²å­¦ + å¼ å°é¾™çš„å…‹åˆ¶è®¾è®¡

ğŸ”¥ æœ€æ–°æ›´æ–°ï¼š
1. AI æš–å¿ƒåé¦ˆä» Claude Sonnet å›å½’ OpenAI GPT-4o-miniï¼ˆTestFlight éªŒè¯ç¨³å®šç‰ˆï¼‰
2. æ¶¦è‰² + æ ‡é¢˜ä¸åé¦ˆç»Ÿä¸€ä½¿ç”¨ GPT-4o-miniï¼ˆé™ä½ç»´æŠ¤æˆæœ¬ï¼‰
3. å¹¶è¡Œæ‰§è¡Œç­–ç•¥ä¿æŒä¸å˜ï¼Œæ€§èƒ½ç»§ç»­ç¨³å®š
4. Whisper è¯­éŸ³è½¬æ–‡å­—æŒç»­æ²¿ç”¨ï¼Œä¿è¯è¯†åˆ«å‡†ç¡®åº¦

æ ¸å¿ƒç†å¿µï¼š
1. ç®€å•ä½†ä¸ç®€é™‹ï¼ˆSimple but not simplisticï¼‰
2. å¼ºå¤§ä½†ä¸å¤æ‚ï¼ˆPowerful but not complicatedï¼‰
3. ä¼˜é›…ä½†ä¸ç‚«æŠ€ï¼ˆElegant but not showyï¼‰
"""

import tempfile
import os
import json
import asyncio  # ğŸ”¥ ç”¨äºå¹¶è¡Œæ‰§è¡Œ
import re  # ç”¨äºæ–‡æœ¬å¤„ç†
import traceback  # ç”¨äºé”™è¯¯è¿½è¸ª
from typing import Dict, Optional, List, Any
from openai import OpenAI, AsyncOpenAI, APIError, RateLimitError, APIConnectionError
import io
import base64
import requests
import httpx  # âœ… ç»Ÿä¸€å¯¼å…¥ï¼Œç”¨äºå¼‚æ­¥ HTTP è¯·æ±‚

# âœ… Phase 1.4: æ·»åŠ é‡è¯•æœºåˆ¶
from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type,
    before_sleep_log,
)
import logging

# é…ç½®æ—¥å¿—ç”¨äºé‡è¯•
logger = logging.getLogger(__name__)

from ..config import get_settings


class OpenAIService:
    """
    AI æœåŠ¡ç±» - æ”¯æŒå¤šè¯­è¨€æ—¥è®°å¤„ç†
    
    è¿™ä¸ªç±»å°±åƒä¸€ä¸ªæ¸©æŸ”çš„æ—¥è®°åŠ©æ‰‹ï¼Œå®ƒä¼šï¼š
    1. å¬æ‡‚ä½ çš„å£°éŸ³ï¼ˆè¯­éŸ³è½¬æ–‡å­— - Whisperï¼‰
    2. ç¾åŒ–ä½ çš„æ–‡å­—ï¼ˆè½»åº¦æ¶¦è‰² - GPT-4o-miniï¼‰
    3. ç»™ä½ æ¸©æš–çš„å›åº”ï¼ˆå¿ƒç†é™ªä¼´ - GPT-4o-miniï¼‰
    4. å¸®ä½ èµ·ä¸ªå¥½æ ‡é¢˜ï¼ˆç”»é¾™ç‚¹ç› - GPT-4o-miniï¼‰
    
    ğŸ”¥ æ¨¡å‹é€‰æ‹©ç­–ç•¥ï¼š
    - Whisper: è¯­éŸ³è½¬æ–‡å­—ï¼ˆOpenAIï¼Œæ— å¯æ›¿ä»£ï¼‰
    - GPT-4o-mini: æ¶¦è‰² + æ ‡é¢˜ï¼ˆå¿«é€Ÿã€ç¨³å®šã€æˆæœ¬å¯æ§ï¼‰
    - GPT-4o-mini: AI åé¦ˆï¼ˆTestFlight å›å½’éªŒè¯æ›´ç¨³å®šï¼‰
    """
    
    # ğŸ¯ æ¨¡å‹é…ç½® - OpenAI Models Only
    MODEL_CONFIG = {
        # è¯­éŸ³è½¬æ–‡å­—
        "transcription": "whisper-1",
        
        # ğŸ”¥ GPT æ¨¡å‹é…ç½® - é€Ÿåº¦ä¸è´¨é‡å¹³è¡¡
        "polish": "gpt-4o",              # æ¶¦è‰² + æ ‡é¢˜: è´¨é‡ä¼˜å…ˆï¼ˆç”¨æˆ·ç›´æ¥æ„Ÿå—ï¼‰
        "emotion": "gpt-4o-mini",        # æƒ…ç»ªåˆ†æ: é€Ÿåº¦ä¼˜å…ˆï¼ˆ3x faster, å‡†ç¡®åº¦85%â†’90%ï¼‰
        "feedback": "gpt-4o",       # æ¸©æš–åé¦ˆ: é€Ÿåº¦ä¼˜å…ˆï¼ˆ2x faster, æ¸©æš–åº¦è¶³å¤Ÿï¼‰
        
        # ğŸ¤ ä¸ºä»€ä¹ˆ Whisperï¼Ÿ
        # âœ… OpenAI å®˜æ–¹è¯­éŸ³è½¬æ–‡å­—æ¨¡å‹
        # âœ… æ”¯æŒ 100+ è¯­è¨€ï¼ˆä¸­è‹±æ–‡å®Œç¾ï¼‰
        # âœ… é«˜å‡†ç¡®åº¦ï¼Œä½å¹»è§‰ç‡
        
        # ğŸ¨ ä¸ºä»€ä¹ˆ Polish ç”¨ gpt-4oï¼Ÿï¼ˆä¿æŒé«˜è´¨é‡ï¼‰
        # âœ… è¯­è¨€è´¨é‡æå‡ 3-5 å€ - è¾¾åˆ°æ¯è¯­æ°´å¹³
        # âœ… å®Œç¾å¤„ç†è¯­æ°”è¯å’Œåœé¡¿ - é€‚åˆè¯­è¨€å­¦ä¹ 
        # âœ… ç»†èŠ‚æ‰“ç£¨ç²¾è‡´ - å£è¯­è½¬ä¹¦é¢è¯­èƒ½åŠ›å¼º
        # âœ… æ•™å­¦çº§åˆ«è¾“å‡º - ç”¨æˆ·å¯é€šè¿‡å¯¹æ¯”å­¦ä¹ è‹±è¯­
        # âœ… ç”¨æˆ·ä½“éªŒä¼˜å…ˆ - æ¶¦è‰²æ˜¯æœ€ç›´æ¥çš„æ„Ÿå—
        
        # ğŸ¯ ä¸ºä»€ä¹ˆ Emotion ç”¨ gpt-4o-miniï¼Ÿï¼ˆé€Ÿåº¦ä¸è´¨é‡å¹³è¡¡ï¼‰
        # âœ… é€Ÿåº¦å¿« 3 å€ (2.5s â†’ 0.8s)
        # âœ… æˆæœ¬é™ä½ 15 å€
        # âœ… 24ç§æƒ…ç»ªä¸­ï¼Œ80%æ˜¯æ˜æ˜¾çš„ï¼ˆ"å¼€å¿ƒ"ã€"éš¾è¿‡"ï¼‰
        # âœ… å‡†ç¡®åº¦ä¾ç„¶å¾ˆé«˜ï¼ˆ85-90%ï¼‰
        # âœ… é…åˆä¼˜åŒ–çš„æç¤ºè¯ï¼ˆFew-Shotï¼‰ï¼Œå‡†ç¡®åº¦å¯è¾¾90%
        
        # ğŸ’¬ ä¸ºä»€ä¹ˆ Feedback ç”¨ gpt-4o-miniï¼Ÿï¼ˆé€Ÿåº¦ä¼˜å…ˆï¼‰
        # âœ… é€Ÿåº¦å¿« 2 å€ (2.5s â†’ 1.2s)
        # âœ… åˆ›æ„è¡¨è¾¾å¥½ - æ›´è‡ªç„¶çš„è¯­è¨€
        # âœ… ä¸ªæ€§åŒ–å¼º - åŸºäºæƒ…ç»ªçš„ç²¾å‡†åé¦ˆ
        # âœ… ç”¨æˆ·æœ€å…³æ³¨ï¼Œä½“éªŒä¼˜å…ˆ
    }
    
    # ğŸ“ é•¿åº¦é™åˆ¶ï¼ˆä¿æŒä¸å˜ï¼‰
    LENGTH_LIMITS = {
        "title_min": 4,
        "title_max": 50,
        "feedback_min": 30,
        "feedback_max": 250,
        "polished_ratio": 1.15,
        "min_audio_text": 5,
    }
    
    def __init__(self):
        """åˆå§‹åŒ–æœåŠ¡å®¢æˆ·ç«¯"""
        settings = get_settings()
        
        # OpenAI å®¢æˆ·ç«¯ï¼ˆç”¨äº Whisper å’ŒåŒæ­¥è°ƒç”¨çš„å…¼å®¹ï¼‰
        self.openai_client = OpenAI(api_key=settings.openai_api_key)
        # âœ… Phase 1.1: æ·»åŠ  AsyncOpenAI å®¢æˆ·ç«¯ï¼ˆç”¨äºå¼‚æ­¥è°ƒç”¨ï¼Œæå‡æ€§èƒ½ï¼‰
        self.async_client = AsyncOpenAI(api_key=settings.openai_api_key)
        self.openai_api_key = settings.openai_api_key
        
        print(f"âœ… AI æœåŠ¡åˆå§‹åŒ–å®Œæˆï¼ˆå·²å¯ç”¨ AsyncOpenAI + é‡è¯•æœºåˆ¶ï¼‰")
        print(f"   - Whisper: è¯­éŸ³è½¬æ–‡å­—")
        print(f"   - gpt-4o: æ¶¦è‰² + æ ‡é¢˜ (polish) - æ•™å­¦çº§åˆ«")
        print(f"   - gpt-4o: æƒ…ç»ªåˆ†æ (emotion) - å¼‚æ­¥ä¼˜åŒ–")
        print(f"   - gpt-4o: AI åé¦ˆ (feedback) - å¼‚æ­¥ä¼˜åŒ–")
    
    # ========================================================================
    # âœ… Phase 1.4: å¸¦é‡è¯•çš„ GPT-4o è°ƒç”¨è¾…åŠ©æ–¹æ³•
    # ========================================================================
    
    @retry(
        stop=stop_after_attempt(3),  # æœ€å¤šé‡è¯• 3 æ¬¡
        wait=wait_exponential(multiplier=1, min=1, max=10),  # æŒ‡æ•°é€€é¿ï¼š1s, 2s, 4s...
        # âœ… Review ä¼˜åŒ–ï¼šåªé‡è¯•ç½‘ç»œå’Œ API ç›¸å…³å¼‚å¸¸ï¼Œé¿å…é‡è¯•é€»è¾‘é”™è¯¯
        retry=retry_if_exception_type((APIError, RateLimitError, APIConnectionError, httpx.RequestError)),
        before_sleep=before_sleep_log(logger, logging.WARNING),  # é‡è¯•å‰è®°å½•æ—¥å¿—
        reraise=True  # æœ€ç»ˆå¤±è´¥æ—¶é‡æ–°æŠ›å‡ºå¼‚å¸¸
    )
    async def _call_gpt4o_with_retry(
        self,
        model: str,
        messages: list,
        temperature: float = 0.3,
        max_tokens: int = 2000,
        response_format: dict = None
    ):
        """
        å¸¦é‡è¯•çš„ GPT-4o è°ƒç”¨
        
        ğŸ”¥ Phase 1.4: æ·»åŠ æŒ‡æ•°é€€é¿é‡è¯•æœºåˆ¶
        - æœ€å¤šé‡è¯• 3 æ¬¡
        - æŒ‡æ•°é€€é¿ï¼š1s â†’ 2s â†’ 4s
        - è®°å½•é‡è¯•æ—¥å¿—
        
        å¸¸è§å¯é‡è¯•é”™è¯¯ï¼š
        - ç½‘ç»œè¶…æ—¶
        - API é™æµ (429)
        - æœåŠ¡å™¨é”™è¯¯ (5xx)
        """
        try:
            if response_format:
                response = await self.async_client.chat.completions.create(
                    model=model,
                    messages=messages,
                    temperature=temperature,
                    max_tokens=max_tokens,
                    response_format=response_format
                )
            else:
                response = await self.async_client.chat.completions.create(
                    model=model,
                    messages=messages,
                    temperature=temperature,
                    max_tokens=max_tokens
                )
            return response
        except Exception as e:
            print(f"âš ï¸ GPT-4o è°ƒç”¨å¤±è´¥ï¼Œå°†é‡è¯•: {type(e).__name__}: {str(e)}")
            raise  # é‡æ–°æŠ›å‡ºï¼Œè®© tenacity å¤„ç†é‡è¯•
    
    # ========================================================================
    # è¯­éŸ³è½¬æ–‡å­—ï¼ˆä¿æŒä¸å˜ï¼‰
    # ========================================================================
    
    async def transcribe_audio(
        self, 
        audio_content: bytes, 
        filename: str,
        expected_duration: Optional[int] = None
    ) -> str:
        """
        è¯­éŸ³è½¬æ–‡å­— - æŠŠä½ çš„å£°éŸ³å˜æˆæ–‡å­—
        
        ğŸ”¥ æ³¨æ„ï¼šè¿™ä¸ªæ–¹æ³•å®Œå…¨ä¸å˜ï¼Œç»§ç»­ä½¿ç”¨ Whisper
        
        å·¥ä½œæµç¨‹ï¼š
        1. æ”¶åˆ°éŸ³é¢‘ â†’ æ£€æŸ¥å¤§å°
        2. åˆ›å»ºä¸´æ—¶æ–‡ä»¶ â†’ ç¡®ä¿æ ¼å¼æ­£ç¡®
        3. å‘é€ç»™ Whisper â†’ å®ƒæ˜¯è¯­éŸ³è¯†åˆ«ä¸“å®¶
        4. æ£€æŸ¥ç»“æœ â†’ ç¡®ä¿ä¸æ˜¯ç©ºçš„
        5. æ¸…ç†ä¸´æ—¶æ–‡ä»¶ â†’ ä¿æŒæ•´æ´
        """
        temp_file_path = None
        
        try:
            # æ£€æŸ¥éŸ³é¢‘å¤§å°
            audio_size_kb = len(audio_content) / 1024
            print(f"ğŸ¤ æ”¶åˆ°éŸ³é¢‘: {filename}, å¤§å°: {audio_size_kb:.1f} KB")
            
            if audio_size_kb < 1:
                raise ValueError("éŸ³é¢‘æ–‡ä»¶å¤ªå°ï¼Œè¯·è¯´é•¿ä¸€ç‚¹")
            
            # å‡†å¤‡ä¸´æ—¶æ–‡ä»¶
            suffix = '.m4a' if not filename.endswith('.m4a') else ''
            with tempfile.NamedTemporaryFile(
                delete=False, 
                suffix=suffix or os.path.splitext(filename)[1]
            ) as temp_file:
                temp_file.write(audio_content)
                temp_file_path = temp_file.name
            
            print(f"âœ… ä¸´æ—¶æ–‡ä»¶å‡†å¤‡å®Œæˆ")
            
            # âœ… Phase 1.1: ä½¿ç”¨ httpx.AsyncClient å¼‚æ­¥è°ƒç”¨ Whisperï¼ˆæå‡æ€§èƒ½ï¼‰
            print("ğŸ“¤ æ­£åœ¨è¯†åˆ«è¯­éŸ³ï¼ˆverbose_json æ¨¡å¼ - å¼‚æ­¥ï¼‰...")
            response_json = None
            try:
                async with httpx.AsyncClient(timeout=60.0) as client:
                    file_stream = io.BytesIO(audio_content)
                    response = await client.post(
                        "https://api.openai.com/v1/audio/transcriptions",
                        headers={
                            "Authorization": f"Bearer {self.openai_api_key}",
                        },
                        data={
                            "model": self.MODEL_CONFIG["transcription"],
                            "language": "",
                            "temperature": "0",
                            "response_format": "verbose_json",
                        },
                        files={
                            "file": (filename or "recording.m4a", file_stream, "audio/m4a"),
                        },
                    )
                    response.raise_for_status()
                    response_json = response.json()
            except httpx.HTTPError as http_err:
                print(f"âŒ Whisper HTTP è¯·æ±‚å¤±è´¥: {http_err}")
                if http_err.response is not None:
                    print(f"ğŸ“„ Whisper å“åº”: {http_err.response.text[:200]}...")
                raise ValueError("è¯­éŸ³è¯†åˆ«å¤±è´¥: æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•")
            
            if not response_json:
                raise ValueError("è¯­éŸ³è¯†åˆ«å¤±è´¥: æœªæ”¶åˆ°æœ‰æ•ˆå“åº”")
            
            text = (response_json.get("text") or "").strip()
            segments = response_json.get("segments", []) or []
            detected_language = response_json.get("language", "").lower()  # âœ… è·å–æ£€æµ‹åˆ°çš„è¯­è¨€
            
            # ğŸ”¥ æ–°å¢ï¼šè¯­è¨€ç™½åå•æ£€æŸ¥ - é˜²æ­¢èƒŒæ™¯éŸ³ä¹è¢«è¯¯è¯†åˆ«ä¸ºéŸ©è¯­/æ—¥è¯­ç­‰
            SUPPORTED_LANGUAGES = {"zh", "en", "chinese", "english"}
            if detected_language and detected_language not in SUPPORTED_LANGUAGES:
                print(f"âŒ æ£€æµ‹åˆ°ä¸æ”¯æŒçš„è¯­è¨€: '{detected_language}'")
                print(f"   è¯†åˆ«æ–‡æœ¬: '{text[:100]}'")
                print(f"   è¿™å¯èƒ½æ˜¯èƒŒæ™¯éŸ³ä¹æˆ–å™ªéŸ³è¢«è¯¯è¯†åˆ«")
                raise ValueError("æœªè¯†åˆ«åˆ°æœ‰æ•ˆå†…å®¹ï¼Œè¯·ç”¨ä¸­æ–‡æˆ–è‹±æ–‡è¯´è¯")
            
            # ğŸ”¥ æ–°å¢ï¼šæ£€æµ‹éŸ©è¯­/æ—¥è¯­å­—ç¬¦ - åŒé‡ä¿é™©
            korean_chars = len(re.findall(r'[\uac00-\ud7af]', text))  # éŸ©è¯­å­—ç¬¦
            japanese_chars = len(re.findall(r'[\u3040-\u309f\u30a0-\u30ff]', text))  # æ—¥è¯­å­—ç¬¦
            if korean_chars > 3 or japanese_chars > 3:
                print(f"âŒ æ£€æµ‹åˆ°éŸ©è¯­/æ—¥è¯­å­—ç¬¦: éŸ©è¯­={korean_chars}, æ—¥è¯­={japanese_chars}")
                print(f"   è¯†åˆ«æ–‡æœ¬: '{text[:100]}'")
                print(f"   è¿™å¯èƒ½æ˜¯èƒŒæ™¯éŸ³ä¹æˆ–å™ªéŸ³è¢«è¯¯è¯†åˆ«")
                raise ValueError("æœªè¯†åˆ«åˆ°æœ‰æ•ˆå†…å®¹ï¼Œè¯·ç”¨ä¸­æ–‡æˆ–è‹±æ–‡è¯´è¯")
            
            # ğŸ”¥ æ–°å¢ï¼šæ£€æµ‹é‡å¤æ–‡æœ¬æ¨¡å¼ - Whisper å¹»è§‰çš„å¸¸è§ç‰¹å¾
            # ä¾‹å¦‚: "ë‹­ê°€ìŠ´ì‚´ ì¹˜í‚¨ì…ë‹ˆë‹¤. ë‹­ê°€ìŠ´ì‚´ ì¹˜í‚¨ê³¼ ë‹­ê°€ìŠ´ì‚´ ì¹˜í‚¨ì€..."
            words = text.split()
            if len(words) >= 5:
                # æ£€æŸ¥æ˜¯å¦æœ‰å¤§é‡é‡å¤çš„è¯
                word_counts = {}
                for word in words:
                    if len(word) >= 3:  # åªç»Ÿè®¡é•¿åº¦>=3çš„è¯
                        word_counts[word] = word_counts.get(word, 0) + 1
                
                # å¦‚æœæŸä¸ªè¯å‡ºç°æ¬¡æ•°è¶…è¿‡æ€»è¯æ•°çš„40%,å¯èƒ½æ˜¯å¹»è§‰
                max_repetition = max(word_counts.values()) if word_counts else 0
                repetition_ratio = max_repetition / len(words) if len(words) > 0 else 0
                
                if repetition_ratio > 0.4:
                    print(f"âŒ æ£€æµ‹åˆ°é«˜åº¦é‡å¤çš„æ–‡æœ¬æ¨¡å¼: é‡å¤ç‡={repetition_ratio:.1%}")
                    print(f"   è¯†åˆ«æ–‡æœ¬: '{text[:100]}'")
                    print(f"   è¿™å¯èƒ½æ˜¯èƒŒæ™¯éŸ³ä¹æˆ–å™ªéŸ³è¢«è¯¯è¯†åˆ«")
                    raise ValueError("æœªè¯†åˆ«åˆ°æœ‰æ•ˆå†…å®¹ï¼Œè¯·è¯´æ¸…æ¥šä¸€äº›")
            
            normalized_text = re.sub(r"\s+", "", text)
            
            if len(normalized_text) < self.LENGTH_LIMITS["min_audio_text"]:
                print(f"âŒ è½¬å½•å†…å®¹è¿‡çŸ­: '{text}'")
                raise ValueError("æœªè¯†åˆ«åˆ°æœ‰æ•ˆå†…å®¹ï¼Œè¯·è¯´æ¸…æ¥šä¸€äº›")
            
            filler_tokens = {
                "um",
                "uh",
                "uhh",
                "hmm",
                "hmmm",
                "erm",
                "er",
                "ah",
                "oh",
                "mmm",
            }
            token_pattern = r"[A-Za-z\u4e00-\u9fff\u3040-\u309f\u30a0-\u30ff]+"
            tokens = re.findall(token_pattern, text)
            meaningful_tokens = [
                token
                for token in tokens
                if len(token) >= 2 and token.lower() not in filler_tokens
            ]
            cjk_chars = re.findall(r"[\u4e00-\u9fff]", text)
            has_cjk = len(cjk_chars) > 0
            
            unique_chars = len(set(normalized_text))
            if unique_chars <= 2 and len(normalized_text) > 2:
                print(
                    "âŒ è½¬å½•ç»“æœåŒ…å«å¤§é‡é‡å¤å­—ç¬¦ï¼Œè§†ä¸ºæ— æ•ˆ:",
                    {"text": text, "normalized": normalized_text},
                )
                raise ValueError("æœªè¯†åˆ«åˆ°æœ‰æ•ˆå†…å®¹ï¼Œè¯·è¯´æ¸…æ¥šä¸€äº›")
            
            # åˆ†æ Whisper æ®µç»“æœï¼Œç¡®è®¤æ˜¯å¦çœŸçš„æœ‰è®²è¯
            def _segment_value(segment, attr, default):
                if isinstance(segment, dict):
                    return segment.get(attr, default)
                return getattr(segment, attr, default)
            
            confident_segments = []
            total_confident_duration = 0.0
            total_segment_duration = 0.0
            avg_no_speech_sum = 0.0
            
            for segment in segments:
                try:
                    start = float(_segment_value(segment, "start", 0))
                    end = float(_segment_value(segment, "end", 0))
                    seg_duration = max(0.0, end - start)
                except (TypeError, ValueError):
                    seg_duration = 0.0
                    start = 0.0
                    end = 0.0
                
                total_segment_duration += seg_duration
                
                try:
                    no_speech_prob = float(_segment_value(segment, "no_speech_prob", 1))
                except (TypeError, ValueError):
                    no_speech_prob = 1
                
                try:
                    avg_logprob = float(_segment_value(segment, "avg_logprob", -10))
                except (TypeError, ValueError):
                    avg_logprob = -10
                
                avg_no_speech_sum += no_speech_prob * seg_duration
                
                if (
                    seg_duration >= 0.3
                    and no_speech_prob < 0.45
                    and avg_logprob > -0.75
                ):
                    confident_segments.append(segment)
                    total_confident_duration += seg_duration
            
            reference_duration = None
            if expected_duration and expected_duration > 0:
                reference_duration = float(expected_duration)
            elif total_segment_duration > 0:
                reference_duration = total_segment_duration
            else:
                reference_duration = None
            
            speech_ratio = (
                total_confident_duration / reference_duration
                if reference_duration and reference_duration > 0
                else None
            )
            
            avg_no_speech_prob = (
                avg_no_speech_sum / total_segment_duration
                if total_segment_duration > 0
                else 1.0
            )
            
            if reference_duration and reference_duration >= 6:
                if (
                    len(normalized_text) < self.LENGTH_LIMITS["min_audio_text"]
                    and (speech_ratio is None or speech_ratio < 0.15)
                    and total_confident_duration < 0.6
                ):
                    print(
                        "âŒ æ£€æµ‹åˆ°æœ‰æ•ˆè¯­éŸ³è¿‡å°‘:",
                        {
                            "expected_duration": expected_duration,
                            "total_confident_duration": total_confident_duration,
                            "speech_ratio": speech_ratio,
                            "avg_no_speech_prob": avg_no_speech_prob,
                            "segments_count": len(segments),
                        },
                    )
                    raise ValueError("æœªè¯†åˆ«åˆ°æœ‰æ•ˆå†…å®¹ï¼Œè¯·è¯´æ¸…æ¥šä¸€äº›")
            
            # å¯¹é•¿å½•éŸ³ä¸å†ä½¿ç”¨å­—ç¬¦å¯†åº¦ç¡¬é˜ˆå€¼ï¼Œé¿å…è¯¯æ€çœŸå®å†…å®¹

            if reference_duration:
                if has_cjk:
                    # ä¸­æ–‡åœºæ™¯ï¼šç”¨æ±‰å­—æ•°é‡åˆ¤æ–­ï¼Œé¿å…â€œä¸€ä¸ªé•¿è¯â€è¢«è¯¯åˆ¤
                    if (
                        len(cjk_chars) < 3
                        and len(normalized_text) < self.LENGTH_LIMITS["min_audio_text"]
                    ):
                        print(
                            "âŒ ä¸­æ–‡æœ‰æ•ˆå­—ç¬¦è¿‡å°‘ï¼Œåˆ¤å®šä¸ºæ— æ„ä¹‰å†…å®¹:",
                            {
                                "cjk_chars": len(cjk_chars),
                                "duration": reference_duration,
                            },
                        )
                        raise ValueError("æœªè¯†åˆ«åˆ°æœ‰æ•ˆå†…å®¹ï¼Œè¯·ç¨ä½œè¡¨è¾¾åå†è¯•")
                else:
                    if (
                        len(meaningful_tokens) < 2
                        and len(normalized_text) < self.LENGTH_LIMITS["min_audio_text"] * 2
                    ):
                        print(
                            "âŒ æœ‰æ•ˆè¯æ±‡æ•°é‡ä¸è¶³ï¼Œåˆ¤å®šä¸ºæ— æ„ä¹‰å†…å®¹:",
                            {
                                "tokens": tokens,
                                "meaningful_tokens": meaningful_tokens,
                                "duration": reference_duration,
                            }
                        )
                        raise ValueError("æœªè¯†åˆ«åˆ°æœ‰æ•ˆå†…å®¹ï¼Œè¯·ç¨ä½œè¡¨è¾¾åå†è¯•")
            
            print(f"âœ… è¯­éŸ³è¯†åˆ«æˆåŠŸ: '{text[:50]}...'")
            print(f"ğŸŒ Whisper æ£€æµ‹åˆ°çš„è¯­è¨€: {detected_language}")
            
            # ğŸ”¥ è¿”å›å­—å…¸ï¼ŒåŒ…å«æ–‡æœ¬å’Œæ£€æµ‹åˆ°çš„è¯­è¨€
            return {
                "text": text,
                "detected_language": detected_language  # "en" æˆ– "zh" æˆ–å…¶ä»–è¯­è¨€ä»£ç 
            }
            
        except Exception as e:
            print(f"âŒ è¯­éŸ³è½¬æ–‡å­—å¤±è´¥: {str(e)}")
            if "Invalid file format" in str(e):
                raise ValueError("éŸ³é¢‘æ ¼å¼ä¸æ”¯æŒï¼Œè¯·ä½¿ç”¨ m4a æ ¼å¼")
            elif "File too large" in str(e):
                raise ValueError("éŸ³é¢‘æ–‡ä»¶å¤ªå¤§ï¼Œè¯·æ§åˆ¶åœ¨ 2 åˆ†é’Ÿå†…")
            else:
                raise ValueError(f"è¯­éŸ³è¯†åˆ«å¤±è´¥: {str(e)}")
        
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if temp_file_path and os.path.exists(temp_file_path):
                try:
                    os.unlink(temp_file_path)
                    print(f"ğŸ§¹ ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†")
                except Exception as e:
                    print(f"âš ï¸ æ¸…ç†å¤±è´¥ï¼ˆä¸å½±å“åŠŸèƒ½ï¼‰: {e}")
    
    # ========================================================================
    # ğŸ”¥ æ ¸å¿ƒæ”¹åŠ¨ï¼šæ··åˆæ¨¡å‹å¤„ç†
    # ========================================================================
    
    async def polish_content_multilingual(
        self, 
        text: str,
        user_name: Optional[str] = None,  # ç”¨æˆ·åå­—ï¼Œç”¨äºä¸ªæ€§åŒ–åé¦ˆ
        image_urls: Optional[List[str]] = None,  # å›¾ç‰‡URLåˆ—è¡¨ï¼Œç”¨äºvisionåˆ†æ
        whisper_detected_language: Optional[str] = None  # ğŸ”¥ Whisperæ£€æµ‹åˆ°çš„è¯­è¨€ ("en", "zh", etc.)
    ) -> Dict[str, Any]:
        """
        ğŸ”¥ é‡å¤§æ”¹åŠ¨ï¼šä»å•ä¸€æ¨¡å‹æ”¹ä¸ºæ··åˆæ¨¡å‹ + å¹¶è¡Œæ‰§è¡Œ
        
        æ—§é€»è¾‘ï¼š
        1. GPT-4o-mini ä¸€æ¬¡æ€§ç”Ÿæˆæ¶¦è‰² + æ ‡é¢˜ + åé¦ˆï¼ˆä¸²è¡Œï¼Œ3-5ç§’ï¼‰
        
        æ–°é€»è¾‘ï¼š
        1. gpt-4o-mini ç”Ÿæˆæ¶¦è‰² + æ ‡é¢˜ï¼ˆpolishï¼Œ1-2ç§’ï¼‰
        2. gpt-4o ç”Ÿæˆæƒ…ç»ªåˆ†æï¼ˆemotionï¼Œ2-3ç§’ï¼‰
        3. gpt-4o ç”Ÿæˆåé¦ˆï¼ˆfeedbackï¼ŒåŸºäºåŸå§‹æ–‡æœ¬ï¼Œ2-3ç§’ï¼‰
        3. ä¸¤ä¸ªä»»åŠ¡å¹¶è¡Œæ‰§è¡Œï¼Œæ€»è€—æ—¶ = max(1-2, 2-3) = 2-3ç§’
        
        ä¸ºä»€ä¹ˆåŸºäºåŸå§‹æ–‡æœ¬ç”Ÿæˆåé¦ˆï¼Ÿ
        - æ›´çœŸå®ï¼šåŸå§‹æ–‡æœ¬ä¿ç•™äº†ç”¨æˆ·æœ€çœŸå®çš„æƒ…æ„Ÿ
        - æ›´å¿«ï¼šä¸éœ€è¦ç­‰æ¶¦è‰²å®Œæˆ
        - æ›´æ¸©æš–ï¼šAI å›åº”"çœŸå®çš„ä½ "è€Œä¸æ˜¯"å®Œç¾çš„æ–‡å­—"
        """
        try:
            # è¾“å…¥æ£€æŸ¥
            if not text or len(text.strip()) < 5:
                raise ValueError("å†…å®¹å¤ªçŸ­ï¼Œè¯·å¤šå†™ä¸€äº›")
            
            print(f"âœ¨ å¼€å§‹AIå¤„ç†ï¼ˆå¹¶è¡Œæ¨¡å¼ï¼‰: {text[:50]}...")
            
            # ğŸ”¥ ä¼˜åŒ–è¯­è¨€æ£€æµ‹ï¼šä¼˜å…ˆä½¿ç”¨ Whisper çš„æ£€æµ‹ç»“æœ
            detected_lang = None
            
            # æ–¹æ¡ˆ1: ä¼˜å…ˆä½¿ç”¨ Whisper çš„æ£€æµ‹ç»“æœï¼ˆæœ€å‡†ç¡®ï¼‰
            if whisper_detected_language:
                whisper_lang = whisper_detected_language.lower()
                if whisper_lang in ["en", "english"]:
                    detected_lang = "English"
                    print(f"ğŸŒ ä½¿ç”¨ Whisper æ£€æµ‹çš„è¯­è¨€: {whisper_detected_language} â†’ English")
                elif whisper_lang in ["zh", "chinese", "zh-cn", "zh-tw"]:
                    detected_lang = "Chinese"
                    print(f"ğŸŒ ä½¿ç”¨ Whisper æ£€æµ‹çš„è¯­è¨€: {whisper_detected_language} â†’ Chinese")
                else:
                    # å¦‚æœæ˜¯å…¶ä»–è¯­è¨€ï¼Œè®°å½•æ—¥å¿—ä½†ç»§ç»­ä½¿ç”¨ç»Ÿè®¡æ£€æµ‹
                    print(f"âš ï¸ Whisper æ£€æµ‹åˆ°ä¸æ”¯æŒçš„è¯­è¨€: {whisper_detected_language}ï¼Œé™çº§åˆ°ç»Ÿè®¡æ£€æµ‹")
            
            # æ–¹æ¡ˆ2: å¦‚æœæ²¡æœ‰ Whisper æ£€æµ‹ç»“æœï¼Œä½¿ç”¨ç»Ÿè®¡æ£€æµ‹ï¼ˆå…œåº•ï¼‰
            if not detected_lang:
                # ç§»é™¤ç©ºç™½å­—ç¬¦å’Œæ ‡ç‚¹ï¼Œåªç»Ÿè®¡å®é™…å†…å®¹å­—ç¬¦
                content_only = re.sub(r'[\s\W]', '', text)
                chinese_chars = 0
                english_words = 0
                
                if not content_only:
                    # å¦‚æœåªæœ‰ç©ºç™½å’Œæ ‡ç‚¹ï¼Œé»˜è®¤ä½¿ç”¨è‹±æ–‡ï¼ˆå›½é™…åŒ–ä¼˜å…ˆï¼‰
                    detected_lang = "English"
                    print(f"ğŸŒ å†…å®¹ä¸ºç©ºï¼Œé»˜è®¤ä½¿ç”¨: English")
                else:
                    # ç»Ÿè®¡ä¸­æ–‡å­—ç¬¦
                    chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', content_only))
                    # ç»Ÿè®¡è‹±æ–‡å­—ç¬¦ï¼ˆå•è¯ï¼‰
                    english_words = len(re.findall(r'[a-zA-Z]+', content_only))
                    
                    # ğŸ”¥ æ–°å¢ï¼šæ£€æµ‹éŸ©è¯­/æ—¥è¯­å­—ç¬¦
                    korean_chars = len(re.findall(r'[\uac00-\ud7af]', content_only))
                    japanese_chars = len(re.findall(r'[\u3040-\u309f\u30a0-\u30ff]', content_only))
                    
                    # ğŸ”¥ è¯­è¨€ç™½åå•æ£€æŸ¥ï¼šå¦‚æœæ£€æµ‹åˆ°å¤§é‡éä¸­è‹±æ–‡å­—ç¬¦ï¼Œé™çº§åˆ°è‹±æ–‡ï¼ˆå›½é™…åŒ–ä¼˜å…ˆï¼‰
                    if korean_chars > 5 or japanese_chars > 5:
                        print(f"âš ï¸ æ£€æµ‹åˆ°éæ”¯æŒè¯­è¨€å­—ç¬¦: éŸ©è¯­={korean_chars}, æ—¥è¯­={japanese_chars}")
                        print(f"   å†…å®¹: '{text[:50]}'")
                        print(f"   é™çº§åˆ°ç³»ç»Ÿé»˜è®¤è¯­è¨€: English")
                        detected_lang = "English"  # é™çº§åˆ°è‹±æ–‡ï¼ˆå›½é™…åŒ–ä¼˜å…ˆï¼‰
                    else:
                        # è®¡ç®—ä¸­æ–‡å­—ç¬¦å æ¯”
                        chinese_ratio = chinese_chars / len(content_only) if len(content_only) > 0 else 0
                        # è®¡ç®—è‹±æ–‡å•è¯å æ¯”ï¼ˆæ¯ä¸ªå•è¯å¹³å‡5ä¸ªå­—ç¬¦ä¼°ç®—ï¼‰
                        english_ratio = (english_words * 5) / len(content_only) if len(content_only) > 0 else 0
                        
                        # ğŸ”¥ å…³é”®é€»è¾‘ï¼šå¦‚æœä¸­æ–‡å­—ç¬¦å æ¯”è¶…è¿‡30%ï¼Œæˆ–è€…ä¸­æ–‡å­—ç¬¦æ•°é‡æ˜æ˜¾å¤šäºè‹±æ–‡å•è¯ï¼Œåˆ¤å®šä¸ºä¸­æ–‡
                        if chinese_ratio > 0.3 or (chinese_chars > 5 and chinese_chars > english_words * 2):
                            detected_lang = "Chinese"
                        elif english_ratio > 0.5 or english_words > 10:
                            detected_lang = "English"
                        else:
                            # ğŸ”¥ ä¿®æ”¹é»˜è®¤å€¼ï¼šä¼˜å…ˆè‹±æ–‡ï¼ˆå›½é™…åŒ–ä¼˜å…ˆï¼‰
                            detected_lang = "English" if chinese_chars < 3 else "Chinese"
                        
                        print(f"ğŸŒ ç»Ÿè®¡æ£€æµ‹è¯­è¨€: {detected_lang} (ä¸­æ–‡å­—ç¬¦={chinese_chars}, è‹±æ–‡å•è¯={english_words})")
            
            print(f"ğŸŒ æœ€ç»ˆä½¿ç”¨è¯­è¨€: {detected_lang}")
            
            # ğŸ”¥ å…³é”®æ”¹åŠ¨ï¼šæœ€ä¼˜Agent Orchestrationæ¶æ„
            # ç­–ç•¥: Polishç‹¬ç«‹å¹¶è¡Œ | (Emotion â†’ Feedback) ç»„å†…ä¸²è¡Œ
            print(f"ğŸš€ å¯åŠ¨æœ€ä¼˜Agentå¹¶è¡Œæ¶æ„...")
            if image_urls and len(image_urls) > 0:
                print(f"   - æ£€æµ‹åˆ° {len(image_urls)} å¼ å›¾ç‰‡ï¼Œå°†ä½¿ç”¨ Vision èƒ½åŠ›åˆ†æå›¾ç‰‡+æ–‡å­—")
            print(f"   - å¹¶è¡Œç»„1: Polish Agent (ç‹¬ç«‹è¿è¡Œ)")
            print(f"   - å¹¶è¡Œç»„2: Emotion Agent â†’ Feedback Agent (ä¸²è¡Œ)")
            print(f"   - ğŸ¯ ä¸¤ç»„å¹¶è¡Œ,æ€»è€—æ—¶ = max(Polish, Emotion+Feedback)")
            
            # ğŸ”¥ æ€§èƒ½ä¼˜åŒ–ï¼šé¢„å…ˆä¸‹è½½å¹¶ç¼–ç æ‰€æœ‰å›¾ç‰‡ï¼Œé¿å…åœ¨å¹¶è¡Œä»»åŠ¡ä¸­é‡å¤ä¸‹è½½
            encoded_images = []
            if image_urls and len(image_urls) > 0:
                print(f"ğŸ–¼ï¸ é¢„å¤„ç† {len(image_urls)} å¼ å›¾ç‰‡...")
                # å¹¶è¡Œä¸‹è½½å›¾ç‰‡
                download_tasks = [self._download_and_encode_image(url) for url in image_urls]
                results = await asyncio.gather(*download_tasks, return_exceptions=True)
                for i, img_data in enumerate(results):
                    if isinstance(img_data, Exception):
                        print(f"âš ï¸ å›¾ç‰‡ä¸‹è½½å¤±è´¥ ({image_urls[i]}): {img_data}")
                    else:
                        encoded_images.append(img_data)
            
            # ğŸ”¥ å®šä¹‰å¹¶è¡Œç»„2: Emotion â†’ Feedback (ç»„å†…ä¸²è¡Œ)
            async def emotion_feedback_pipeline():
                """
                Emotionå’ŒFeedbackçš„ä¸²è¡Œæµæ°´çº¿
                
                ä¸ºä»€ä¹ˆä¸²è¡Œ?
                - Feedbackéœ€è¦çŸ¥é“Emotionç»“æœ
                - å¯ä»¥ç”Ÿæˆæ›´ç²¾å‡†ã€æ›´è´´åˆ‡çš„åé¦ˆ
                """
                # æ­¥éª¤1: Emotionåˆ†æ
                emotion_result = await self.analyze_emotion_only(text, detected_lang, encoded_images)
                print(f"   âœ… Emotion Agentå®Œæˆ: {emotion_result.get('emotion')} (ç½®ä¿¡åº¦: {emotion_result.get('confidence')})")
                
                # æ­¥éª¤2: åŸºäºEmotionç”ŸæˆFeedback
                feedback_data = await self._call_gpt4o_for_feedback(
                    text,
                    detected_lang,
                    user_name,
                    encoded_images
                    # TODO: æœªæ¥å¯ä»¥ä¼ å…¥ emotion_hint=emotion_result
                )
                print(f"   âœ… Feedback Agentå®Œæˆ")
                
                return emotion_result, feedback_data
            
            # ğŸ”¥ å¹¶è¡Œç»„1: Polish (ç‹¬ç«‹)
            polish_task = self._call_gpt4o_for_polish_and_title(text, detected_lang, encoded_images)
            
            # ğŸ”¥ å¹¶è¡Œç»„2: Emotion â†’ Feedback (ç»„å†…ä¸²è¡Œ)
            emotion_feedback_task = emotion_feedback_pipeline()
            
            # ğŸ”¥ ä¸¤ç»„å¹¶è¡Œæ‰§è¡Œ - âœ… å…³é”®ä¿®å¤ï¼šæ·»åŠ  return_exceptions=True
            print(f"   ğŸš€ å¯åŠ¨ä¸¤ç»„å¹¶è¡Œ...")
            results = await asyncio.gather(
                polish_task,                # ç»„1: Polishç‹¬ç«‹
                emotion_feedback_task,      # ç»„2: Emotion â†’ Feedback
                return_exceptions=True      # âœ… é˜²æ­¢å•ä¸ªå¤±è´¥å¯¼è‡´æ•´ä½“å¤±è´¥
            )
            
            # âœ… æ£€æŸ¥æ¯ä¸ªç»“æœï¼Œæä¾›å…œåº•å€¼
            polish_result = results[0]
            emotion_feedback_result = results[1]
            
            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæå‰åˆå§‹åŒ–å˜é‡ï¼Œé˜²æ­¢NameError
            emotion_result = None
            feedback_data = None
            
            # å¤„ç†Polishç»“æœ
            if isinstance(polish_result, Exception):
                print(f"âŒ Polish Agentå¤±è´¥: {polish_result}")
                print(f"   ä½¿ç”¨å…œåº•ï¼šåŸæ–‡ + é»˜è®¤æ ‡é¢˜")
                polish_result = {
                    "title": "ä»Šæ—¥è®°å½•" if detected_lang == "Chinese" else "Today's Reflection",
                    "polished_content": text
                }
            
            # å¤„ç†Emotion+Feedbackç»“æœ
            if isinstance(emotion_feedback_result, Exception):
                print(f"âŒ Emotion+Feedback Agentå¤±è´¥: {emotion_feedback_result}")
                print(f"   ä½¿ç”¨å…œåº•ï¼šé»˜è®¤æƒ…ç»ª + ç®€å•åé¦ˆ")
                emotion_result = {"emotion": "Thoughtful", "confidence": 0.5, "rationale": "é»˜è®¤æƒ…ç»ª"}
                feedback_data = "æ„Ÿè°¢åˆ†äº«ä½ çš„æ•…äº‹ã€‚" if detected_lang == "Chinese" else "Thanks for sharing your story."
                if user_name:
                    separator = "ï¼Œ" if detected_lang == "Chinese" else ", "
                    feedback_data = f"{user_name}{separator}{feedback_data}"
            else:
                emotion_result, feedback_data = emotion_feedback_result

            
            print(f"âœ… ä¸¤ç»„å¹¶è¡Œå®Œæˆ")
            
            # ğŸ”¥ æœ€ç»ˆå…œåº•æ£€æŸ¥ï¼šç¡®ä¿å˜é‡ä¸ä¸ºNone
            if emotion_result is None:
                print(f"âš ï¸ emotion_resultä¸ºNoneï¼Œä½¿ç”¨é»˜è®¤å€¼")
                emotion_result = {"emotion": "Thoughtful", "confidence": 0.5, "rationale": "é»˜è®¤æƒ…ç»ª"}
            
            if feedback_data is None:
                print(f"âš ï¸ feedback_dataä¸ºNoneï¼Œä½¿ç”¨é»˜è®¤å€¼")
                feedback_data = "æ„Ÿè°¢åˆ†äº«ä½ çš„æ•…äº‹ã€‚" if detected_lang == "Chinese" else "Thanks for sharing your story."
                if user_name:
                    separator = "ï¼Œ" if detected_lang == "Chinese" else ", "
                    feedback_data = f"{user_name}{separator}{feedback_data}"
            
            # å¤„ç†åé¦ˆç»“æœ
            if isinstance(feedback_data, dict):
                feedback_text = feedback_data.get("reply", "")
            else:
                feedback_text = str(feedback_data)
            
            # åˆå¹¶ç»“æœ
            result = {
                "title": polish_result['title'],
                "polished_content": polish_result['polished_content'],
                "feedback": feedback_text,
                "emotion_data": emotion_result  # âœ… æ¥è‡ªä¸“é—¨çš„Emotion Agent
            }
            
            # è´¨é‡æ£€æŸ¥
            result = self._validate_and_fix_result(result, text)
            
            print(f"âœ… å¤„ç†å®Œæˆ:")
            print(f"  - æ ‡é¢˜: {result['title']}")
            print(f"  - å†…å®¹é•¿åº¦: {len(result['polished_content'])} å­—")
            print(f"  - åé¦ˆé•¿åº¦: {len(result['feedback'])} å­—")
            print(f"  - æƒ…ç»ª: {result.get('emotion_data', {}).get('emotion', 'Unknown')}")
            
            return result
        
        except Exception as e:
            error_type = type(e).__name__
            error_msg = str(e)
            print(f"âŒ AIå¤„ç†å¤±è´¥: {error_type}: {error_msg}")
            error_trace = traceback.format_exc()
            print(f"ğŸ“ å®Œæ•´é”™è¯¯å †æ ˆ:")
            print(error_trace)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å¹¶è¡Œä»»åŠ¡ä¸­çš„é”™è¯¯
            if isinstance(e, (asyncio.TimeoutError, asyncio.CancelledError)):
                print(f"âš ï¸ å¹¶è¡Œä»»åŠ¡è¶…æ—¶æˆ–å–æ¶ˆ")
            elif isinstance(e, Exception):
                print(f"âš ï¸ å¹¶è¡Œä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
            
            return self._create_fallback_result(text, user_name=user_name)
    
    # ========================================================================
    # ğŸ”¥ GPT-4o-mini è°ƒç”¨ï¼ˆæ¶¦è‰² + æ ‡é¢˜ï¼‰
    # ========================================================================
    
    async def _call_gpt4o_for_polish_and_title(
        self, 
        text: str,
        language: str,
        encoded_images: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """
        è°ƒç”¨ GPT-4o è¿›è¡Œæ¶¦è‰²å’Œç”Ÿæˆæ ‡é¢˜
        
        ğŸ“š å­¦ä¹ ç‚¹ï¼šè¿™ä¸ªå‡½æ•°è´Ÿè´£ä¸¤ä¸ªä»»åŠ¡
        1. æ¶¦è‰²ç”¨æˆ·çš„åŸå§‹æ–‡æœ¬ï¼ˆä¿®å¤è¯­æ³•ã€ä¼˜åŒ–è¡¨è¾¾ï¼‰
        2. ç”Ÿæˆä¸€ä¸ªç®€æ´æœ‰æ„ä¹‰çš„æ ‡é¢˜
        
        ä¸ºä»€ä¹ˆä½¿ç”¨ GPT-4oï¼Ÿ
        - è´¨é‡æé«˜
        - æ ‡é¢˜ç”Ÿæˆæ›´ç²¾å‡†ï¼Œä¸å‡ºç°ä½çº§é”™è¯¯
        
        è¿”å›:
            {
                "title": "æ ‡é¢˜",
                "polished_content": "æ¶¦è‰²åçš„å†…å®¹"
            }
        """
        try:
            print(f"ğŸ¨ GPT-4o: å¼€å§‹æ¶¦è‰²å’Œç”Ÿæˆæ ‡é¢˜...")
            
            # ğŸ”¥ ä¼˜åŒ–ï¼šæ ¹æ®ä¼ å…¥çš„ language å‚æ•°æ„å»ºæ›´ä¸¥æ ¼çš„ prompt
            # æ ¸å¿ƒåŸåˆ™ï¼šæ ‡é¢˜è¯­è¨€å¿…é¡»ä¸ç”¨æˆ·è¾“å…¥å†…å®¹çš„ä¸»è¦è¯­è¨€å®Œå…¨ä¸€è‡´
            language_instruction = ""
            if language == "Chinese":
                language_instruction = """ğŸš¨ CRITICAL LANGUAGE RULE - YOU MUST FOLLOW:
The user's content is primarily in CHINESE (ç®€ä½“ä¸­æ–‡). 

MANDATORY REQUIREMENTS:
1. **Title MUST be in Chinese (ç®€ä½“ä¸­æ–‡) ONLY** - NO English, NO Japanese, NO Korean
2. **Title language must match the user's input language** - If user writes in Chinese, title MUST be Chinese
3. Even if the content contains some English words or other languages, the title MUST be in Chinese
4. Polished content should preserve the original language of each part, but the title MUST be Chinese

WRONG Examples (DO NOT DO THIS):
- User input in Chinese â†’ Title: "Reflections on..." âŒ
- User input in Chinese â†’ Title: "ã‚ªãƒ¬ãƒ³ã‚¸ã®é­…åŠ›" âŒ

CORRECT Examples:
- User input: "æˆ‘å…ˆè¯•ä¸€ä¸‹è¯­éŸ³è¾“å…¥ï¼Œç°åœ¨æ€ä¹ˆæ ·" â†’ Title: "è¯­éŸ³è¾“å…¥çš„å°è¯•" âœ…
- User input: "ã‚ªãƒ¬ãƒ³ã‚¸ã®é­…åŠ› Talking about orange..." â†’ Title: "æ©™å­çš„é­…åŠ›" âœ… (Chinese, not Japanese)

ğŸ¯ SPECIAL POLISHING RULES FOR CHINESE (High-Quality Standards):

**ğŸ“ æ ¸å¿ƒä½¿å‘½ï¼šåˆ›å»ºé«˜è´¨é‡çš„ä¸­æ–‡ï¼Œè®©ç”¨æˆ·å¯ä»¥å­¦ä¹ å‚è€ƒ**

**ä¼˜å…ˆçº§é¡ºåºï¼ˆä¸¥æ ¼éµå¾ªï¼‰ï¼š**

1. **é¦–è¦ç›®æ ‡ï¼šæ¶ˆé™¤æ‰€æœ‰å£è¯­åŒ–æ ‡è®°**
   âŒ åˆ é™¤ï¼šæ‰€æœ‰è¯­æ°”è¯ï¼ˆå—¯ã€å•Šã€å‘ƒã€å“ã€å“å‘€ã€è¯¶ï¼‰
   âŒ åˆ é™¤ï¼šæ‰€æœ‰åœé¡¿è¯ï¼ˆé‚£ä¸ªã€å°±æ˜¯ã€ç„¶åã€å—¯å—¯ã€è¿™ä¸ªï¼‰
   âŒ åˆ é™¤ï¼šæ‰€æœ‰çŠ¹è±«å’Œé‡å¤ï¼ˆ"æˆ‘æˆ‘æˆ‘"ã€"å°±å°±"ï¼‰
   âŒ ä¿®æ­£ï¼šæ‰€æœ‰è¯­æ³•é”™è¯¯å’Œä¸é€šé¡ºçš„è¡¨è¾¾
   âœ… ç»“æœï¼šæµç•…è‡ªç„¶çš„ä¹¦é¢è¯­ï¼Œé€‚åˆé˜…è¯»å’Œå­¦ä¹ 

2. **æ¬¡è¦ç›®æ ‡ï¼šå±•ç¤ºä¼˜è´¨ä¸­æ–‡è¡¨è¾¾**
   âœ… ä½¿ç”¨è‡ªç„¶æµç•…çš„å¥å¼ç»“æ„
   âœ… é€‰æ‹©å‡†ç¡®ç”ŸåŠ¨çš„è¯æ±‡ï¼ˆé¿å…"å¾ˆå¥½"ã€"ä¸é”™"ç­‰æ³›æ³›ä¹‹è¯ï¼‰
   âœ… ä¿æŒå¥å­é•¿çŸ­é€‚ä¸­ï¼Œå¯Œæœ‰èŠ‚å¥æ„Ÿ
   âœ… é€‚å½“ä½¿ç”¨æˆè¯­å’Œæƒ¯ç”¨è¡¨è¾¾ï¼ˆä½†ä¸è¦è¿‡åº¦æ–‡è‰ºï¼‰
   
3. **ç¬¬ä¸‰ç›®æ ‡ï¼šä¿ç•™åŸæ„å’Œæƒ…æ„Ÿ**
   âœ… ä¿æŒæ ¸å¿ƒä¿¡æ¯ã€æƒ…ç»ªå’Œå…³é”®ç»†èŠ‚
   âœ… ç»´æŒæ—¥è®°çš„çœŸå®ã€ä¸ªäººåŒ–è¯­æ°”
   âœ… ä¸æ·»åŠ ç”¨æˆ·æœªè¡¨è¾¾çš„ä¿¡æ¯
   âš ï¸ **å…³é”®**ï¼šå¦‚æœæµç•…åº¦å’ŒåŸæ–‡æªè¾å†²çªï¼Œä¼˜å…ˆé€‰æ‹©æµç•…åº¦

**ğŸš¨ ç»å¯¹è§„åˆ™ - æ— ä¾‹å¤–ï¼š**

1. **é›¶å®¹å¿å£è¯­åŒ–è¯­æ°”è¯ï¼š**
   - è¾“å…¥ï¼š"å—¯ï¼Œæˆ‘è§‰å¾—ï¼Œå°±æ˜¯ï¼Œä»Šå¤©è¿˜ä¸é”™ï¼Œé‚£ä¸ªï¼ŒæŒºå¥½çš„"
   - è¾“å‡ºï¼š"ä»Šå¤©è¿˜ä¸é”™ï¼ŒæŒºå¥½çš„ã€‚" âœ…
   - é”™è¯¯ï¼š"å—¯ï¼Œæˆ‘è§‰å¾—ä»Šå¤©è¿˜ä¸é”™ã€‚" âŒ

2. **é›¶å®¹å¿è¯­æ³•é”™è¯¯ï¼š**
   - æ¯ä¸ªå¥å­å¿…é¡»è¯­æ³•æ­£ç¡®
   - æ ‡ç‚¹ç¬¦å·ä½¿ç”¨è§„èŒƒ
   - é¿å…å£è¯­åŒ–çš„çœç•¥ï¼ˆ"å»å…¬å›­"â†’"å»äº†å…¬å›­"ï¼‰

3. **é›¶å®¹å¿é‡å¤å’Œå•°å—¦ï¼š**
   - "ç„¶åæˆ‘å°±å»äº†ï¼Œç„¶åå°±çœ‹åˆ°äº†" â†’ "æˆ‘å»äº†ä¹‹åçœ‹åˆ°äº†"
   - "å¾ˆå¥½å¾ˆå¥½å¾ˆå¥½" â†’ "éå¸¸å¥½"

**ğŸ“‹ å¸¸è§å£è¯­åŒ–é—®é¢˜ä¿®æ­£ï¼š**

**è¯­æ°”è¯å’Œåœé¡¿è¯ï¼š**
- "å—¯ï¼Œä»Šå¤©å¤©æ°”ä¸é”™" â†’ "ä»Šå¤©å¤©æ°”ä¸é”™"
- "æˆ‘è§‰å¾—ï¼Œå°±æ˜¯ï¼Œæœ‰ç‚¹ç´¯" â†’ "æˆ‘æœ‰ç‚¹ç´¯"
- "é‚£ä¸ªï¼Œæˆ‘æƒ³è¯´çš„æ˜¯" â†’ "æˆ‘æƒ³è¯´çš„æ˜¯"
- "ç„¶åï¼Œç„¶åæˆ‘å°±å»äº†" â†’ "ç„¶åæˆ‘å°±å»äº†" æˆ– "æ¥ç€æˆ‘å»äº†"
- "å°±æ˜¯æœ‰ç‚¹ï¼Œå—¯ï¼Œä¸å¤ªå¥½" â†’ "æœ‰ç‚¹ä¸å¤ªå¥½"

**é‡å¤å’Œå•°å—¦ï¼š**
- "æˆ‘æˆ‘æˆ‘ä»Šå¤©" â†’ "æˆ‘ä»Šå¤©"
- "å¾ˆå¥½å¾ˆå¥½" â†’ "å¾ˆå¥½" æˆ– "éå¸¸å¥½"
- "ç„¶åæˆ‘å°±ï¼Œç„¶åå°±" â†’ "ç„¶åæˆ‘å°±"

**å£è¯­åŒ–è¡¨è¾¾ä¼˜åŒ–ï¼š**
- "æŒºå¥½çš„å§" â†’ "æŒºå¥½çš„"
- "è¿˜è¡Œè¿˜è¡Œ" â†’ "è¿˜ä¸é”™"
- "æœ‰ç‚¹é‚£ä¸ª" â†’ æ ¹æ®ä¸Šä¸‹æ–‡è¡¥å……å®Œæ•´
- "å·®ä¸å¤šå§" â†’ "å·®ä¸å¤š"

**å¥å¼ä¼˜åŒ–ï¼š**
- çŸ­å¥åˆå¹¶ï¼š"ä»Šå¤©å»å…¬å›­ã€‚çœ‹åˆ°èŠ±ã€‚å¾ˆå¼€å¿ƒã€‚" â†’ "ä»Šå¤©å»å…¬å›­çœ‹åˆ°äº†èŠ±ï¼Œå¾ˆå¼€å¿ƒã€‚"
- æµæ°´å¥æ‹†åˆ†ï¼š"æˆ‘èµ·åºŠç„¶ååƒæ—©é¥­ç„¶åå»ä¸Šç­ç„¶åå¾ˆç´¯" â†’ "æˆ‘èµ·åºŠååƒäº†æ—©é¥­ï¼Œç„¶åå»ä¸Šç­ã€‚æ„Ÿè§‰å¾ˆç´¯ã€‚"

**ğŸ” é«˜è´¨é‡ç¤ºä¾‹ï¼š**

ç¤ºä¾‹ 1 - æ¶ˆé™¤è¯­æ°”è¯ + è¯­æ³•ä¿®æ­£ï¼š
âŒ åŸæ–‡ï¼š"å—¯ï¼Œä»Šå¤©æˆ‘å»äº†ï¼Œé‚£ä¸ªï¼Œå…¬å›­ï¼Œç„¶åçœ‹åˆ°å¾ˆå¤šèŠ±ï¼Œå°±æ˜¯ï¼Œå¾ˆå¼€å¿ƒ"
âœ… æ¶¦è‰²ï¼š"ä»Šå¤©æˆ‘å»äº†å…¬å›­ï¼Œçœ‹åˆ°å¾ˆå¤šèŠ±ï¼Œå¾ˆå¼€å¿ƒã€‚"
ğŸ“š æ”¹è¿›ï¼šåˆ é™¤æ‰€æœ‰è¯­æ°”è¯ï¼ˆå—¯ã€é‚£ä¸ªã€ç„¶åã€å°±æ˜¯ï¼‰ï¼Œå¥å¼æ›´æµç•…

ç¤ºä¾‹ 2 - ä¼˜åŒ–è¡¨è¾¾ï¼š
âŒ åŸæ–‡ï¼š"ä»Šå¤©å·¥ä½œå¾ˆç´¯å¾ˆç´¯ï¼Œå°±æ˜¯æ„Ÿè§‰ä¸å¤ªå¥½ï¼Œæœ‰ç‚¹é‚£ä¸ªï¼Œä¸æƒ³åŠ¨"
âœ… æ¶¦è‰²ï¼š"ä»Šå¤©å·¥ä½œå¾ˆç´¯ï¼Œæ„Ÿè§‰ä¸å¤ªå¥½ï¼Œä¸æƒ³åŠ¨ã€‚"
ğŸ“š æ”¹è¿›ï¼šåˆ é™¤é‡å¤ï¼ˆå¾ˆç´¯å¾ˆç´¯ï¼‰ï¼Œåˆ é™¤åœé¡¿è¯ï¼ˆå°±æ˜¯ã€æœ‰ç‚¹é‚£ä¸ªï¼‰ï¼Œè¡¨è¾¾æ›´ç®€æ´

ç¤ºä¾‹ 3 - å¥å¼ä¼˜åŒ–ï¼š
âŒ åŸæ–‡ï¼š"æˆ‘èµ·åºŠã€‚åƒæ—©é¥­ã€‚å»ä¸Šç­ã€‚å¾ˆç´¯ã€‚"
âœ… æ¶¦è‰²ï¼š"æˆ‘èµ·åºŠååƒäº†æ—©é¥­ï¼Œç„¶åå»ä¸Šç­ï¼Œæ„Ÿè§‰å¾ˆç´¯ã€‚"
ğŸ“š æ”¹è¿›ï¼šåˆå¹¶çŸ­å¥ï¼Œå¢åŠ è¿æ¥è¯ï¼Œæ›´æµç•…è‡ªç„¶

ç¤ºä¾‹ 4 - è¯­éŸ³è¾“å…¥ï¼ˆåˆ é™¤æ‰€æœ‰è¯­æ°”è¯ï¼‰ï¼š
âŒ åŸæ–‡ï¼š"å—¯ï¼Œæˆ‘æƒ³ï¼Œå°±æ˜¯ï¼Œè¯•ä¸€ä¸‹è¿™ä¸ªï¼Œé‚£ä¸ªï¼Œè¯­éŸ³è¾“å…¥ï¼Œçœ‹çœ‹ï¼Œå—¯ï¼Œæ€ä¹ˆæ ·"
âœ… æ¶¦è‰²ï¼š"æˆ‘æƒ³è¯•ä¸€ä¸‹è¿™ä¸ªè¯­éŸ³è¾“å…¥ï¼Œçœ‹çœ‹æ€ä¹ˆæ ·ã€‚"
ğŸ“š æ”¹è¿›ï¼šåˆ é™¤æ‰€æœ‰è¯­æ°”è¯å’Œåœé¡¿è¯ï¼ˆå—¯ã€å°±æ˜¯ã€é‚£ä¸ªï¼‰ï¼Œç®€æ´æ¸…æ™°

ç¤ºä¾‹ 5 - é«˜çº§ï¼šä¿ç•™åŸæ„ï¼Œæœ€å¤§åŒ–æµç•…åº¦ï¼š
âŒ åŸæ–‡ï¼š"æˆ‘è§‰å¾—å§ï¼Œå¯èƒ½ï¼Œå°±æ˜¯åº”è¯¥ï¼Œå—¯ï¼Œå¤šè¿åŠ¨ä¸€ç‚¹ï¼Œå› ä¸ºæœ€è¿‘ï¼Œé‚£ä¸ªï¼Œæ„Ÿè§‰èº«ä½“ä¸å¤ªå¥½"
âœ… æ¶¦è‰²ï¼š"æˆ‘è§‰å¾—åº”è¯¥å¤šè¿åŠ¨ä¸€ç‚¹ï¼Œå› ä¸ºæœ€è¿‘æ„Ÿè§‰èº«ä½“ä¸å¤ªå¥½ã€‚"
ğŸ“š æ”¹è¿›ï¼šåˆ é™¤çŠ¹è±«è¯ï¼ˆå§ã€å¯èƒ½ã€å—¯ã€é‚£ä¸ªï¼‰ï¼Œä¿ç•™æ ¸å¿ƒæ„æ€ï¼Œè¡¨è¾¾æ›´è‡ªä¿¡

**âš ï¸ ä¸è¦æ”¹å˜çš„å†…å®¹ï¼š**
- æƒ…æ„ŸåŸºè°ƒï¼ˆéšæ„çš„ä¿æŒéšæ„ï¼Œæ­£å¼çš„ä¿æŒæ­£å¼ï¼‰
- æ ¸å¿ƒæ„æ€å’Œç»å†
- é‡è¦ç»†èŠ‚å’Œäº‹å®
- ä¸“æœ‰åè¯ã€äººåã€ç‰¹å®šæœ¯è¯­ï¼ˆé™¤éæ˜¯æ˜æ˜¾çš„é”™åˆ«å­—ï¼‰
- æ—¥è®°çš„ä¸ªäººåŒ–ã€çœŸå®æ„Ÿ"""
            elif language == "English":
                language_instruction = """ğŸš¨ CRITICAL LANGUAGE RULE - YOU MUST FOLLOW:
The user's content is primarily in ENGLISH.

MANDATORY REQUIREMENTS:
1. **Title MUST be in English ONLY** - NO Chinese, NO Japanese, NO Korean
2. **Title language must match the user's input language** - If user writes in English, title MUST be English
3. Even if the content contains some Chinese words or other languages, the title MUST be in English
4. Polished content should preserve the original language of each part, but the title MUST be English

WRONG Examples (DO NOT DO THIS):
- User input in English â†’ Title: "ä»Šæ—¥è®°å½•" âŒ
- User input in English â†’ Title: "ã‚ªãƒ¬ãƒ³ã‚¸ã®é­…åŠ›" âŒ

CORRECT Examples:
- User input: "today was good i went to park" â†’ Title: "A Day at the Park" âœ…
- User input: "ã‚ªãƒ¬ãƒ³ã‚¸ã®é­…åŠ› Talking about orange..." â†’ Title: "The Charm of Oranges" âœ… (English, not Japanese)

ğŸ¯ SPECIAL POLISHING RULES FOR ENGLISH (Language Learning Quality - TEACHING GRADE):

**ğŸ“ CORE MISSION: Create TEACHING-GRADE English that users can learn from**
Your polished version is a LEARNING TOOL. Users will compare it with their original to improve their English.
This is NOT just editingâ€”it's TEACHING through example.

**PRIORITY ORDER (CRITICAL - Follow this exact sequence):**

1. **PRIMARY GOAL: ELIMINATE ALL NON-NATIVE MARKERS**
   âŒ Remove: ALL filler words (um, uh, er, ah, like, you know, I mean)
   âŒ Remove: ALL hesitations and false starts
   âŒ Remove: ALL grammatical errors (articles, prepositions, tenses, subject-verb agreement)
   âŒ Remove: ALL awkward phrasing and "foreign feel"
   âœ… Result: Text that sounds 100% nativeâ€”indistinguishable from a native speaker's diary

2. **SECONDARY GOAL: DEMONSTRATE NATIVE PATTERNS**
   âœ… Use natural idioms and collocations that natives actually use
   âœ… Apply authentic sentence structures (varied, flowing, rhythmic)
   âœ… Choose precise, vivid vocabulary (not generic words)
   âœ… Employ contractions naturally (I'm, don't, can't, it's)
   âœ… Show proper use of phrasal verbs (figure out, keep going, run into)
   
3. **TERTIARY GOAL: PRESERVE MEANING & EMOTION**
   âœ… Keep the core message, emotions, and key details intact
   âœ… Maintain the diary's authentic, personal tone
   âœ… Don't add information the user didn't express
   âš ï¸ **CRITICAL**: If there's a conflict between native fluency and exact wording, ALWAYS choose native fluency

**ğŸš¨ ABSOLUTE RULES - NO EXCEPTIONS:**

1. **ZERO TOLERANCE for filler words in polished output:**
   - Input: "um, I think, like, today was, you know, pretty good"
   - Output: "Today was pretty good." âœ…
   - NOT: "Um, I think today was pretty good." âŒ

2. **ZERO TOLERANCE for grammatical errors:**
   - Every sentence must be grammatically perfect
   - Every article (a/an/the) must be correct
   - Every preposition must be natural
   - Every tense must be appropriate

3. **ZERO TOLERANCE for non-native patterns:**
   - "I very like" â†’ "I really like" or "I love"
   - "eat medicine" â†’ "take medicine"
   - "go to park" â†’ "go to the park"
   - "in Monday" â†’ "on Monday"

**ğŸ“‹ COMPREHENSIVE NON-NATIVE PATTERNS TO FIX:**

**Grammar Errors:**
- Missing articles: "I went to park" â†’ "I went to the park"
- Wrong articles: "I saw a beautiful scenery" â†’ "I saw beautiful scenery" (uncountable)
- Wrong prepositions: "in the morning of Monday" â†’ "on Monday morning"
- Wrong tenses: "Today I go to park" (past event) â†’ "I went to the park today"
- Subject-verb agreement: "She don't like it" â†’ "She doesn't like it"

**Word Order & Structure:**
- Unnatural order: "I very like it" â†’ "I really like it" / "I like it a lot"
- Adjective placement: "I saw beautiful very flowers" â†’ "I saw very beautiful flowers"
- Adverb placement: "I always am happy" â†’ "I'm always happy"

**Vocabulary & Expressions:**
- Literal translations: "eat medicine" â†’ "take medicine", "open the light" â†’ "turn on the light"
- Overly formal: "I am feeling very happy" â†’ "I'm so happy" / "I feel great"
- Generic words: "very good" â†’ "great/wonderful/fantastic/amazing"
- Wrong collocations: "make homework" â†’ "do homework", "say a lie" â†’ "tell a lie"

**Sentence Flow:**
- Choppy sentences: "I went to store. I bought milk. I came home." 
  â†’ "I went to the store, bought some milk, and came home."
- Run-on sentences: "I woke up and I ate breakfast and I went to work and I was tired"
  â†’ "I woke up, ate breakfast, and went to work. I was tired."

**âœ¨ NATIVE ENHANCEMENT TECHNIQUES:**

1. **Contractions** (casual diary style):
   - "I am" â†’ "I'm", "do not" â†’ "don't", "it is" â†’ "it's"
   - "I am going to" â†’ "I'm going to" / "I'm gonna" (very casual)

2. **Phrasal Verbs** (more natural than formal verbs):
   - "continue" â†’ "keep going", "understand" â†’ "figure out"
   - "encounter" â†’ "run into", "postpone" â†’ "put off"

3. **Idiomatic Expressions**:
   - "very tired" â†’ "exhausted" / "beat" / "wiped out"
   - "very happy" â†’ "thrilled" / "over the moon" / "on cloud nine"
   - "very busy" â†’ "swamped" / "up to my ears in work"

4. **Vivid, Specific Vocabulary**:
   - "good" â†’ "great/wonderful/fantastic/lovely"
   - "bad" â†’ "rough/tough/awful/terrible"
   - "walk" â†’ "stroll/wander/stride" (context-dependent)

5. **Sentence Variety** (mix short and long):
   - Short for impact: "It was amazing."
   - Long for detail: "I spent the afternoon wandering through the park, watching kids play soccer and couples having picnics."

**ğŸ” TEACHING-GRADE EXAMPLES:**

Example 1 - Eliminating Fillers + Grammar:
âŒ Original: "um, today i go to park and, like, see many flower, it make me, you know, very happy"
âœ… Polished: "I went to the park today and saw so many flowers. It made me really happy!"
ğŸ“š Learning: Removed all fillers (um, like, you know), fixed tense (goâ†’went), added articles (the park), fixed grammar (flowerâ†’flowers, makeâ†’made)

Example 2 - Native Patterns:
âŒ Original: "I am very like this new job because can learn many things"
âœ… Polished: "I really love this new job because I'm learning so much!"
ğŸ“š Learning: Fixed "very like"â†’"really love", added subject "I'm", used contraction, "many things"â†’"so much" (more natural)

Example 3 - Idiomatic + Flow:
âŒ Original: "Today weather is not good so I stay at house and do nothing"
âœ… Polished: "The weather was terrible today, so I just stayed home and did nothing."
ğŸ“š Learning: Added article "the", "not good"â†’"terrible" (more vivid), "at house"â†’"home", added natural "just"

Example 4 - Voice Input (Remove ALL fillers):
âŒ Original: "um, i think, like, i want to, you know, try this voice input thing, let's see, uh, how it work"
âœ… Polished: "I want to try this voice input thing. Let's see how it works!"
ğŸ“š Learning: Removed ALL fillers (um, like, you know, uh, i think), fixed "work"â†’"works", clean and natural

Example 5 - Combining Sentences:
âŒ Original: "I have one meeting today. The meeting is very boring. I don't like the meeting. After meeting I feel tired."
âœ… Polished: "I had a meeting today, and it was so boring. I really didn't like it, and afterwards I felt exhausted."
ğŸ“š Learning: Combined choppy sentences, varied structure, "very boring"â†’"so boring", "tired"â†’"exhausted"

Example 6 - Advanced: Preserving Meaning, Maximizing Fluency:
âŒ Original: "I think maybe I should, like, start to exercise more because I am feeling not very healthy recently"
âœ… Polished: "I think I should start exercising moreâ€”I haven't been feeling very healthy lately."
ğŸ“š Learning: Removed fillers (like, maybe), "start to exercise"â†’"start exercising", "not very healthy"â†’natural phrasing, "recently"â†’"lately"

**âš ï¸ WHAT NOT TO CHANGE:**
- Emotional tone (casual stays casual, formal stays formal)
- Core meaning and experiences
- Important details or facts
- Proper nouns, names, specific terms (unless typo)
- The diary-like, personal feel"""
            else:
                # é»˜è®¤ï¼šæ£€æµ‹è¯­è¨€ï¼Œä½†å¿…é¡»ä¸¥æ ¼åŒ¹é…
                language_instruction = """ğŸš¨ CRITICAL LANGUAGE RULE - YOU MUST FOLLOW:
Detect the user's PRIMARY language from their input content.

MANDATORY REQUIREMENTS:
1. **Title language MUST match the user's primary input language**
2. If content is primarily Chinese â†’ Title MUST be Chinese
3. If content is primarily English â†’ Title MUST be English
4. If content contains mixed languages, use the language that appears MOST FREQUENTLY
5. NEVER use Japanese or Korean for titles unless the ENTIRE content is in that language
6. **DO NOT mix languages in the title** - Use ONE language only, matching the user's primary language

Examples:
- User input: "ä»Šå¤©å¤©æ°”å¾ˆå¥½" (Chinese) â†’ Title: "ç¾å¥½çš„å¤©æ°”" âœ… (Chinese)
- User input: "today was good" (English) â†’ Title: "A Good Day" âœ… (English)
- User input: "ä»Šå¤©å¤©æ°”å¾ˆå¥½ today was good" (mixed, more Chinese) â†’ Title: "ç¾å¥½çš„ä¸€å¤©" âœ… (Chinese, matching primary language)"""
            
            # æ„å»º prompt
            system_prompt = f"""You are a gentle diary editor. Your task is to polish the user's diary entry and create a title.

{language_instruction}

Your responsibilities:
1. **For ENGLISH input (non-native speakers):**
   - PRIMARY: Make it sound like a native English speaker wrote it (eliminate all non-native patterns)
   - SECONDARY: Preserve the user's intended meaning and emotions
   - GOAL: Help users learn natural English by providing an exemplary polished version
   
2. **For OTHER languages (Chinese, etc.):**
   - Fix obvious grammar/typos
   - Make the text flow naturally
   - Keep it authentic and close to the original style

3. **Universal rules:**
   - Keep polished content â‰¤115% of original length
   - **CRITICAL: Preserve ALL original content. Do NOT delete or omit any part of the user's entry.**
   - **Formatting: Preserve the user's line breaks, blank lines, and bullet/numbered lists. Do NOT merge everything into one paragraph.**
   - **If the input is long and mostly one block (no line breaks), add clear paragraph breaks based on meaning.**
   - **Avoid overly short paragraphs. Do NOT break right after the first sentence. Keep the first 3 sentences in the same paragraph when you add breaks.**
   
4. **ğŸš¨ MOST CRITICAL: Create a title in the EXACT SAME LANGUAGE as the user's primary input language**
   - If user writes in Chinese â†’ Title MUST be in Chinese
   - If user writes in English â†’ Title MUST be in English
   - The title language must match the content language - NO EXCEPTIONS
   - Title should be short, warm, poetic, and meaningful, but ALWAYS in the user's language
   
5. **ğŸš¨ TITLE CONTENT RULES - AVOID GENERIC AND REDUNDANT TITLES:**
   - **NEVER use "ä»Šæ—¥" (today) in Chinese titles** - It's too generic and meaningless
   - **NEVER use "Today's..." in English titles** - Same reason, too generic
   - **If you must reference the day, use specific date format instead**: "1æœˆ9æ—¥" (Jan 9), not "ä»Šæ—¥"
   - **AVOID repeating the first line of content in the title** - The title should complement, not duplicate
   - **Be specific and meaningful**: Extract the core theme, emotion, or key event from the content
   
   **ğŸ¯ SPECIAL RULE FOR TASK LISTS AND PLANNING CONTENT:**
   - **For task lists, to-do lists, or planning content (ä»»åŠ¡æ¸…å•, è®¡åˆ’, to-do, plan, goal):**
     - **MUST include the specific date in the title** to make it informative and unique
     - Use format: "1æœˆ9æ—¥ + theme" (Chinese) or "Jan 9 + theme" (English)
     - This prevents repetitive titles like "ä»»åŠ¡æ¸…å•" appearing multiple times
   
   Examples of BAD titles (DO NOT USE):
   âŒ "ä»Šæ—¥ä»»åŠ¡æ¸…å•" - Generic "today" + redundant with content's first line "ä»Šæ—¥ä»»åŠ¡:"
   âŒ "ä»»åŠ¡æ¸…å•" - Too generic, will repeat for every task list entry
   âŒ "ä»Šæ—¥è®°å½•" - Too generic, no meaning
   âŒ "Today's Thoughts" - Generic "today"
   âŒ "Task List" - Too generic, will repeat
   
   Examples of GOOD titles:
   âœ… "1æœˆ9æ—¥ä»»åŠ¡æ¸…å•" - Specific date + clear theme, won't repeat
   âœ… "Jan 9 Task List" - Specific date + clear theme
   âœ… "1æœˆ9æ—¥çš„Appä¸Šæ¶è®¡åˆ’" - Date + specific goal
   âœ… "App Storeä¸Šæ¶è®¡åˆ’" - Specific, captures the main theme (if not a generic task list)
   âœ… "è¿ˆå‘æ–°ç›®æ ‡" - Meaningful, captures the essence

Style Guidelines:
- **For English**: Natural, fluent, native-sounding. Prioritize authenticity over preserving awkward phrasing.
- **For Chinese**: Natural, warm, authentic. Don't over-edit.
- **For all**: Keep the emotional tone and diary-like feel.

Response format (JSON only):
{{
  "title": "Title in the EXACT SAME LANGUAGE as the user's primary input (Chinese or English only - MUST match user's language)",
  "polished_content": "fixed text, preserving original language AND original formatting (line breaks/lists) - MUST include all original content"
}}

ğŸš¨ CRITICAL EXAMPLES - Study these carefully:

Example 1 (User writes in Chinese - Title MUST be Chinese):
Input: "æˆ‘å…ˆè¯•ä¸€ä¸‹è¯­éŸ³è¾“å…¥ï¼Œç°åœ¨æ€ä¹ˆæ ·ã€‚å“å‘€ï¼Œå°±æ˜¯æœ‰ç‚¹å¤±è½ï¼Œå› ä¸ºæ˜æ˜åº”è¯¥æ—©ç‚¹ç¡çš„ã€‚"
Output: {{"title": "å¤±çœ çš„å¤œæ™š", "polished_content": "æˆ‘å…ˆè¯•ä¸€ä¸‹è¯­éŸ³è¾“å…¥ï¼Œç°åœ¨æ€ä¹ˆæ ·ã€‚å“å‘€ï¼Œå°±æ˜¯æœ‰ç‚¹å¤±è½ï¼Œå› ä¸ºæ˜æ˜åº”è¯¥æ—©ç‚¹ç¡çš„ã€‚"}}
âŒ WRONG: {{"title": "Reflections on Sleepless Nights"}} - This is English, but user wrote in Chinese!

Example 2 (User writes in English - Title MUST be English):
Input: "today was good i went to park and saw many flowers"
Output: {{"title": "A Day at the Park", "polished_content": "Today was good. I went to the park and saw many flowers."}}
âŒ WRONG: {{"title": "å…¬å›­ä¸€æ—¥"}} - This is Chinese, but user wrote in English!

Example 3 (User writes in Chinese with some English words - Title MUST be Chinese):
Input: "ä»Šå¤©å»äº†parkï¼Œçœ‹åˆ°äº†å¾ˆå¤šflowersï¼Œå¿ƒæƒ…å¾ˆå¥½"
Output: {{"title": "å…¬å›­é‡Œçš„èŠ±", "polished_content": "ä»Šå¤©å»äº†parkï¼Œçœ‹åˆ°äº†å¾ˆå¤šflowersï¼Œå¿ƒæƒ…å¾ˆå¥½ã€‚"}}
âœ… CORRECT: Title is in Chinese because user's primary language is Chinese

Example 4 (User writes in English with some Chinese words - Title MUST be English):
Input: "I went to å…¬å›­ today and saw many èŠ±"
Output: {{"title": "A Visit to the Park", "polished_content": "I went to å…¬å›­ today and saw many èŠ±."}}
âœ… CORRECT: Title is in English because user's primary language is English"""

            # æ„å»ºç”¨æˆ·æ¶ˆæ¯å†…å®¹
            user_content = []
            
            # å¦‚æœæœ‰å›¾ç‰‡ï¼Œæ·»åŠ å›¾ç‰‡åˆ°æ¶ˆæ¯ä¸­ï¼ˆä½¿ç”¨visionèƒ½åŠ›ï¼‰
            if encoded_images and len(encoded_images) > 0:
                print(f"ğŸ–¼ï¸ æ·»åŠ  {len(encoded_images)} å¼ å›¾ç‰‡åˆ° Vision è¯·æ±‚ (Low-res æ¨¡å¼)...")
                for image_data in encoded_images:
                    user_content.append({
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{image_data}",
                            "detail": "low"  # âœ… ä½¿ç”¨ä½åˆ†è¾¨ç‡æ¨¡å¼ï¼Œå¤„ç†æ›´å¿«ä¸”æ›´çœé’±
                        }
                    })
                
                # æ·»åŠ æ–‡å­—å†…å®¹
                user_content.append({
                    "type": "text",
                    "text": f"Please polish this diary entry (preserve ALL content) and create a title. Consider both the images and the text:\n\n{text}"
                })
                user_prompt = user_content
            else:
                # åªæœ‰æ–‡å­—ï¼Œä½¿ç”¨çº¯æ–‡æœ¬
                user_prompt = f"Please polish this diary entry (preserve ALL content):\n\n{text}"
            
            # âœ… åŠ¨æ€è®¡ç®— max_tokensï¼šç¡®ä¿è¶³å¤Ÿè¾“å‡ºå®Œæ•´å†…å®¹
            # åŸå§‹æ–‡æœ¬é•¿åº¦ + æ ‡é¢˜ + JSON æ ¼å¼å¼€é”€ + å®‰å…¨è¾¹è·
            original_length = len(text)
            # å¦‚æœæœ‰å›¾ç‰‡ï¼Œéœ€è¦é¢å¤–çš„tokensï¼ˆæ¯å¼ å›¾ç‰‡çº¦85 tokensï¼‰
            image_tokens = len(encoded_images) * 85 if encoded_images else 0
            # ä¼°ç®—ï¼šåŸå§‹æ–‡æœ¬ * 1.15ï¼ˆ115%é™åˆ¶ï¼‰ + æ ‡é¢˜ï¼ˆ50å­—ç¬¦ï¼‰ + JSONæ ¼å¼ï¼ˆ100å­—ç¬¦ï¼‰ + å®‰å…¨è¾¹è·ï¼ˆ500å­—ç¬¦ï¼‰
            estimated_output_length = int(original_length * 1.15) + 50 + 100 + 500
            # max_tokens å¤§çº¦æ˜¯å­—ç¬¦æ•°çš„ 0.75ï¼ˆä¸­æ–‡ï¼‰åˆ° 1.5ï¼ˆè‹±æ–‡ï¼‰ï¼Œå–ä¸­é—´å€¼ 1.0
            max_tokens = max(2000, int(estimated_output_length * 1.0) + image_tokens)
            # ä½†ä¸è¦è¶…è¿‡ OpenAI çš„é™åˆ¶ï¼ˆGPT-4o-mini æ”¯æŒ 16384 tokensï¼‰
            max_tokens = min(max_tokens, 16000)
            
            print(f"ğŸ“¤ GPT-4o-mini: å‘é€è¯·æ±‚åˆ° OpenAI...")
            print(f"   æ¨¡å‹: {self.MODEL_CONFIG['polish']}")
            print(f"   åŸå§‹æ–‡æœ¬é•¿åº¦: {original_length} å­—ç¬¦")
            print(f"   å›¾ç‰‡æ•°é‡: {len(encoded_images) if encoded_images else 0}")
            print(f"   ä¼°ç®—è¾“å‡ºé•¿åº¦: {estimated_output_length} å­—ç¬¦")
            print(f"   è®¾ç½® max_tokens: {max_tokens}")
            
            # æ„å»ºæ¶ˆæ¯
            if encoded_images and len(encoded_images) > 0:
                # ä½¿ç”¨visionæ ¼å¼ï¼ˆåŒ…å«å›¾ç‰‡ï¼‰
                messages = [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ]
            else:
                # çº¯æ–‡æœ¬æ ¼å¼
                messages = [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ]
            
            # âœ… Phase 1.1 + 1.4: ä½¿ç”¨ AsyncOpenAI + é‡è¯•æœºåˆ¶
            response = await self._call_gpt4o_with_retry(
                model=self.MODEL_CONFIG["polish"],
                messages=messages,
                temperature=0.3,
                max_tokens=max_tokens,
                response_format={"type": "json_object"}  # å¼ºåˆ¶ JSON æ ¼å¼
            )
            
            # è§£æå“åº”
            content = response.choices[0].message.content
            if not content:
                raise ValueError("OpenAI è¿”å›ç©ºå“åº”")
            
            print(f"âœ… GPT-4o-mini: æ”¶åˆ°å“åº”")
            print(f"ğŸ“ GPT-4o-mini: å“åº”å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
            
            # è§£æ JSON
            try:
                result = json.loads(content)
                polished_content = result.get("polished_content", text)
                
                # âœ… æ·»åŠ é•¿åº¦å¯¹æ¯”æ—¥å¿—ï¼Œæ£€æŸ¥æ˜¯å¦è¢«æˆªæ–­
                original_length = len(text)
                polished_length = len(polished_content)
                length_ratio = polished_length / original_length if original_length > 0 else 0
                
                print(f"âœ… GPT-4o-mini: æ¶¦è‰²å®Œæˆ")
                print(f"ğŸ“Š é•¿åº¦å¯¹æ¯”: åŸå§‹={original_length} å­—ç¬¦, æ¶¦è‰²å={polished_length} å­—ç¬¦, æ¯”ä¾‹={length_ratio:.2%}")
                
                # âš ï¸ å¦‚æœæ¶¦è‰²åå†…å®¹æ˜æ˜¾å°‘äºåŸå§‹å†…å®¹ï¼ˆå°äº80%ï¼‰ï¼Œå¯èƒ½æ˜¯è¢«æˆªæ–­äº†
                if polished_length < original_length * 0.8:
                    print(f"âš ï¸ è­¦å‘Šï¼šæ¶¦è‰²åå†…å®¹æ˜æ˜¾å°‘äºåŸå§‹å†…å®¹ï¼Œå¯èƒ½è¢«æˆªæ–­ï¼")
                    print(f"   åŸå§‹å†…å®¹å‰100å­—ç¬¦: {text[:100]}...")
                    print(f"   æ¶¦è‰²åå†…å®¹å‰100å­—ç¬¦: {polished_content[:100]}...")
                    # å¦‚æœç¡®å®è¢«æˆªæ–­ï¼Œä½¿ç”¨åŸå§‹å†…å®¹ä½œä¸ºé™çº§æ–¹æ¡ˆ
                    polished_content = text
                    print(f"   ä½¿ç”¨åŸå§‹å†…å®¹ä½œä¸ºé™çº§æ–¹æ¡ˆ")
                
                return {
                    "title": result.get("title", "Today's Reflection"),
                    "polished_content": polished_content
                }
            except json.JSONDecodeError as e:
                print(f"âš ï¸ GPT-4o-mini: JSON è§£æå¤±è´¥: {e}")
                print(f"   åŸå§‹å“åº”: {content[:200]}...")
                # å°è¯•ä»æ–‡æœ¬ä¸­æå– JSON
                json_match = re.search(r'\{.*?"title".*?"polished_content".*?\}', content, re.DOTALL)
                if json_match:
                    try:
                        result = json.loads(json_match.group())
                        return {
                            "title": result.get("title", "Today's Reflection"),
                            "polished_content": result.get("polished_content", text)
                        }
                    except:
                        pass
                
                # é™çº§æ–¹æ¡ˆ
                print(f"âš ï¸ GPT-4o-mini: ä½¿ç”¨é™çº§æ–¹æ¡ˆ")
                return {
                    "title": "Today's Reflection" if language == "English" else "ä»Šæ—¥è®°å½•",
                    "polished_content": text
                }
        
        except Exception as e:
            error_type = type(e).__name__
            error_msg = str(e)
            print(f"âŒ GPT-4o-mini è°ƒç”¨å¤±è´¥: {error_type}: {error_msg}")
            
            # è¯¦ç»†é”™è¯¯ä¿¡æ¯
            error_trace = traceback.format_exc()
            print(f"ğŸ“ GPT-4o-mini å®Œæ•´é”™è¯¯å †æ ˆ:")
            print(error_trace)
            
            # æ£€æŸ¥å¸¸è§é”™è¯¯ç±»å‹
            if "RateLimitError" in error_type or "rate_limit" in error_msg.lower():
                print(f"âš ï¸ OpenAI API é™æµ: è¯·æ±‚é¢‘ç‡è¿‡é«˜")
                print(f"ğŸ’¡ å»ºè®®: ç¨åé‡è¯•ï¼Œæˆ–æ£€æŸ¥ OpenAI è´¦æˆ·çš„é…é¢é™åˆ¶")
            elif "AuthenticationError" in error_type or "InvalidApiKey" in error_type:
                print(f"âš ï¸ OpenAI API Key é”™è¯¯: è¯·æ£€æŸ¥ OPENAI_API_KEY ç¯å¢ƒå˜é‡")
            elif "APIConnectionError" in error_type:
                print(f"âš ï¸ OpenAI API è¿æ¥é”™è¯¯: è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
            
            # é™çº§æ–¹æ¡ˆ
            return {
                "title": "Today's Reflection" if language == "English" else "ä»Šæ—¥è®°å½•",
                "polished_content": text
            }
    
    # ========================================================================
    # ğŸ”¥ GPT-4o-mini è°ƒç”¨ï¼ˆAI åé¦ˆï¼‰
    # ========================================================================
    
    async def _call_gpt4o_for_feedback(
        self, 
        text: str,
        language: str,
        user_name: Optional[str] = None,
        encoded_images: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """
        è°ƒç”¨ GPT-4o ç”Ÿæˆæ¸©æš–çš„ AI åé¦ˆ + æƒ…ç»ªåˆ†æ
        
        æ³¨ï¼šè™½ç„¶å‡½æ•°åæ›¾å« _call_gpt4o_mini_for_feedbackï¼Œç°åœ¨å·²å‡çº§ä¸º gpt-4o ä»¥ç¡®ä¿æƒ…ç»ªæ„ŸçŸ¥çš„å‡†ç¡®æ€§ã€‚
        
        è¿”å›:
            {
                "reply": "æ¸©æš–çš„åé¦ˆæ–‡å­—",
                "emotion": "Joyful",
                "confidence": 0.9,
                "rationale": "åˆ†æç†ç”±..."
            }
        """
        try:
            print(f"ğŸ’¬ GPT-4o: å¼€å§‹ç”Ÿæˆåé¦ˆ + æƒ…ç»ªåˆ†æ...")
            print(f"ğŸ‘¤ ç”¨æˆ·åå­—: {user_name if user_name else 'æœªæä¾›'}")
            
            # è®¡ç®—ç”¨æˆ·è¾“å…¥é•¿åº¦ï¼Œç”¨äºåŠ¨æ€è°ƒæ•´åé¦ˆé•¿åº¦
            user_text_length = len(text.strip())
            max_feedback_length = max(user_text_length, 20 if language == "Chinese" else 15)
            
            # æ„å»ºç»Ÿä¸€çš„ç³»ç»Ÿæç¤ºè¯
            # æƒ…ç»ªåˆ—è¡¨ï¼šä¸å‰ç«¯ EmotionType ä¿æŒä¸¥æ ¼ä¸€è‡´ï¼ˆ2026-01-10 æ›´æ–° v4 - æ‰©å±•åˆ°23ä¸ªæƒ…ç»ªï¼ŒReflectiveæ‹†åˆ†ä¸ºThoughtfulå’ŒReflectiveï¼‰
            # Joyful, Grateful, Fulfilled, Proud, Surprised, Excited, Peaceful, Hopeful,
            # Reflective, Intentional, Inspired, Curious, Nostalgic, Calm,
            # Uncertain, Misunderstood, Lonely, Down, Anxious, Overwhelmed, Venting, Frustrated
            system_prompt = f"""You are a warm, empathetic listener AND an expert emotion analyst.

LANGUAGE RULES:
1. Detect and Follow: Respond in THE SAME LANGUAGE as the user's input.
2. Fallback: If input is empty/images only, respond in {language}.
3. Consistency: NEVER translate. Match the emotional tone.

âš ï¸ CRITICAL RULES FOR REPLY:
1. **NEVER ask questions**: Do not ask "How are you?" or "What's on your mind?".
2. **Warm Listener**: Acknowledge their feelings with warmth and resonance.
3. **Short and Powerful**: 1-2 sentences. Concise.
4. **Greeting**: {"Start response with '" + user_name + (", " if language == "English" else "ï¼Œ") + "'." if user_name else "Start directly."}

ğŸ“Š EMOTION ANALYSIS RULES:
Analyze the user's emotion from the text/images and choose ONE from this STRICT list (23 emotions):
[Joyful, Grateful, Fulfilled, Proud, Surprised, Excited, Peaceful, Hopeful, Thoughtful, Reflective, Intentional, Inspired, Curious, Nostalgic, Calm, Uncertain, Misunderstood, Lonely, Down, Anxious, Overwhelmed, Venting, Frustrated]

ğŸ¯ Detailed Usage Guide:

**ğŸŒŸ Positive Emotions (8) - é«˜èƒ½é‡/æ­£å‘:**

- **Joyful (å–œæ‚¦)**: Pure happiness, celebration, good things happening. User expresses excitement, delight, or joy.
  Examples: "Had so much fun today!", "Laughed until my stomach hurt", "ä»Šå¤©å¤ªå¼€å¿ƒäº†"

- **Grateful (æ„Ÿæ©)**: Thankfulness towards people, events, or things. Core of gratitude journaling.
  Examples: "So thankful for my friend's help", "Grateful for this moment", "æ„Ÿè°¢å®¶äººçš„æ”¯æŒ"

- **Fulfilled (å……å®)**: âœ¨ NEW - Sense of accomplishment, achievement, productive satisfaction. Completing goals, getting results.
  Examples: "Completed my project!", "Learned a new skill today", "å®Œæˆäº†å¤§é¡¹ç›®ï¼Œå¾ˆæœ‰æˆå°±æ„Ÿ"
  Keywords: "å®Œæˆ", "è¾¾æˆ", "å®ç°", "æˆå°±", "æ”¶è·", "accomplished", "achieved", "completed"
  
- **Proud (æ¬£æ…°)**: Feeling pleased about personal growth or others' progress. For self or others.
  Examples: "My child made progress", "Overcame a challenge", "å­©å­è¿›æ­¥äº†ï¼Œå¾ˆæ¬£æ…°"
  NOTE: Use sparingly; default to Fulfilled for routine accomplishments.

- **Surprised (æƒŠå–œ)**: âœ¨ NEW - Unexpected joy, pleasant surprise, serendipity. Unplanned good things.
  Examples: "Received an unexpected gift!", "Ran into an old friend", "æ²¡æƒ³åˆ°ä¼šæ”¶åˆ°è¿™ä»½ç¤¼ç‰©"
  Keywords: "æ„å¤–", "æƒŠå–œ", "æ²¡æƒ³åˆ°", "çªç„¶", "unexpected", "surprise", "serendipity"

- **Excited (æœŸå¾…)**: âœ¨ NEW - Anticipation, looking forward to something, energized about future.
  Examples: "Can't wait for the trip!", "Starting a new project tomorrow", "å¥½æœŸå¾…æ˜å¤©çš„æ´»åŠ¨"
  Keywords: "æœŸå¾…", "ç­‰å¾…", "å³å°†", "é©¬ä¸Š", "looking forward", "can't wait", "excited about"

- **Peaceful (å¹³é™)**: Inner calm, tranquility, relaxation. No turmoil.
  Examples: "Meditated by the lake", "Quiet evening at home", "å†…å¿ƒå¾ˆå¹³é™"

- **Hopeful (å¸Œæœ›)**: âœ¨ NEW - Optimism about the future, seeing light in darkness, believing things will improve.
  Examples: "Things will get better", "Saw a glimmer of hope", "ç›¸ä¿¡æ˜å¤©ä¼šæ›´å¥½"
  Keywords: "å¸Œæœ›", "ç›¸ä¿¡", "ä¼šå¥½", "æ›™å…‰", "hope", "believe", "will get better"

**ğŸ§˜ Neutral/Constructive Emotions (7) - ç¨³æ€/å»ºè®¾æ€§:**

- **Thoughtful (è‹¥æœ‰æ‰€æ€)**: ğŸ”¥ **DEFAULT for general thinking/recording**. Pondering, considering, thinking things through. Most common neutral state for daily journaling.
  Examples: "Thinking about today", "Just recording my thoughts", "åœ¨æƒ³ä¸è®°å½•"
  Keywords: "åœ¨æƒ³", "è®°å½•", "æ€è€ƒ", "æƒ³ç€", "thoughtful", "pondering", "considering"
  NOTE: Use Thoughtful as the default neutral emotion when user is simply thinking or recording without strong emotional state.

- **Reflective (å†…çœ)**: Deep self-reflection, insights, understanding experiences and motivations. Deeper contemplation than Thoughtful.
  Examples: "Realized something important today", "Deep reflection on my life", "æ·±åº¦åæ€è‡ªå·±çš„ç»å†"
  Keywords: "æ„Ÿæ‚Ÿ", "åæ€", "å†…çœ", "æ·±åº¦", "realized", "reflection", "insights", "deep thoughts"

- **Intentional (ç¬ƒå®š)**: ğŸ”¥ **HIGHEST PRIORITY for planning content**. Goal-setting, planning, creating to-do lists.
  **MANDATORY KEYWORDS**: "è®¡åˆ’", "æ‰“ç®—", "æƒ³è¦", "è¦åš", "ç›®æ ‡", "å‡†å¤‡", "å®‰æ’", "æ›´æ–°", "plan", "goal", "to-do", "will do", "want to", "update"
  **If ANY of these keywords appear â†’ MUST choose Intentional**
  Examples: "ä»Šå¤©æˆ‘æƒ³è¦æŠŠè¿™ä¸ªäº§å“æ›´æ–°åˆ°App Store", "äº§å“æ›´æ–°è®¡åˆ’"

- **Inspired (å¯è¿ª)**: ğŸ”¥ **HIGHEST PRIORITY for learning content**. Recording learning notes, new knowledge, insights.
  **MANDATORY KEYWORDS**: "å­¦åˆ°", "å­¦ä¹ ", "å‘ç°", "äº†è§£åˆ°", "è®¤è¯†åˆ°", "æ–°çŸ¥", "è§‚ç‚¹", "å¯å‘", "learn", "discover", "realize", "insight", "knowledge", "phrase", "concept"
  **If ANY of these keywords appear â†’ MUST choose Inspired**
  Examples: "Today, I learned a new phrase", "ä»Šå¤©å­¦åˆ°ä¸€ä¸ªæ¦‚å¿µ"

- **Curious (å¥½å¥‡)**: âœ¨ NEW - Interested in exploring, desire to learn, wondering about something.
  Examples: "Want to try something new", "Curious about this topic", "å¯¹è¿™ä¸ªå¾ˆå¥½å¥‡"
  Keywords: "å¥½å¥‡", "æƒ³çŸ¥é“", "æ¢ç´¢", "å°è¯•", "curious", "wonder", "explore", "try"

- **Nostalgic (æ€€å¿µ)**: âœ¨ NEW - Reminiscing about the past, missing old times, sentimental memories.
  Examples: "Looking at old photos", "Missing childhood", "æƒ³èµ·äº†å°æ—¶å€™"
  Keywords: "æ€€å¿µ", "æƒ³èµ·", "å›å¿†", "è¿‡å»", "ä»¥å‰", "nostalgic", "remember", "miss", "old times"

- **Calm (æ·¡ç„¶)**: âœ¨ NEW - Accepting reality, letting go, equanimity. Not fighting, just accepting.
  Examples: "Let it be", "Accepting what is", "é¡ºå…¶è‡ªç„¶å§"
  Keywords: "æ·¡ç„¶", "é¡ºå…¶è‡ªç„¶", "æ¥å—", "æ”¾ä¸‹", "let go", "accept", "let it be"

**ğŸ˜” Negative/Release Emotions (7) - ä½èƒ½é‡/å®£æ³„:**

- **Uncertain (è¿·èŒ«)**: âœ¨ NEW - Self-doubt, lack of direction, confusion, not knowing what to do.
  Examples: "Don't know what to do", "Feeling lost", "ä¸çŸ¥é“è¯¥æ€ä¹ˆåŠ", "å¯¹è‡ªå·±æ²¡ä¿¡å¿ƒ"
  Keywords: "è¿·èŒ«", "ä¸çŸ¥é“", "å›°æƒ‘", "æ²¡æ–¹å‘", "æ€€ç–‘è‡ªå·±", "uncertain", "confused", "lost", "don't know"

- **Misunderstood (å§”å±ˆ)**: âœ¨ NEW - Feeling wronged, not understood, unappreciated. Efforts not seen.
  Examples: "No one understands me", "My efforts weren't seen", "æ²¡äººç†è§£æˆ‘çš„æƒ³æ³•"
  Keywords: "å§”å±ˆ", "ä¸è¢«ç†è§£", "è¯¯è§£", "ä¸å…¬å¹³", "misunderstood", "wronged", "not appreciated"

- **Lonely (å­¤ç‹¬)**: âœ¨ NEW - Lack of meaningful social connection, feeling isolated or alone. Missing companionship.
  Examples: "Feeling lonely in a new city", "Miss having someone to talk to", "ä¸€ä¸ªäººåœ¨å¼‚åœ°ï¼Œå¾ˆå­¤ç‹¬", "æ²¡äººé™ªä¼´"
  Keywords: "å­¤ç‹¬", "å­¤å•", "ä¸€ä¸ªäºº", "æ²¡äººé™ª", "æƒ³å¿µ", "lonely", "alone", "isolated", "miss company", "no one around"

- **Down (ä½è½)**: Sadness, feeling low, unhappy. General low mood.
  Examples: "Feeling sad today", "Not in a good mood", "å¿ƒæƒ…å¾ˆä½è½"

- **Anxious (ç„¦è™‘)**: Worry about the future, tension, pressure, nervousness.
  Examples: "Worried about the exam", "Nervous about the meeting", "å¾ˆç„¦è™‘"

- **Overwhelmed (ç–²æƒ«)**: âœ¨ NEW - Exhausted, burned out, too much to handle. Can't cope.
  Examples: "So tired", "Too much work", "å®Œå…¨ç´¯å®äº†", "å‹åŠ›å¤ªå¤§äº†"
  Keywords: "ç–²æƒ«", "ç´¯", "è€—ç«­", "ä¸å ªé‡è´Ÿ", "overwhelmed", "exhausted", "burned out", "too much"

- **Venting (å®£æ³„)**: Actively releasing anger, frustration, need to vent. Healthy emotional release.
  Examples: "So annoyed!", "Need to vent", "å¤ªçƒ¦äº†ï¼Œè¦åæ§½ä¸€ä¸‹"
  Keywords: "çƒ¦", "ç”Ÿæ°”", "åæ§½", "å‘æ³„", "annoyed", "frustrated", "venting", "letting it out"

- **Frustrated (å—æŒ«)**: âœ¨ NEW - Feeling blocked, plans failed, setbacks, things not working out.
  Examples: "Nothing is going right", "Plans fell through", "åŠªåŠ›äº†å¾ˆä¹…è¿˜æ˜¯æ²¡æˆåŠŸ"
  Keywords: "å—æŒ«", "å¤±è´¥", "ä¸é¡º", "é˜»ç¢", "frustrated", "setback", "didn't work", "blocked"

ğŸš¨ CRITICAL DISTINCTION RULES:

1. **Fulfilled vs Joyful**: Fulfilled = achievement/accomplishment, Joyful = pure happiness
2. **Surprised vs Excited**: Surprised = unexpected event (past), Excited = anticipation (future)
3. **Uncertain vs Down**: Uncertain = self-doubt/confusion, Down = general sadness
4. **Misunderstood vs Venting**: Misunderstood = feeling wronged, Venting = actively releasing anger
5. **Lonely vs Down**: Lonely = lack of connection/companionship, Down = general sadness
6. **Lonely vs Misunderstood**: Lonely = no one around, Misunderstood = people around but don't understand
7. **Overwhelmed vs Down**: Overwhelmed = exhausted/too much, Down = sad/low mood
8. **Frustrated vs Venting**: Frustrated = blocked/setback, Venting = releasing emotion
9. **Proud vs Fulfilled**: Proud = pleased about growth (self/others), Fulfilled = accomplished goals
10. **Thoughtful vs Reflective**: Thoughtful = general thinking/pondering (default neutral), Reflective = deep self-reflection with insights

ğŸš¨ CRITICAL EXAMPLES - STUDY THESE CAREFULLY:

1. "ä»Šå¤©å®Œæˆäº†ä¸€ä¸ªå¤§é¡¹ç›®ï¼Œå¾ˆæœ‰æˆå°±æ„Ÿï¼"
   â†’ **Fulfilled** âœ… (achievement, accomplishment)
   â†’ NOT Joyful âŒ (not pure happiness, it's about achievement)
   
2. "æ²¡æƒ³åˆ°ä¼šæ”¶åˆ°è¿™ä»½ç¤¼ç‰©ï¼Œå¤ªæƒŠå–œäº†ï¼"
   â†’ **Surprised** âœ… (unexpected, pleasant surprise)
   â†’ NOT Joyful âŒ (emphasis on unexpectedness)
   
3. "ä¸çŸ¥é“è¯¥æ€ä¹ˆåŠï¼Œå¾ˆè¿·èŒ«"
   â†’ **Uncertain** âœ… (self-doubt, lack of direction)
   â†’ NOT Down âŒ (not general sadness, specific confusion)
   
4. "æ²¡äººç†è§£æˆ‘çš„æƒ³æ³•ï¼Œå¾ˆå§”å±ˆ"
   â†’ **Misunderstood** âœ… (feeling wronged, not understood)
   â†’ NOT Venting âŒ (not actively releasing anger)
   
5. "ä»Šå¤©æˆ‘æƒ³è¦æŠŠè¿™ä¸ªäº§å“æ›´æ–°åˆ°App Store"
   â†’ **Intentional** âœ… (planning keywords: "æƒ³è¦", "æ›´æ–°")
   â†’ NOT Fulfilled âŒ (planning future, not completed yet)

Response format (JSON ONLY):
{{
  "reply": "Your warm response text here...",
  "emotion": "Selected Emotion from list",
  "confidence": 0.9,
  "rationale": "Short reason for analysis"
}}"""


            # æ„å»ºæ¶ˆæ¯
            user_content = []
            if encoded_images and len(encoded_images) > 0:
                for image_data in encoded_images:
                    user_content.append({
                        "type": "image_url",
                        "image_url": {"url": f"data:image/jpeg;base64,{image_data}", "detail": "low"}
                    })
                user_content.append({"type": "text", "text": f"Analyze emotion and respond to this (including images):\n\n{text}"})
                messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": user_content}]
            else:
                messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": f"Analyze emotion and respond to this:\n\n{text}"}]

            # å¢åŠ  max_tokens ä»¥å®¹çº³ JSON
            estimated_output_length = max_feedback_length + 200 
            max_tokens = max(300, min(estimated_output_length, 1000))

            # âœ… Phase 1.1 + 1.4: ä½¿ç”¨ AsyncOpenAI + é‡è¯•æœºåˆ¶
            response = await self._call_gpt4o_with_retry(
                model=self.MODEL_CONFIG["feedback"],  # gpt-4o for better empathy
                messages=messages,
                temperature=0.7,
                max_tokens=max_tokens,
                response_format={"type": "json_object"}
            )

            content = response.choices[0].message.content
            if not content:
                raise ValueError("OpenAI è¿”å›ç©ºå“åº”")

            try:
                result = json.loads(content)
                reply = result.get("reply", "").strip()
                emotion = result.get("emotion", "Reflective")
                
                # âœ… æ·»åŠ è°ƒè¯•æ—¥å¿—
                print(f"ğŸ” [DEBUG] åå­—å‰ç¼€æ£€æŸ¥:")
                print(f"   user_name å‚æ•°: '{user_name}'")
                print(f"   AI åŸå§‹å›å¤: '{reply}'")
                
                # åå­—å‰ç¼€æ£€æŸ¥
                if user_name and user_name.strip():
                    trimmed_reply = reply.lstrip()
                    if not trimmed_reply.lower().startswith(user_name.lower()):
                        has_cjk = bool(re.search(r'[\u4e00-\u9fff]', trimmed_reply))
                        separator = "ï¼Œ" if has_cjk else ", "
                        reply = f"{user_name}{separator}{trimmed_reply}"
                
                result["reply"] = reply
                print(f"âœ… åé¦ˆç”Ÿæˆ: {reply[:30]}... (Mood: {emotion})")
                return result
                
            except json.JSONDecodeError:
                print("âš ï¸ JSON è§£æå¤±è´¥ï¼Œå›é€€åˆ°çº¯æ–‡æœ¬å¤„ç†")
                return {
                    "reply": content.strip(),
                    "emotion": "Reflective", 
                    "confidence": 0.5,
                    "rationale": "Extracted from non-JSON response"
                }
        
        except Exception as e:
            print(f"âŒ åé¦ˆç”Ÿæˆå¤±è´¥: {e}")
            fallback_reply = "æ„Ÿè°¢åˆ†äº«ä½ çš„è¿™ä¸€åˆ»ã€‚" if language == "Chinese" else "Thanks for sharing this moment."
            
            # âœ… å³ä½¿åœ¨å¤±è´¥çš„æƒ…å†µä¸‹ï¼Œä¹Ÿå°½é‡å¸¦ä¸Šç”¨æˆ·åå­—
            if user_name and user_name.strip():
                separator = "ï¼Œ" if language == "Chinese" else ", "
                fallback_reply = f"{user_name}{separator}{fallback_reply}"
                
            return {
                "reply": fallback_reply,
                "emotion": "Reflective",
                "confidence": 0.0,
                "rationale": f"Fallback due to error: {str(e)}"
            }
    
    # ========================================================================
    # ğŸ”¥ æ–°å¢: ä¸“é—¨çš„æƒ…ç»ªåˆ†æAgent (Agent Orchestration æ¶æ„)
    # ========================================================================
    
    async def analyze_emotion_only(
        self,
        text: str,
        language: str,
        encoded_images: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """
        âœ… æ–°å¢: ä¸“é—¨çš„æƒ…ç»ªåˆ†æAgent
        
        èŒè´£: åªåšæƒ…ç»ªåˆ†æ,ä¸ç”Ÿæˆåé¦ˆ
        ä¼˜åŠ¿: 
        - Promptæ›´çŸ­ (300 tokens vs 1050 tokens)
        - æ›´ä¸“æ³¨,å‡†ç¡®åº¦æ›´é«˜
        - å¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„åˆ†æé€»è¾‘
        
        è¿”å›:
            {
                "emotion": "Fulfilled",
                "confidence": 0.92,
                "rationale": "ç”¨æˆ·å®Œæˆäº†é¡¹ç›®,è¡¨è¾¾äº†æˆå°±æ„Ÿå’Œæ»¡è¶³æ„Ÿ"
            }
        """
        try:
            print(f"ğŸ¯ Emotion Agent: å¼€å§‹ä¸“ä¸šæƒ…ç»ªåˆ†æ...")
            
            # âœ… Phase 1-3 ä¼˜åŒ–: å¯¹æ¯”è¡¨æ ¼ + è¾¹ç¼˜æ¡ˆä¾‹ + Few-Shot + æ¸©åº¦0.3 + gpt-4o
            system_prompt = f"""You are an expert emotion analyst specializing in psychological assessment.

Your ONLY task: Analyze the user's emotion from their text with MAXIMUM ACCURACY.

ğŸ¯ EMOTION CATEGORIES (24 emotions):

**Positive (9)**: Joyful, Grateful, Fulfilled, Proud, Surprised, Excited, Loved, Peaceful, Hopeful
**Neutral (7)**: Thoughtful, Reflective, Intentional, Inspired, Curious, Nostalgic, Calm
**Negative (8)**: Uncertain, Misunderstood, Lonely, Down, Anxious, Overwhelmed, Venting, Frustrated

ğŸ” EMOTION COMPARISON TABLE (Critical - Study Carefully):

| Emotion Pair | Key Difference | Example |
|--------------|----------------|---------|  
| **Fulfilled vs Joyful** | Fulfilled=Achievement, Joyful=Pure Happiness | "å®Œæˆé¡¹ç›®"â†’Fulfilled, "å’Œæœ‹å‹ç©"â†’Joyful |
| **Loved vs Grateful** | Loved=Feeling Cherished, Grateful=Thankfulness | "è¢«æ·±æ·±åœ°æŒ‚å¿µç€"â†’Loved, "æ„Ÿè°¢æœ‹å‹å¸®å¿™"â†’Grateful |
| **Anxious vs Overwhelmed** | Anxious=Worry future, Overwhelmed=Too much NOW | "æ‹…å¿ƒé¢è¯•"â†’Anxious, "å·¥ä½œå¤ªå¤š"â†’Overwhelmed |
| **Reflective vs Thoughtful** | Reflective=Looking back, Thoughtful=Pondering | "å›æƒ³å¾€äº‹"â†’Reflective, "åœ¨æƒ³é—®é¢˜"â†’Thoughtful |
| **Proud vs Fulfilled** | Proud=Pride, Fulfilled=Completion | "ä¸ºè‡ªå·±éª„å‚²"â†’Proud, "å®Œæˆç›®æ ‡"â†’Fulfilled |
| **Excited vs Hopeful** | Excited=Near future, Hopeful=Distant | "æ˜å¤©æ—…è¡Œ"â†’Excited, "å¸Œæœ›æœªæ¥"â†’Hopeful |
| **Down vs Frustrated** | Down=Sadness, Frustrated=Anger | "å¾ˆå¤±è½"â†’Down, "æ€»ä¸é¡º"â†’Frustrated |

ğŸ“‹ EDGE CASE HANDLING:

1. **Very Short Text** (<10 words):
   - Default "Thoughtful" (0.4-0.6)
   - Only specific emotion if keywords CRYSTAL CLEAR
   - Example: "ç´¯" â†’ Thoughtful (0.5), NOT Overwhelmed
   - Example: "è¶…çº§å¼€å¿ƒ" â†’ Joyful (0.8)

2. **Mixed Emotions**:
   - Choose DOMINANT (>60%)
   - No clear dominant â†’ "Reflective" (0.5-0.6)
   - Example: "å¼€å¿ƒä½†ç´¯" â†’ Joyful (0.6) if happiness dominates

3. **Neutral Recording**:
   - "ä»Šå¤©å»å…¬å›­" â†’ Thoughtful (0.5)
   - "è®°å½•ä¸€ä¸‹" â†’ Intentional (0.6)

ğŸ“Š CONFIDENCE SCORING (Detailed):

**0.9-1.0 (Very High):**
- Multiple EXPLICIT keywords
- Strong context, ZERO ambiguity
- Example: "è¶…çº§å¼€å¿ƒï¼Œç¬‘å¾—è‚šå­ç–¼" â†’ Joyful (0.95)

**0.7-0.9 (High):**
- Clear keywords, context supports
- Minor ambiguity
- Example: "å®Œæˆé¡¹ç›®ï¼Œæœ‰æˆå°±æ„Ÿ" â†’ Fulfilled (0.85)

**0.5-0.7 (Moderate):**
- Implicit emotion, context suggests
- Some ambiguity
- Example: "å¤©æ°”å¥½ï¼Œå»å…¬å›­" â†’ Peaceful (0.6)

**0.4-0.5 (Low):**
- Very ambiguous/neutral
- Default Thoughtful
- Example: "è®°å½•ä»Šå¤©" â†’ Thoughtful (0.45)

**<0.4: DO NOT USE** (use 0.4-0.5 instead)

ğŸ¯ KEY DEFINITIONS (Enhanced):

**Loved (è¢«çˆ±ç€)** - PRIORITY: RECEIVING love/care from others (PASSIVE)
- Keywords: "è¢«çˆ±", "è¢«çˆ±ç€", "æ„Ÿè§‰åˆ°çˆ±", "æ„Ÿå—åˆ°çˆ±", "è¢«å…³å¿ƒ", "è¢«æŒ‚å¿µ", "æ— æ¡ä»¶çš„çˆ±", "æ¸©æš–"
- ğŸ”¥ IF "è¢«çˆ±" OR "æ„Ÿè§‰åˆ°çˆ±" â†’ 95% is Loved, NOT Grateful!
- Example: "æ„Ÿè§‰åˆ°æ·±æ·±åœ°è¢«çˆ±" â†’ Loved âœ…

**Grateful (æ„Ÿæ©)** - EXPRESSING thanks for actions (ACTIVE)
- Keywords: "æ„Ÿè°¢", "æ„Ÿæ©", "è°¢è°¢", "grateful", "thankful"
- Example: "æ„Ÿè°¢æœ‹å‹çš„å¸®åŠ©" â†’ Grateful âœ…

**Fulfilled**: "å®Œæˆ","è¾¾æˆ","æˆå°±" | Achievement/Completion
**Joyful**: "å¼€å¿ƒ","å¿«ä¹","ç¬‘" | Pure Happiness (NOT achievement)
**Anxious**: "ç„¦è™‘","æ‹…å¿ƒ","ç´§å¼ " | Worry FUTURE
**Overwhelmed**: "å‹åŠ›å¤§","å´©æºƒ","æ’‘ä¸ä½" | Too much NOW
**Thoughtful**: DEFAULT when unclear
**Excited**: "æœŸå¾…","ç­‰å¾…" | Anticipation (near)
**Down**: "éš¾è¿‡","å¤±è½" | Sadness
**Proud**: "éª„å‚²","è‡ªè±ª" | Pride
**Reflective**: "å›æƒ³","å›é¡¾" | Looking back

ğŸ“š FEW-SHOT EXAMPLES:

1. "æ„Ÿè§‰åˆ°æ·±æ·±åœ°è¢«çˆ±ï¼Œçˆ¸çˆ¸ä¸€ç›´å…³å¿ƒæˆ‘" â†’ Loved (0.95)
   Rationale: "è¢«çˆ±"+"è¢«å…³å¿ƒ"=receiving love (PASSIVE), NOT expressing thanks

2. "ä»Šå¤©å®Œæˆäº†é¡¹ç›®ï¼Œç»ˆäºæ¾å£æ°”" â†’ Fulfilled (0.9)
   Rationale: "å®Œæˆ"=achievement, "æ¾å£æ°”"=relief

3. "å’Œæœ‹å‹èšä¼šï¼Œç¬‘å¾—è‚šå­ç–¼" â†’ Joyful (0.95)
   Rationale: "ç¬‘"+"èšä¼š"=pure happiness, NOT achievement

4. "æ„Ÿè°¢æœ‹å‹ä¸€ç›´é™ªä¼´æˆ‘" â†’ Grateful (0.85)
   Rationale: "æ„Ÿè°¢"=expressing thanks (ACTIVE), NOT receiving love

5. "æ˜å¤©é¢è¯•ï¼Œæœ‰ç‚¹ç´§å¼ " â†’ Anxious (0.85)
   Rationale: "ç´§å¼ "=worry about FUTURE event

6. "ä»Šå¤©å»äº†å…¬å›­" â†’ Thoughtful (0.5)
   Rationale: No emotion keywords, neutral recording

7. "å·¥ä½œå¤ªå¤šï¼Œå‹åŠ›å¤§ï¼Œè¦å´©æºƒ" â†’ Overwhelmed (0.95)
   Rationale: "å‹åŠ›å¤§"+"å´©æºƒ"=too much pressure NOW

8. "å®Œæˆä»»åŠ¡ï¼Œå¼€å¿ƒä½†ç´¯" â†’ Fulfilled (0.75)
   Rationale: "å®Œæˆ"=dominant (~70%), tired=minor

âš ï¸ CRITICAL RULES:
1. Choose MOST SPECIFIC emotion
2. Fulfilledâ‰ Joyful, Anxiousâ‰ Overwhelmed
3. When doubt â†’ Thoughtful (0.4-0.6)
4. Keywords + Context (both matter)
5. Short text â†’ conservative
6. Mixed â†’ choose dominant (>60%)

Response Format (JSON):
{{
    "emotion": "Fulfilled",
    "confidence": 0.92,
    "rationale": "ç”¨æˆ·å®Œæˆäº†é¡¹ç›®,æ˜ç¡®è¡¨è¾¾äº†æˆå°±æ„Ÿã€‚ä½¿ç”¨äº†'å®Œæˆ'è¿™ä¸ªå…³é”®è¯,ä¸”è¯­å¢ƒæ˜¯å·¥ä½œæˆæœ,å› æ­¤åˆ¤æ–­ä¸ºFulfilledè€ŒéJoyfulã€‚"
}}
"""

            # æ„å»ºæ¶ˆæ¯
            messages = [
                {"role": "system", "content": system_prompt}
            ]
            
            # æ„å»ºç”¨æˆ·æ¶ˆæ¯
            user_content = []
            
            # å¦‚æœæœ‰å›¾ç‰‡,æ·»åŠ å›¾ç‰‡
            if encoded_images and len(encoded_images) > 0:
                print(f"ğŸ–¼ï¸ æ·»åŠ  {len(encoded_images)} å¼ å›¾ç‰‡åˆ°æƒ…ç»ªåˆ†æ...")
                for image_data in encoded_images:
                    user_content.append({
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{image_data}",
                            "detail": "low"
                        }
                    })
                
                user_content.append({
                    "type": "text",
                    "text": f"è¯·åˆ†æä»¥ä¸‹å†…å®¹çš„æƒ…ç»ª(è€ƒè™‘å›¾ç‰‡å’Œæ–‡å­—):\\n\\n{text}"
                })
                user_prompt = user_content
            else:
                user_prompt = f"è¯·åˆ†æä»¥ä¸‹å†…å®¹çš„æƒ…ç»ª:\\n\\n{text}"
            
            messages.append({"role": "user", "content": user_prompt})
            
            # âœ… Phase 1.2 + 1.4: ä¿®å¤åŒæ­¥è°ƒç”¨ + æ·»åŠ é‡è¯•æœºåˆ¶
            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šä¹‹å‰è¿™é‡Œæ˜¯åŒæ­¥è°ƒç”¨ï¼Œä¼šé˜»å¡äº‹ä»¶å¾ªç¯ï¼
            response = await self._call_gpt4o_with_retry(
                model=self.MODEL_CONFIG["emotion"],  # ğŸ”¥ ä½¿ç”¨gpt-4o,å‡†ç¡®åº¦+10%
                messages=messages,
                temperature=0.3,  # â† é™ä½æ¸©åº¦,æé«˜ä¸€è‡´æ€§
                max_tokens=500,
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content)
            
            print(f"âœ… Emotion Agent åˆ†æå®Œæˆ:")
            print(f"   - æƒ…ç»ª: {result.get('emotion')}")
            print(f"   - ç½®ä¿¡åº¦: {result.get('confidence')}")
            print(f"   - ç†ç”±: {result.get('rationale')[:50]}...")
            
            return result
            
        except Exception as e:
            print(f"âŒ Emotion Agent å¤±è´¥: {str(e)}")
            # è¿”å›é»˜è®¤å€¼
            return {
                "emotion": "Thoughtful",
                "confidence": 0.5,
                "rationale": "åˆ†æå¤±è´¥,ä½¿ç”¨é»˜è®¤æƒ…ç»ª"
            }
    # ========================================================================
    # éªŒè¯å’Œé™çº§é€»è¾‘ï¼ˆä¿æŒä¸å˜ï¼‰
    # ========================================================================
    
    def _validate_and_fix_result(
        self, 
        result: Dict[str, str], 
        original_text: str
    ) -> Dict[str, str]:
        """
        éªŒè¯å¹¶ä¿®æ­£AIè¾“å‡º - è´¨é‡æŠŠå…³
        
        ğŸ”¥ æ³¨æ„ï¼šè¿™ä¸ªæ–¹æ³•å®Œå…¨ä¿æŒä¸å˜
        """
        
        orig_len = len(original_text.strip())
        
        # æ£€æµ‹è¯­è¨€
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', original_text))
        is_chinese = chinese_chars > len(original_text) * 0.2
        
        print(f"ğŸ“Š åŸæ–‡è¯­è¨€æ£€æµ‹: æ€»é•¿åº¦={len(original_text)}, ä¸­æ–‡å­—ç¬¦={chinese_chars}, åˆ¤å®š={'ä¸­æ–‡' if is_chinese else 'è‹±æ–‡'}")
        
        # æå–å„éƒ¨åˆ†
        title = (result.get("title", "") or "").strip()
        polished = (result.get("polished_content", "") or "").strip()
        feedback = (result.get("feedback", "") or "").strip()
        emotion_data = result.get("emotion_data", {"emotion": "Reflective"}) # âœ… ä¿ç•™æƒ…ç»ªæ•°æ®
        
        # ğŸ”¥ ä¼˜åŒ–ï¼šè¯­è¨€ä¸€è‡´æ€§éªŒè¯ - æ›´å®½å®¹çš„æ£€æµ‹é€»è¾‘
        title_has_chinese = bool(re.search(r'[\u4e00-\u9fff]', title))
        title_has_english = bool(re.search(r'[a-zA-Z]', title))
        feedback_has_chinese = bool(re.search(r'[\u4e00-\u9fff]', feedback))
        feedback_has_english = bool(re.search(r'[a-zA-Z]', feedback))
        
        used_fallback = False
        
        # ğŸ”¥ æ›´å®½å®¹çš„æ ‡é¢˜è¯­è¨€æ£€æŸ¥ï¼ˆåªåœ¨å®Œå…¨é”™è¯¯æ—¶æ‰fallbackï¼‰
        title_language_mismatch = False
        if is_chinese:
            # ç”¨æˆ·è¾“å…¥æ˜¯ä¸­æ–‡ï¼Œä½†æ ‡é¢˜100%æ˜¯è‹±æ–‡ï¼ˆæ²¡æœ‰ä¸€ä¸ªä¸­æ–‡å­—ç¬¦ï¼‰
            if not title_has_chinese and title_has_english and len(title) > 3:
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ··åˆè¯­è¨€ï¼ˆä¾‹å¦‚ï¼š"Project å®Œæˆ"ï¼‰
                # å¦‚æœæ ‡é¢˜ä¸­æœ‰è‡³å°‘ä¸€ä¸ªä¸­æ–‡å­—ç¬¦ï¼Œå°±è®¤ä¸ºæ˜¯æ­£å¸¸çš„
                title_language_mismatch = True
                print(f"âš ï¸ æ ‡é¢˜è¯­è¨€ä¸ä¸€è‡´ï¼ç”¨æˆ·è¾“å…¥æ˜¯ä¸­æ–‡ï¼Œä½†æ ‡é¢˜æ˜¯çº¯è‹±æ–‡: '{title}'")
        else:
            # ç”¨æˆ·è¾“å…¥æ˜¯è‹±æ–‡ï¼Œä½†æ ‡é¢˜100%æ˜¯ä¸­æ–‡ï¼ˆæ²¡æœ‰ä¸€ä¸ªè‹±æ–‡å­—ç¬¦ï¼‰
            if not title_has_english and title_has_chinese and len(title) > 3:
                title_language_mismatch = True
                print(f"âš ï¸ æ ‡é¢˜è¯­è¨€ä¸ä¸€è‡´ï¼ç”¨æˆ·è¾“å…¥æ˜¯è‹±æ–‡ï¼Œä½†æ ‡é¢˜æ˜¯çº¯ä¸­æ–‡: '{title}'")
        
        if title_language_mismatch:
            # ä½¿ç”¨é™çº§æ–¹æ¡ˆï¼Œç¡®ä¿è¯­è¨€ä¸€è‡´
            title = "ä»Šæ—¥è®°å½•" if is_chinese else "Today's Reflection"
            used_fallback = True
            print(f"âœ… å·²ä¿®æ­£æ ‡é¢˜ä¸º: '{title}'")
        
        # ğŸ”¥ ä¼˜åŒ–ï¼šåé¦ˆè¯­è¨€æ£€æŸ¥ - æ›´å®½å®¹çš„é€»è¾‘
        # åªæœ‰åœ¨åé¦ˆä¸åŸæ–‡è¯­è¨€å®Œå…¨ç›¸åæ—¶æ‰fallback
        feedback_language_mismatch = False
        if is_chinese:
            # ç”¨æˆ·æ˜¯ä¸­æ–‡ï¼Œä½†åé¦ˆæ˜¯çº¯è‹±æ–‡ï¼ˆæ²¡æœ‰ä¸€ä¸ªä¸­æ–‡å­—ç¬¦ï¼Œä½†æœ‰è‹±æ–‡ï¼‰
            if not feedback_has_chinese and feedback_has_english and len(feedback) > 10:
                feedback_language_mismatch = True
                print(f"âš ï¸ åé¦ˆè¯­è¨€ä¸ä¸€è‡´ï¼ç”¨æˆ·è¾“å…¥æ˜¯ä¸­æ–‡ï¼Œä½†åé¦ˆæ˜¯çº¯è‹±æ–‡: '{feedback[:50]}'")
        else:
            # ç”¨æˆ·æ˜¯è‹±æ–‡ï¼Œä½†åé¦ˆæ˜¯çº¯ä¸­æ–‡ï¼ˆæ²¡æœ‰ä¸€ä¸ªè‹±æ–‡å­—ç¬¦ï¼Œä½†æœ‰ä¸­æ–‡ï¼‰
            if not feedback_has_english and feedback_has_chinese and len(feedback) > 10:
                feedback_language_mismatch = True
                print(f"âš ï¸ åé¦ˆè¯­è¨€ä¸ä¸€è‡´ï¼ç”¨æˆ·è¾“å…¥æ˜¯è‹±æ–‡ï¼Œä½†åé¦ˆæ˜¯çº¯ä¸­æ–‡: '{feedback[:50]}'")
        
        if feedback_language_mismatch:
            print(f"âš ï¸ ä½¿ç”¨è¯­è¨€ä¸ä¸€è‡´ fallback")
            feedback = "æ„Ÿè°¢åˆ†äº«ä½ çš„è¿™ä¸€åˆ»ã€‚" if is_chinese else "Thanks for sharing this moment."
            # âœ… å³ä½¿æ˜¯ fallbackï¼Œä¹Ÿè¦åŠ ä¸Šç”¨æˆ·åå­—
            if user_name and user_name.strip():
                separator = "ï¼Œ" if is_chinese else ", "
                feedback = f"{user_name}{separator}{feedback}"
            used_fallback = True
        
        # æ¸…ç†å‡½æ•°
        def clean_text(text: str) -> str:
            text = re.sub(r'[\U0001F300-\U0001FAFF\U00002700-\U000027BF]+', '', text)
            text = text.replace('ï¼', 'ã€‚').replace('!', '.')
            text = re.sub(r'\s+', ' ', text).strip()
            return text

        def clean_text_preserve_formatting(
            text: str,
            is_chinese: bool,
            should_adjust_paragraphs: bool,
        ) -> str:
            """
            ä¿ç•™ç”¨æˆ·æ’ç‰ˆï¼ˆæ¢è¡Œ/åˆ—è¡¨ï¼‰ï¼Œåªåšè½»åº¦æ¸…ç†ã€‚
            """
            text = re.sub(r'[\U0001F300-\U0001FAFF\U00002700-\U000027BF]+', '', text)
            text = text.replace('ï¼', 'ã€‚').replace('!', '.')
            text = text.replace('\r\n', '\n').replace('\r', '\n')
            lines = text.split('\n')
            cleaned_lines = []
            bullet_pattern = re.compile(r'^(\s*)([-*â€¢]|\d+[.)])\s*(.*)$')
            for line in lines:
                if not line.strip():
                    cleaned_lines.append("")
                    continue
                bullet_match = bullet_pattern.match(line)
                if bullet_match:
                    indent, marker, content = bullet_match.groups()
                    content = re.sub(r'\s+', ' ', content).strip()
                    cleaned_lines.append(f"{indent}{marker} {content}".rstrip())
                else:
                    leading_ws = re.match(r'^\s*', line).group(0)
                    content = line[len(leading_ws):]
                    content = re.sub(r'\s+', ' ', content).strip()
                    cleaned_lines.append(f"{leading_ws}{content}".rstrip())
            cleaned = "\n".join(cleaned_lines).strip()

            if not should_adjust_paragraphs:
                return cleaned

            # å¦‚æœåŒ…å«åˆ—è¡¨ï¼Œé¿å…è‡ªåŠ¨åˆå¹¶æ®µè½
            for line in cleaned.split("\n"):
                if bullet_pattern.match(line):
                    return cleaned

            paragraphs = re.split(r"\n\s*\n+", cleaned)
            if len(paragraphs) <= 1:
                return cleaned

            def sentence_count(paragraph: str) -> int:
                if is_chinese:
                    matches = re.findall(r"[ã€‚ï¼ï¼Ÿ!?ï¼›;]", paragraph)
                else:
                    matches = re.findall(r"[.!?;]", paragraph)
                return max(1, len(matches))

            def merge_text(a: str, b: str) -> str:
                if not a:
                    return b
                if is_chinese:
                    sep = ""
                else:
                    sep = "" if a.endswith((" ", "\n")) else " "
                return f"{a.rstrip()}{sep}{b.lstrip()}"

            # âœ… é¦–æ®µè‡³å°‘åŒ…å«3å¥ï¼Œé¿å…ç¬¬ä¸€å¥åæ–­æ®µ
            while len(paragraphs) > 1 and sentence_count(paragraphs[0]) < 3:
                paragraphs[0] = merge_text(paragraphs[0], paragraphs[1])
                paragraphs.pop(1)

            # âœ… åˆå¹¶è¿‡çŸ­æ®µè½ï¼ˆé¿å…ç©ºç™½æ„Ÿï¼‰
            min_chars = 60 if is_chinese else 90
            i = 1
            while i < len(paragraphs):
                if sentence_count(paragraphs[i]) < 2 or len(paragraphs[i]) < min_chars:
                    paragraphs[i - 1] = merge_text(paragraphs[i - 1], paragraphs[i])
                    paragraphs.pop(i)
                else:
                    i += 1

            return "\n\n".join(p.strip() for p in paragraphs)
        
        def trim_to_complete_sentences(text: str, max_len: int) -> str:
            if len(text) <= max_len:
                return text

            sentence_pattern = r"([ã€‚ï¼ï¼Ÿ.!?])(['\"\"ã€ã€)]?)\s*"
            last_end = None

            for match in re.finditer(sentence_pattern, text):
                end_pos = match.end()
                if end_pos <= max_len:
                    last_end = end_pos
                else:
                    break

            if last_end is not None:
                return text[:last_end].rstrip()

            for punct in ['ã€‚', '.', 'ï¼', '!', 'ï¼Ÿ', '?', 'ï¼›', ';']:
                idx = text.rfind(punct, 0, max_len + 1)
                if idx > max_len * 0.5:
                    return text[:idx + 1].rstrip()
            return text[:max_len].rstrip()
        
        # ä¿®æ­£æ ‡é¢˜
        title = clean_text(title)
        title = re.sub(r'[^\w\u4e00-\u9fff\s-]', '', title)
        title = re.sub(r'\s+', ' ', title).strip()
        
        if len(title) < self.LENGTH_LIMITS["title_min"]:
            title = "Today's Reflection" if any(ord(c) < 128 for c in original_text) else "ä»Šæ—¥è®°å½•"
        elif len(title) > self.LENGTH_LIMITS["title_max"]:
            max_len = self.LENGTH_LIMITS["title_max"]
            if ' ' in title and len(title) > max_len:
                words = title[:max_len].rsplit(' ', 1)
                title = words[0] if len(words[0]) > max_len * 0.6 else title[:max_len]
            else:
                title = title[:max_len]
        
        # ä¿®æ­£æ¶¦è‰²å†…å®¹
        original_has_linebreaks = "\n" in original_text
        original_has_list = bool(re.search(r"(?m)^\s*([-*â€¢]|\d+[.)])\s+", original_text))
        should_adjust_paragraphs = not original_has_linebreaks and not original_has_list
        polished = clean_text_preserve_formatting(
            polished,
            is_chinese,
            should_adjust_paragraphs,
        )
        max_polished_len = int(orig_len * self.LENGTH_LIMITS["polished_ratio"])
        
        # âœ… æ·»åŠ é•¿åº¦æ£€æŸ¥æ—¥å¿—
        print(f"ğŸ“Š æ¶¦è‰²å†…å®¹éªŒè¯: åŸå§‹é•¿åº¦={orig_len}, æ¶¦è‰²åé•¿åº¦={len(polished)}, æœ€å¤§å…è®¸é•¿åº¦={max_polished_len}")
        
        # âš ï¸ å¦‚æœæ¶¦è‰²åå†…å®¹æ˜æ˜¾å°‘äºåŸå§‹å†…å®¹ï¼ˆå°äº80%ï¼‰ï¼Œå¯èƒ½æ˜¯è¢«æˆªæ–­äº†ï¼Œä½¿ç”¨åŸå§‹å†…å®¹
        if len(polished) < orig_len * 0.8:
            print(f"âš ï¸ è­¦å‘Šï¼šæ¶¦è‰²åå†…å®¹æ˜æ˜¾å°‘äºåŸå§‹å†…å®¹ï¼ˆ{len(polished)} < {orig_len * 0.8}ï¼‰ï¼Œä½¿ç”¨åŸå§‹å†…å®¹")
            polished = original_text.strip()
        
        # åªæœ‰åœ¨è¶…è¿‡æœ€å¤§é•¿åº¦æ—¶æ‰æˆªæ–­ï¼ˆä½†è¿™ç§æƒ…å†µä¸åº”è¯¥å‘ç”Ÿï¼Œå› ä¸ºæç¤ºè¯è¦æ±‚â‰¤115%ï¼‰
        if len(polished) > max_polished_len:
            print(f"âš ï¸ æ¶¦è‰²åå†…å®¹è¶…è¿‡æœ€å¤§é•¿åº¦ï¼ˆ{len(polished)} > {max_polished_len}ï¼‰ï¼ŒæŒ‰å®Œæ•´å¥å­æˆªæ–­")
            polished = trim_to_complete_sentences(polished, max_polished_len)
        
        # ä¿®æ­£åé¦ˆ
        feedback = clean_text(feedback)
        
        if not used_fallback and len(feedback) < self.LENGTH_LIMITS.get("feedback_min", 20):
            print(f"âš ï¸ åé¦ˆè¿‡çŸ­ï¼Œä½¿ç”¨é™çº§")
            feedback = "æ„Ÿè°¢åˆ†äº«ä½ çš„è¿™ä¸€åˆ»ã€‚" if is_chinese else "Thanks for sharing this moment."
            # âœ… å³ä½¿æ˜¯ fallbackï¼Œä¹Ÿè¦åŠ ä¸Šç”¨æˆ·åå­—
            if user_name and user_name.strip():
                separator = "ï¼Œ" if is_chinese else ", "
                feedback = f"{user_name}{separator}{feedback}"
        
        if len(feedback) > self.LENGTH_LIMITS["feedback_max"]:
            print(f"ğŸ“ åé¦ˆè¿‡é•¿ï¼ŒæŒ‰å®Œæ•´å¥å­æˆªæ–­")
            feedback = trim_to_complete_sentences(feedback, self.LENGTH_LIMITS["feedback_max"])
        
        is_english = any(ord(c) < 128 for c in original_text[:50])
        default_feedback = "Thank you for sharing." if is_english else "æ„Ÿè°¢åˆ†äº«ã€‚"
        
        return {
            "title": title,
            "polished_content": polished or original_text,
            "feedback": feedback or default_feedback,
            "emotion_data": emotion_data # âœ… è¿”å›æƒ…ç»ªæ•°æ®
        }
    
    def _create_fallback_result(self, text: str, user_name: str = None) -> Dict[str, Any]:
        """
        åˆ›å»ºé™çº§ç»“æœ
        """
        
        print(f"âš ï¸ ä½¿ç”¨é™çº§æ–¹æ¡ˆ (user_name={user_name})")
        
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
        is_chinese = chinese_chars > len(text) * 0.2
        
        feedback = "æ„Ÿè°¢åˆ†äº«ã€‚" if is_chinese else "Thanks for sharing."
        if user_name and user_name.strip():
            separator = "ï¼Œ" if is_chinese else ", "
            feedback = f"{user_name}{separator}{feedback}"

        return {
            "title": "ä»Šæ—¥è®°å½•" if is_chinese else "Today's Reflection",
            "polished_content": text,
            "feedback": feedback,
            "emotion_data": {"emotion": "Reflective", "confidence": 0.5} # âœ… é»˜è®¤æƒ…ç»ª
        }
    
    # ========================================================================
    # å‘åå…¼å®¹æ–¹æ³•ï¼ˆä¿æŒä¸å˜ï¼‰
    # ========================================================================
    
    def polish_text(self, text: str) -> str:
        """æ¶¦è‰²æ–‡æœ¬ï¼ˆæ—§APIï¼‰"""
        result = self.polish_content_multilingual(text)
        return result["polished_content"]
    
    def generate_feedback(self, diary_content: str) -> str:
        """ç”Ÿæˆåé¦ˆï¼ˆæ—§APIï¼‰"""
        result = self.polish_content_multilingual(diary_content)
        return result["feedback"]


    # ========================================================================
    # ğŸ”¥ å›¾ç‰‡ä¸‹è½½å’Œç¼–ç ï¼ˆç”¨äºVision APIï¼‰
    # ========================================================================
    
    async def _download_and_encode_image(self, image_url: str) -> str:
        """
        ä¸‹è½½å›¾ç‰‡å¹¶è½¬æ¢ä¸ºbase64ç¼–ç ï¼ˆç”¨äºOpenAI Vision APIï¼‰
        
        Args:
            image_url: å›¾ç‰‡çš„URLï¼ˆS3 URLæˆ–HTTP URLï¼‰
        
        Returns:
            base64ç¼–ç çš„å›¾ç‰‡æ•°æ®
        """
        try:
            print(f"ğŸ“¥ ä¸‹è½½å›¾ç‰‡: {image_url[:50]}...")
            
            # âœ… Phase 1.1: ä½¿ç”¨ httpx.AsyncClient å¼‚æ­¥ä¸‹è½½ï¼ˆæå‡æ€§èƒ½ï¼‰
            async with httpx.AsyncClient(timeout=10.0) as client:
                response = await client.get(image_url)
                response.raise_for_status()
            
            # è½¬æ¢ä¸ºbase64
            image_base64 = base64.b64encode(response.content).decode('utf-8')
            
            print(f"âœ… å›¾ç‰‡ä¸‹è½½å¹¶ç¼–ç å®Œæˆï¼Œå¤§å°: {len(image_base64)} å­—ç¬¦")
            return image_base64
            
        except Exception as e:
            print(f"âŒ ä¸‹è½½å›¾ç‰‡å¤±è´¥: {e}")
            raise

# ğŸ¯ ä½¿ç”¨ç¤ºä¾‹
"""
# 1. åˆå§‹åŒ–æœåŠ¡
service = OpenAIService()

# 2. è¯­éŸ³è½¬æ–‡å­—ï¼ˆWhisperï¼‰
text = await service.transcribe_audio(audio_bytes, "recording.m4a")

# 3. å¹¶è¡Œå¤„ç†ï¼šæ¶¦è‰²ï¼ˆpolishï¼‰+ æƒ…ç»ªåˆ†æï¼ˆemotionï¼‰+ åé¦ˆï¼ˆfeedbackï¼‰
result = await service.polish_content_multilingual(text)

# 4. ä½¿ç”¨ç»“æœ
print(f"æ ‡é¢˜: {result['title']}")        # gpt-4o-mini (polish) ç”Ÿæˆ
print(f"å†…å®¹: {result['polished_content']}")  # gpt-4o-mini (polish) æ¶¦è‰²
print(f"åé¦ˆ: {result['feedback']}")      # gpt-4o (feedback) ç”Ÿæˆ

# 5. å›¾ç‰‡+æ–‡å­—å¤„ç†ï¼ˆæ–°åŠŸèƒ½ï¼‰
result = await service.polish_content_multilingual(
    text="ä»Šå¤©å»äº†å…¬å›­",
    image_urls=["https://s3.../image1.jpg", "https://s3.../image2.jpg"]
)
"""
