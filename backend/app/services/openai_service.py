"""
AI æœåŠ¡ - æ··åˆæ¨¡å‹ä¼˜åŒ–ç‰ˆæœ¬
ä½œè€…çµæ„Ÿæ¥æºï¼šä¹”å¸ƒæ–¯çš„ç®€çº¦å“²å­¦ + å¼ å°é¾™çš„å…‹åˆ¶è®¾è®¡

ğŸ”¥ æœ€æ–°æ›´æ–°ï¼š
1. AI æš–å¿ƒåé¦ˆä» Claude Sonnet å›å½’ OpenAI GPT-4o-miniï¼ˆTestFlight éªŒè¯ç¨³å®šç‰ˆï¼‰
2. æ¶¦è‰² + æ ‡é¢˜ä¸åé¦ˆç»Ÿä¸€ä½¿ç”¨ GPT-4o-miniï¼ˆé™ä½ç»´æŠ¤æˆæœ¬ï¼‰
3. å¹¶è¡Œæ‰§è¡Œç­–ç•¥ä¿æŒä¸å˜ï¼Œæ€§èƒ½ç»§ç»­ç¨³å®š
4. Whisper è¯­éŸ³è½¬æ–‡å­—æŒç»­æ²¿ç”¨ï¼Œä¿è¯è¯†åˆ«å‡†ç¡®åº¦

æ ¸å¿ƒç†å¿µï¼š
1. ç®€å•ä½†ä¸ç®€é™‹ï¼ˆSimple but not simplisticï¼‰
2. å¼ºå¤§ä½†ä¸å¤æ‚ï¼ˆPowerful but not complicatedï¼‰
3. ä¼˜é›…ä½†ä¸ç‚«æŠ€ï¼ˆElegant but not showyï¼‰
"""

import tempfile
import os
import json
import asyncio  # ğŸ”¥ ç”¨äºå¹¶è¡Œæ‰§è¡Œ
from typing import Dict, Optional, List
from openai import OpenAI
import io
import base64
import requests

from ..config import get_settings


class OpenAIService:
    """
    AI æœåŠ¡ç±» - æ”¯æŒå¤šè¯­è¨€æ—¥è®°å¤„ç†
    
    è¿™ä¸ªç±»å°±åƒä¸€ä¸ªæ¸©æŸ”çš„æ—¥è®°åŠ©æ‰‹ï¼Œå®ƒä¼šï¼š
    1. å¬æ‡‚ä½ çš„å£°éŸ³ï¼ˆè¯­éŸ³è½¬æ–‡å­— - Whisperï¼‰
    2. ç¾åŒ–ä½ çš„æ–‡å­—ï¼ˆè½»åº¦æ¶¦è‰² - GPT-4o-miniï¼‰
    3. ç»™ä½ æ¸©æš–çš„å›åº”ï¼ˆå¿ƒç†é™ªä¼´ - GPT-4o-miniï¼‰
    4. å¸®ä½ èµ·ä¸ªå¥½æ ‡é¢˜ï¼ˆç”»é¾™ç‚¹ç› - GPT-4o-miniï¼‰
    
    ğŸ”¥ æ¨¡å‹é€‰æ‹©ç­–ç•¥ï¼š
    - Whisper: è¯­éŸ³è½¬æ–‡å­—ï¼ˆOpenAIï¼Œæ— å¯æ›¿ä»£ï¼‰
    - GPT-4o-mini: æ¶¦è‰² + æ ‡é¢˜ï¼ˆå¿«é€Ÿã€ç¨³å®šã€æˆæœ¬å¯æ§ï¼‰
    - GPT-4o-mini: AI åé¦ˆï¼ˆTestFlight å›å½’éªŒè¯æ›´ç¨³å®šï¼‰
    """
    
    # ğŸ¯ æ¨¡å‹é…ç½®
    MODEL_CONFIG = {
        # è¯­éŸ³è½¬æ–‡å­—ï¼ˆä¿æŒä¸å˜ï¼‰
        "transcription": "whisper-1",
        
        # ğŸ”¥ GPT æ¨¡å‹é…ç½®
        "haiku": "gpt-4o-mini",  # æ¶¦è‰² + æ ‡é¢˜ï¼ˆå‘½åæ²¿ç”¨æ—§å­—æ®µï¼Œä¾¿äºå…¼å®¹ï¼‰
        "sonnet": "gpt-4o-mini",  # AI æš–å¿ƒåé¦ˆï¼ˆå›å½’ OpenAI æ¨¡å‹ï¼‰
        
        # ğŸ¤ ä¸ºä»€ä¹ˆ Whisperï¼Ÿ
        # âœ… OpenAI å®˜æ–¹è¯­éŸ³è½¬æ–‡å­—æ¨¡å‹
        # âœ… æ”¯æŒ 100+ è¯­è¨€ï¼ˆä¸­è‹±æ–‡å®Œç¾ï¼‰
        # âœ… é«˜å‡†ç¡®åº¦ï¼Œä½å¹»è§‰ç‡
        
        # ğŸ¨ ä¸ºä»€ä¹ˆ Haiku æ¶¦è‰²ï¼Ÿ
        # âœ… é€Ÿåº¦å¿«ï¼ˆ1-2ç§’ï¼‰
        # âœ… ä¾¿å®œï¼ˆ$1/1M tokens inputï¼‰
        # âœ… è¶³å¤Ÿèªæ˜ï¼ˆæ—¥è®°æ¶¦è‰²ç»°ç»°æœ‰ä½™ï¼‰
        
        # ğŸ’¬ ä¸ºä»€ä¹ˆ GPT-4o-mini åé¦ˆï¼Ÿ
        # âœ… æ¸©æš–çœŸå®ï¼ˆå…¼é¡¾å…±æƒ…ä¸å®‰å…¨ï¼‰
        # âœ… å¤šè¯­è¨€èƒ½åŠ›å¼ºï¼ˆä¸­è‹±æ–‡éƒ½è‡ªç„¶ï¼‰
        # âœ… ä¸æ¶¦è‰²æ¨¡å‹ç»Ÿä¸€ï¼Œæ–¹ä¾¿ç»´æŠ¤
    }
    
    # ğŸ“ é•¿åº¦é™åˆ¶ï¼ˆä¿æŒä¸å˜ï¼‰
    LENGTH_LIMITS = {
        "title_min": 4,
        "title_max": 50,
        "feedback_min": 30,
        "feedback_max": 250,
        "polished_ratio": 1.15,
        "min_audio_text": 5,
    }
    
    def __init__(self):
        """åˆå§‹åŒ–æœåŠ¡å®¢æˆ·ç«¯"""
        settings = get_settings()
        
        # OpenAI å®¢æˆ·ç«¯ï¼ˆç”¨äº Whisperï¼‰
        self.openai_client = OpenAI(api_key=settings.openai_api_key)
        self.openai_api_key = settings.openai_api_key
        
        print(f"âœ… AI æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
        print(f"   - Whisper: è¯­éŸ³è½¬æ–‡å­—")
        print(f"   - GPT-4o-mini: æ¶¦è‰² + æ ‡é¢˜ (é…ç½®å­—æ®µ haiku)")
        print(f"   - GPT-4o-mini: AI åé¦ˆ (é…ç½®å­—æ®µ sonnet)")
    
    # ========================================================================
    # è¯­éŸ³è½¬æ–‡å­—ï¼ˆä¿æŒä¸å˜ï¼‰
    # ========================================================================
    
    async def transcribe_audio(
        self, 
        audio_content: bytes, 
        filename: str,
        expected_duration: Optional[int] = None
    ) -> str:
        """
        è¯­éŸ³è½¬æ–‡å­— - æŠŠä½ çš„å£°éŸ³å˜æˆæ–‡å­—
        
        ğŸ”¥ æ³¨æ„ï¼šè¿™ä¸ªæ–¹æ³•å®Œå…¨ä¸å˜ï¼Œç»§ç»­ä½¿ç”¨ Whisper
        
        å·¥ä½œæµç¨‹ï¼š
        1. æ”¶åˆ°éŸ³é¢‘ â†’ æ£€æŸ¥å¤§å°
        2. åˆ›å»ºä¸´æ—¶æ–‡ä»¶ â†’ ç¡®ä¿æ ¼å¼æ­£ç¡®
        3. å‘é€ç»™ Whisper â†’ å®ƒæ˜¯è¯­éŸ³è¯†åˆ«ä¸“å®¶
        4. æ£€æŸ¥ç»“æœ â†’ ç¡®ä¿ä¸æ˜¯ç©ºçš„
        5. æ¸…ç†ä¸´æ—¶æ–‡ä»¶ â†’ ä¿æŒæ•´æ´
        """
        temp_file_path = None
        
        try:
            # æ£€æŸ¥éŸ³é¢‘å¤§å°
            audio_size_kb = len(audio_content) / 1024
            print(f"ğŸ¤ æ”¶åˆ°éŸ³é¢‘: {filename}, å¤§å°: {audio_size_kb:.1f} KB")
            
            if audio_size_kb < 1:
                raise ValueError("éŸ³é¢‘æ–‡ä»¶å¤ªå°ï¼Œè¯·è¯´é•¿ä¸€ç‚¹")
            
            # å‡†å¤‡ä¸´æ—¶æ–‡ä»¶
            suffix = '.m4a' if not filename.endswith('.m4a') else ''
            with tempfile.NamedTemporaryFile(
                delete=False, 
                suffix=suffix or os.path.splitext(filename)[1]
            ) as temp_file:
                temp_file.write(audio_content)
                temp_file_path = temp_file.name
            
            print(f"âœ… ä¸´æ—¶æ–‡ä»¶å‡†å¤‡å®Œæˆ")
            
            # è°ƒç”¨ Whisper
            import httpx
            import io
            print("ğŸ“¤ æ­£åœ¨è¯†åˆ«è¯­éŸ³ï¼ˆverbose_json æ¨¡å¼ï¼‰...")
            response_json = None
            try:
                with httpx.Client(timeout=60.0) as client:
                    file_stream = io.BytesIO(audio_content)
                    response = client.post(
                        "https://api.openai.com/v1/audio/transcriptions",
                        headers={
                            "Authorization": f"Bearer {self.openai_api_key}",
                        },
                        data={
                            "model": self.MODEL_CONFIG["transcription"],
                            "language": "",
                            "temperature": "0",
                            "response_format": "verbose_json",
                        },
                        files={
                            "file": (filename or "recording.m4a", file_stream, "audio/m4a"),
                        },
                    )
                    response.raise_for_status()
                    response_json = response.json()
            except httpx.HTTPError as http_err:
                print(f"âŒ Whisper HTTP è¯·æ±‚å¤±è´¥: {http_err}")
                if http_err.response is not None:
                    print(f"ğŸ“„ Whisper å“åº”: {http_err.response.text[:200]}...")
                raise ValueError("è¯­éŸ³è¯†åˆ«å¤±è´¥: æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•")
            
            if not response_json:
                raise ValueError("è¯­éŸ³è¯†åˆ«å¤±è´¥: æœªæ”¶åˆ°æœ‰æ•ˆå“åº”")
            
            text = (response_json.get("text") or "").strip()
            segments = response_json.get("segments", []) or []
            
            import re
            normalized_text = re.sub(r"\s+", "", text)
            
            if len(normalized_text) < self.LENGTH_LIMITS["min_audio_text"]:
                print(f"âŒ è½¬å½•å†…å®¹è¿‡çŸ­: '{text}'")
                raise ValueError("æœªè¯†åˆ«åˆ°æœ‰æ•ˆå†…å®¹ï¼Œè¯·è¯´æ¸…æ¥šä¸€äº›")
            
            cleaned_text = re.sub(r"[^a-z0-9\u4e00-\u9fff\u3040-\u309f\u30a0-\u30ff]+", " ", text.lower()).strip()
            compact_text = cleaned_text.replace(" ", "")
            fallback_phrases = [
                "thank you for watching",
                "thanks for watching",
                "thank you so much for watching",
                "please subscribe",
                "don't forget to subscribe",
                "subscribe to my channel",
                "remember to subscribe",
                "leave a comment",
                "smash that like button",
                "that's it",
                "thats it",
                "that's all",
                "thats all",
            ]
            normalized_fallbacks = []
            for phrase in fallback_phrases:
                normalized_fallbacks.append(phrase)
                normalized_fallbacks.append(phrase.replace(" ", ""))
                normalized_fallbacks.append(phrase.replace("'", ""))
                normalized_fallbacks.append(phrase.replace(" ", "").replace("'", ""))
            if any(phrase in cleaned_text or phrase in compact_text for phrase in normalized_fallbacks):
                print(
                    "âŒ æ£€æµ‹åˆ°æ¨¡æ¿åŒ–å¡«å……è¯­å¥ï¼Œè§†ä¸ºæ— æ•ˆå†…å®¹:",
                    {"text": text, "cleaned": cleaned_text},
                )
                raise ValueError("æœªè¯†åˆ«åˆ°æœ‰æ•ˆå†…å®¹ï¼Œè¯·è¯´æ¸…æ¥šä¸€äº›")
            
            filler_tokens = {
                "um",
                "uh",
                "uhh",
                "hmm",
                "hmmm",
                "erm",
                "er",
                "ah",
                "oh",
                "mmm",
            }
            token_pattern = r"[A-Za-z\u4e00-\u9fff\u3040-\u309f\u30a0-\u30ff]+"
            tokens = re.findall(token_pattern, text)
            meaningful_tokens = [
                token
                for token in tokens
                if len(token) >= 2 and token.lower() not in filler_tokens
            ]
            
            unique_chars = len(set(normalized_text))
            if unique_chars <= 2 and len(normalized_text) > 2:
                print(
                    "âŒ è½¬å½•ç»“æœåŒ…å«å¤§é‡é‡å¤å­—ç¬¦ï¼Œè§†ä¸ºæ— æ•ˆ:",
                    {"text": text, "normalized": normalized_text},
                )
                raise ValueError("æœªè¯†åˆ«åˆ°æœ‰æ•ˆå†…å®¹ï¼Œè¯·è¯´æ¸…æ¥šä¸€äº›")
            
            # åˆ†æ Whisper æ®µç»“æœï¼Œç¡®è®¤æ˜¯å¦çœŸçš„æœ‰è®²è¯
            def _segment_value(segment, attr, default):
                if isinstance(segment, dict):
                    return segment.get(attr, default)
                return getattr(segment, attr, default)
            
            confident_segments = []
            total_confident_duration = 0.0
            total_segment_duration = 0.0
            avg_no_speech_sum = 0.0
            
            for segment in segments:
                try:
                    start = float(_segment_value(segment, "start", 0))
                    end = float(_segment_value(segment, "end", 0))
                    seg_duration = max(0.0, end - start)
                except (TypeError, ValueError):
                    seg_duration = 0.0
                    start = 0.0
                    end = 0.0
                
                total_segment_duration += seg_duration
                
                try:
                    no_speech_prob = float(_segment_value(segment, "no_speech_prob", 1))
                except (TypeError, ValueError):
                    no_speech_prob = 1
                
                try:
                    avg_logprob = float(_segment_value(segment, "avg_logprob", -10))
                except (TypeError, ValueError):
                    avg_logprob = -10
                
                avg_no_speech_sum += no_speech_prob * seg_duration
                
                if (
                    seg_duration >= 0.3
                    and no_speech_prob < 0.45
                    and avg_logprob > -0.75
                ):
                    confident_segments.append(segment)
                    total_confident_duration += seg_duration
            
            reference_duration = None
            if expected_duration and expected_duration > 0:
                reference_duration = float(expected_duration)
            elif total_segment_duration > 0:
                reference_duration = total_segment_duration
            else:
                reference_duration = None
            
            speech_ratio = (
                total_confident_duration / reference_duration
                if reference_duration and reference_duration > 0
                else None
            )
            
            avg_no_speech_prob = (
                avg_no_speech_sum / total_segment_duration
                if total_segment_duration > 0
                else 1.0
            )
            
            if reference_duration and reference_duration >= 6:
                if (speech_ratio is None or speech_ratio < 0.2) or total_confident_duration < 1.0:
                    print(
                        "âŒ æ£€æµ‹åˆ°æœ‰æ•ˆè¯­éŸ³è¿‡å°‘:",
                        {
                            "expected_duration": expected_duration,
                            "total_confident_duration": total_confident_duration,
                            "speech_ratio": speech_ratio,
                            "avg_no_speech_prob": avg_no_speech_prob,
                            "segments_count": len(segments),
                        },
                    )
                    raise ValueError("æœªè¯†åˆ«åˆ°æœ‰æ•ˆå†…å®¹ï¼Œè¯·è¯´æ¸…æ¥šä¸€äº›")
            
            # ä½¿ç”¨æ–‡æœ¬ä¸æ—¶é•¿çš„å…³ç³»åšè¿›ä¸€æ­¥æ ¡éªŒï¼ˆé˜²æ­¢å¹»è§‰ï¼‰
            if reference_duration and reference_duration >= 10:
                char_per_second = len(normalized_text) / reference_duration
                if char_per_second < 0.8:
                    print(
                        "âŒ æ–‡æœ¬ä¸éŸ³é¢‘æ—¶é•¿ä¸åŒ¹é…ï¼Œç–‘ä¼¼é™éŸ³å½•éŸ³:",
                        {
                            "text_length": len(normalized_text),
                            "reference_duration": reference_duration,
                            "char_per_second": char_per_second,
                        },
                    )
                    raise ValueError("æœªè¯†åˆ«åˆ°æœ‰æ•ˆå†…å®¹ï¼Œè¯·ç¨ä½œè¡¨è¾¾åå†è¯•")

            if reference_duration and len(meaningful_tokens) < 2:
                print(
                    "âŒ æœ‰æ•ˆè¯æ±‡æ•°é‡ä¸è¶³ï¼Œåˆ¤å®šä¸ºæ— æ„ä¹‰å†…å®¹:",
                    {
                        "tokens": tokens,
                        "meaningful_tokens": meaningful_tokens,
                        "duration": reference_duration,
                    },
                )
                raise ValueError("æœªè¯†åˆ«åˆ°æœ‰æ•ˆå†…å®¹ï¼Œè¯·ç¨ä½œè¡¨è¾¾åå†è¯•")
            
            print(f"âœ… è¯­éŸ³è¯†åˆ«æˆåŠŸ: '{text[:50]}...'")
            return text
            
        except Exception as e:
            print(f"âŒ è¯­éŸ³è½¬æ–‡å­—å¤±è´¥: {str(e)}")
            if "Invalid file format" in str(e):
                raise ValueError("éŸ³é¢‘æ ¼å¼ä¸æ”¯æŒï¼Œè¯·ä½¿ç”¨ m4a æ ¼å¼")
            elif "File too large" in str(e):
                raise ValueError("éŸ³é¢‘æ–‡ä»¶å¤ªå¤§ï¼Œè¯·æ§åˆ¶åœ¨ 2 åˆ†é’Ÿå†…")
            else:
                raise ValueError(f"è¯­éŸ³è¯†åˆ«å¤±è´¥: {str(e)}")
        
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if temp_file_path and os.path.exists(temp_file_path):
                try:
                    os.unlink(temp_file_path)
                    print(f"ğŸ§¹ ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†")
                except Exception as e:
                    print(f"âš ï¸ æ¸…ç†å¤±è´¥ï¼ˆä¸å½±å“åŠŸèƒ½ï¼‰: {e}")
    
    # ========================================================================
    # ğŸ”¥ æ ¸å¿ƒæ”¹åŠ¨ï¼šæ··åˆæ¨¡å‹å¤„ç†
    # ========================================================================
    
    async def polish_content_multilingual(
        self, 
        text: str,
        user_name: Optional[str] = None,  # ç”¨æˆ·åå­—ï¼Œç”¨äºä¸ªæ€§åŒ–åé¦ˆ
        image_urls: Optional[List[str]] = None  # å›¾ç‰‡URLåˆ—è¡¨ï¼Œç”¨äºvisionåˆ†æ
    ) -> Dict[str, str]:
        """
        ğŸ”¥ é‡å¤§æ”¹åŠ¨ï¼šä»å•ä¸€æ¨¡å‹æ”¹ä¸ºæ··åˆæ¨¡å‹ + å¹¶è¡Œæ‰§è¡Œ
        
        æ—§é€»è¾‘ï¼š
        1. GPT-4o-mini ä¸€æ¬¡æ€§ç”Ÿæˆæ¶¦è‰² + æ ‡é¢˜ + åé¦ˆï¼ˆä¸²è¡Œï¼Œ3-5ç§’ï¼‰
        
        æ–°é€»è¾‘ï¼š
        1. GPT-4o-mini ç”Ÿæˆæ¶¦è‰² + æ ‡é¢˜ï¼ˆå­—æ®µ haikuï¼Œ1-2ç§’ï¼‰
        2. GPT-4o-mini ç”Ÿæˆåé¦ˆï¼ˆå­—æ®µ sonnetï¼ŒåŸºäºåŸå§‹æ–‡æœ¬ï¼Œ2-3ç§’ï¼‰
        3. ä¸¤ä¸ªä»»åŠ¡å¹¶è¡Œæ‰§è¡Œï¼Œæ€»è€—æ—¶ = max(1-2, 2-3) = 2-3ç§’
        
        ä¸ºä»€ä¹ˆåŸºäºåŸå§‹æ–‡æœ¬ç”Ÿæˆåé¦ˆï¼Ÿ
        - æ›´çœŸå®ï¼šåŸå§‹æ–‡æœ¬ä¿ç•™äº†ç”¨æˆ·æœ€çœŸå®çš„æƒ…æ„Ÿ
        - æ›´å¿«ï¼šä¸éœ€è¦ç­‰æ¶¦è‰²å®Œæˆ
        - æ›´æ¸©æš–ï¼šAI å›åº”"çœŸå®çš„ä½ "è€Œä¸æ˜¯"å®Œç¾çš„æ–‡å­—"
        """
        try:
            # è¾“å…¥æ£€æŸ¥
            if not text or len(text.strip()) < 5:
                raise ValueError("å†…å®¹å¤ªçŸ­ï¼Œè¯·å¤šå†™ä¸€äº›")
            
            print(f"âœ¨ å¼€å§‹AIå¤„ç†ï¼ˆå¹¶è¡Œæ¨¡å¼ï¼‰: {text[:50]}...")
            
            # æ£€æµ‹è¯­è¨€
            import re
            chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
            is_chinese = chinese_chars > len(text) * 0.2
            detected_lang = "Chinese" if is_chinese else "English"
            
            print(f"ğŸŒ æ£€æµ‹åˆ°è¯­è¨€: {detected_lang}")
            
            # ğŸ”¥ å…³é”®æ”¹åŠ¨ï¼šå¹¶è¡Œæ‰§è¡Œä¸¤ä¸ªä»»åŠ¡
            print(f"ğŸš€ å¯åŠ¨å¹¶è¡Œå¤„ç†...")
            if image_urls and len(image_urls) > 0:
                print(f"   - æ£€æµ‹åˆ° {len(image_urls)} å¼ å›¾ç‰‡ï¼Œå°†ä½¿ç”¨ Vision èƒ½åŠ›åˆ†æå›¾ç‰‡+æ–‡å­—")
            print(f"   - ä»»åŠ¡1: GPT-4o-mini æ¶¦è‰² + æ ‡é¢˜ï¼ˆå­—æ®µ haikuï¼‰")
            print(f"   - ä»»åŠ¡2: GPT-4o-mini æš–å¿ƒåé¦ˆï¼ˆå­—æ®µ sonnetï¼ŒåŸºäºåŸå§‹æ–‡æœ¬ï¼‰")
            
            # åˆ›å»ºä¸¤ä¸ªå¼‚æ­¥ä»»åŠ¡
            polish_task = self._call_gpt4o_mini_for_polish_and_title(text, detected_lang, image_urls)
            feedback_task = self._call_gpt4o_mini_for_feedback(text, detected_lang, user_name, image_urls)
            
            # å¹¶è¡Œæ‰§è¡Œå¹¶ç­‰å¾…ç»“æœ
            polish_result, feedback = await asyncio.gather(
                polish_task,
                feedback_task
            )
            
            print(f"âœ… å¹¶è¡Œå¤„ç†å®Œæˆ")
            
            # åˆå¹¶ç»“æœ
            result = {
                "title": polish_result['title'],
                "polished_content": polish_result['polished_content'],
                "feedback": feedback
            }
            
            # è´¨é‡æ£€æŸ¥
            result = self._validate_and_fix_result(result, text)
            
            print(f"âœ… å¤„ç†å®Œæˆ:")
            print(f"  - æ ‡é¢˜: {result['title']}")
            print(f"  - å†…å®¹é•¿åº¦: {len(result['polished_content'])} å­—")
            print(f"  - åé¦ˆé•¿åº¦: {len(result['feedback'])} å­—")
            
            return result
        
        except Exception as e:
            error_type = type(e).__name__
            error_msg = str(e)
            print(f"âŒ AIå¤„ç†å¤±è´¥: {error_type}: {error_msg}")
            import traceback
            error_trace = traceback.format_exc()
            print(f"ğŸ“ å®Œæ•´é”™è¯¯å †æ ˆ:")
            print(error_trace)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å¹¶è¡Œä»»åŠ¡ä¸­çš„é”™è¯¯
            if isinstance(e, (asyncio.TimeoutError, asyncio.CancelledError)):
                print(f"âš ï¸ å¹¶è¡Œä»»åŠ¡è¶…æ—¶æˆ–å–æ¶ˆ")
            elif isinstance(e, Exception):
                print(f"âš ï¸ å¹¶è¡Œä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
            
            return self._create_fallback_result(text)
    
    # ========================================================================
    # ğŸ”¥ GPT-4o-mini è°ƒç”¨ï¼ˆæ¶¦è‰² + æ ‡é¢˜ï¼‰
    # ========================================================================
    
    async def _call_gpt4o_mini_for_polish_and_title(
        self, 
        text: str,
        language: str,
        image_urls: Optional[List[str]] = None
    ) -> Dict[str, str]:
        """
        è°ƒç”¨ GPT-4o-mini è¿›è¡Œæ¶¦è‰²å’Œç”Ÿæˆæ ‡é¢˜
        
        ğŸ“š å­¦ä¹ ç‚¹ï¼šè¿™ä¸ªå‡½æ•°è´Ÿè´£ä¸¤ä¸ªä»»åŠ¡
        1. æ¶¦è‰²ç”¨æˆ·çš„åŸå§‹æ–‡æœ¬ï¼ˆä¿®å¤è¯­æ³•ã€ä¼˜åŒ–è¡¨è¾¾ï¼‰
        2. ç”Ÿæˆä¸€ä¸ªç®€æ´æœ‰æ„ä¹‰çš„æ ‡é¢˜
        
        ä¸ºä»€ä¹ˆä½¿ç”¨ GPT-4o-miniï¼Ÿ
        - é€Ÿåº¦å¿«ï¼ˆ1-2ç§’ï¼‰
        - æˆæœ¬ä½ï¼ˆ$1/1M tokens inputï¼‰
        - è´¨é‡è¶³å¤Ÿï¼ˆæ—¥è®°æ¶¦è‰²ç»°ç»°æœ‰ä½™ï¼‰
        
        è¿”å›:
            {
                "title": "æ ‡é¢˜",
                "polished_content": "æ¶¦è‰²åçš„å†…å®¹"
            }
        """
        try:
            print(f"ğŸ¨ GPT-4o-mini: å¼€å§‹æ¶¦è‰²å’Œç”Ÿæˆæ ‡é¢˜...")
            
            # æ„å»º prompt
            system_prompt = """You are a gentle diary editor. Your task is to polish the user's diary entry and create a title.

Language: IMPORTANT - Detect the user's language and respond in THE SAME LANGUAGE. If user writes in Japanese, respond in Japanese. If user writes in Korean, respond in Korean. If user writes in Chinese, respond in Chinese. NEVER translate to a different language.

Your responsibilities:
1. Fix obvious grammar/typos
2. Make the text flow naturally
3. Keep it â‰¤115% of original length
4. **CRITICAL: Preserve ALL original content. Do NOT delete or omit any part of the user's entry.**
5. Create a short, warm, poetic, meaningful title IN THE SAME LANGUAGE as the user's input

Style: Natural, warm, authentic. Don't over-edit.

Response format (JSON only):
{
  "title": "Concise words in USER'S LANGUAGE",
  "polished_content": "fixed text, SAME LANGUAGE as user - MUST include all original content"
}

Example (Chinese input):
Input: "ä»Šå¤©å¤©æ°”å¾ˆå¥½æˆ‘å»äº†å…¬å›­çœ‹åˆ°äº†å¾ˆå¤šèŠ±"
Output: {"title": "å…¬å›­é‡Œçš„èŠ±", "polished_content": "ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œæˆ‘å»äº†å…¬å›­ï¼Œçœ‹åˆ°äº†å¾ˆå¤šèŠ±ã€‚"}

Example (Japanese input):
Input: "ä»Šæ—¥ã¯å¤©æ°—ãŒã‚ˆã‹ã£ãŸå…¬åœ’ã«è¡Œã£ãŸ"
Output: {"title": "å…¬åœ’ã§ã®ä¸€æ—¥", "polished_content": "ä»Šæ—¥ã¯å¤©æ°—ãŒã‚ˆã‹ã£ãŸã€‚å…¬åœ’ã«è¡Œã£ãŸã€‚"}

Example (English input):
Input: "today was good i went to park"
Output: {"title": "A Day at the Park", "polished_content": "Today was good. I went to the park."}"""

            # æ„å»ºç”¨æˆ·æ¶ˆæ¯å†…å®¹
            user_content = []
            
            # å¦‚æœæœ‰å›¾ç‰‡ï¼Œæ·»åŠ å›¾ç‰‡åˆ°æ¶ˆæ¯ä¸­ï¼ˆä½¿ç”¨visionèƒ½åŠ›ï¼‰
            if image_urls and len(image_urls) > 0:
                print(f"ğŸ–¼ï¸ æ·»åŠ  {len(image_urls)} å¼ å›¾ç‰‡åˆ° Vision è¯·æ±‚...")
                for image_url in image_urls:
                    # ä¸‹è½½å›¾ç‰‡å¹¶è½¬æ¢ä¸ºbase64
                    try:
                        image_data = await self._download_and_encode_image(image_url)
                        user_content.append({
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_data}"
                            }
                        })
                    except Exception as e:
                        print(f"âš ï¸ ä¸‹è½½å›¾ç‰‡å¤±è´¥ {image_url}: {e}")
                        # å¦‚æœå›¾ç‰‡ä¸‹è½½å¤±è´¥ï¼Œç»§ç»­å¤„ç†ï¼Œåªä½¿ç”¨æ–‡å­—
                
                # æ·»åŠ æ–‡å­—å†…å®¹
                user_content.append({
                    "type": "text",
                    "text": f"Please polish this diary entry (preserve ALL content) and create a title. Consider both the images and the text:\n\n{text}"
                })
                user_prompt = user_content
            else:
                # åªæœ‰æ–‡å­—ï¼Œä½¿ç”¨çº¯æ–‡æœ¬
                user_prompt = f"Please polish this diary entry (preserve ALL content):\n\n{text}"
            
            # âœ… åŠ¨æ€è®¡ç®— max_tokensï¼šç¡®ä¿è¶³å¤Ÿè¾“å‡ºå®Œæ•´å†…å®¹
            # åŸå§‹æ–‡æœ¬é•¿åº¦ + æ ‡é¢˜ + JSON æ ¼å¼å¼€é”€ + å®‰å…¨è¾¹è·
            original_length = len(text)
            # å¦‚æœæœ‰å›¾ç‰‡ï¼Œéœ€è¦é¢å¤–çš„tokensï¼ˆæ¯å¼ å›¾ç‰‡çº¦85 tokensï¼‰
            image_tokens = len(image_urls) * 85 if image_urls else 0
            # ä¼°ç®—ï¼šåŸå§‹æ–‡æœ¬ * 1.15ï¼ˆ115%é™åˆ¶ï¼‰ + æ ‡é¢˜ï¼ˆ50å­—ç¬¦ï¼‰ + JSONæ ¼å¼ï¼ˆ100å­—ç¬¦ï¼‰ + å®‰å…¨è¾¹è·ï¼ˆ500å­—ç¬¦ï¼‰
            estimated_output_length = int(original_length * 1.15) + 50 + 100 + 500
            # max_tokens å¤§çº¦æ˜¯å­—ç¬¦æ•°çš„ 0.75ï¼ˆä¸­æ–‡ï¼‰åˆ° 1.5ï¼ˆè‹±æ–‡ï¼‰ï¼Œå–ä¸­é—´å€¼ 1.0
            max_tokens = max(2000, int(estimated_output_length * 1.0) + image_tokens)
            # ä½†ä¸è¦è¶…è¿‡ OpenAI çš„é™åˆ¶ï¼ˆGPT-4o-mini æ”¯æŒ 16384 tokensï¼‰
            max_tokens = min(max_tokens, 16000)
            
            print(f"ğŸ“¤ GPT-4o-mini: å‘é€è¯·æ±‚åˆ° OpenAI...")
            print(f"   æ¨¡å‹: {self.MODEL_CONFIG['haiku']}")
            print(f"   åŸå§‹æ–‡æœ¬é•¿åº¦: {original_length} å­—ç¬¦")
            print(f"   å›¾ç‰‡æ•°é‡: {len(image_urls) if image_urls else 0}")
            print(f"   ä¼°ç®—è¾“å‡ºé•¿åº¦: {estimated_output_length} å­—ç¬¦")
            print(f"   è®¾ç½® max_tokens: {max_tokens}")
            
            # æ„å»ºæ¶ˆæ¯
            if image_urls and len(image_urls) > 0:
                # ä½¿ç”¨visionæ ¼å¼ï¼ˆåŒ…å«å›¾ç‰‡ï¼‰
                messages = [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ]
            else:
                # çº¯æ–‡æœ¬æ ¼å¼
                messages = [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ]
            
            # ä½¿ç”¨ OpenAI clientï¼ˆå·²ç»åœ¨ __init__ ä¸­åˆå§‹åŒ–ï¼‰
            response = await asyncio.to_thread(
                self.openai_client.chat.completions.create,
                model=self.MODEL_CONFIG["haiku"],
                messages=messages,
                temperature=0.3,
                max_tokens=max_tokens,
                response_format={"type": "json_object"}  # å¼ºåˆ¶ JSON æ ¼å¼
            )
            
            # è§£æå“åº”
            content = response.choices[0].message.content
            if not content:
                raise ValueError("OpenAI è¿”å›ç©ºå“åº”")
            
            print(f"âœ… GPT-4o-mini: æ”¶åˆ°å“åº”")
            print(f"ğŸ“ GPT-4o-mini: å“åº”å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
            
            # è§£æ JSON
            try:
                result = json.loads(content)
                polished_content = result.get("polished_content", text)
                
                # âœ… æ·»åŠ é•¿åº¦å¯¹æ¯”æ—¥å¿—ï¼Œæ£€æŸ¥æ˜¯å¦è¢«æˆªæ–­
                original_length = len(text)
                polished_length = len(polished_content)
                length_ratio = polished_length / original_length if original_length > 0 else 0
                
                print(f"âœ… GPT-4o-mini: æ¶¦è‰²å®Œæˆ")
                print(f"ğŸ“Š é•¿åº¦å¯¹æ¯”: åŸå§‹={original_length} å­—ç¬¦, æ¶¦è‰²å={polished_length} å­—ç¬¦, æ¯”ä¾‹={length_ratio:.2%}")
                
                # âš ï¸ å¦‚æœæ¶¦è‰²åå†…å®¹æ˜æ˜¾å°‘äºåŸå§‹å†…å®¹ï¼ˆå°äº80%ï¼‰ï¼Œå¯èƒ½æ˜¯è¢«æˆªæ–­äº†
                if polished_length < original_length * 0.8:
                    print(f"âš ï¸ è­¦å‘Šï¼šæ¶¦è‰²åå†…å®¹æ˜æ˜¾å°‘äºåŸå§‹å†…å®¹ï¼Œå¯èƒ½è¢«æˆªæ–­ï¼")
                    print(f"   åŸå§‹å†…å®¹å‰100å­—ç¬¦: {text[:100]}...")
                    print(f"   æ¶¦è‰²åå†…å®¹å‰100å­—ç¬¦: {polished_content[:100]}...")
                    # å¦‚æœç¡®å®è¢«æˆªæ–­ï¼Œä½¿ç”¨åŸå§‹å†…å®¹ä½œä¸ºé™çº§æ–¹æ¡ˆ
                    polished_content = text
                    print(f"   ä½¿ç”¨åŸå§‹å†…å®¹ä½œä¸ºé™çº§æ–¹æ¡ˆ")
                
                return {
                    "title": result.get("title", "Today's Reflection"),
                    "polished_content": polished_content
                }
            except json.JSONDecodeError as e:
                print(f"âš ï¸ GPT-4o-mini: JSON è§£æå¤±è´¥: {e}")
                print(f"   åŸå§‹å“åº”: {content[:200]}...")
                # å°è¯•ä»æ–‡æœ¬ä¸­æå– JSON
                import re
                json_match = re.search(r'\{[^{}]*"title"[^{}]*"polished_content"[^{}]*\}', content)
                if json_match:
                    try:
                        result = json.loads(json_match.group())
                        return {
                            "title": result.get("title", "Today's Reflection"),
                            "polished_content": result.get("polished_content", text)
                        }
                    except:
                        pass
                
                # é™çº§æ–¹æ¡ˆ
                print(f"âš ï¸ GPT-4o-mini: ä½¿ç”¨é™çº§æ–¹æ¡ˆ")
                return {
                    "title": "Today's Reflection" if language == "English" else "ä»Šæ—¥è®°å½•",
                    "polished_content": text
                }
        
        except Exception as e:
            error_type = type(e).__name__
            error_msg = str(e)
            print(f"âŒ GPT-4o-mini è°ƒç”¨å¤±è´¥: {error_type}: {error_msg}")
            
            # è¯¦ç»†é”™è¯¯ä¿¡æ¯
            import traceback
            error_trace = traceback.format_exc()
            print(f"ğŸ“ GPT-4o-mini å®Œæ•´é”™è¯¯å †æ ˆ:")
            print(error_trace)
            
            # æ£€æŸ¥å¸¸è§é”™è¯¯ç±»å‹
            if "RateLimitError" in error_type or "rate_limit" in error_msg.lower():
                print(f"âš ï¸ OpenAI API é™æµ: è¯·æ±‚é¢‘ç‡è¿‡é«˜")
                print(f"ğŸ’¡ å»ºè®®: ç¨åé‡è¯•ï¼Œæˆ–æ£€æŸ¥ OpenAI è´¦æˆ·çš„é…é¢é™åˆ¶")
            elif "AuthenticationError" in error_type or "InvalidApiKey" in error_type:
                print(f"âš ï¸ OpenAI API Key é”™è¯¯: è¯·æ£€æŸ¥ OPENAI_API_KEY ç¯å¢ƒå˜é‡")
            elif "APIConnectionError" in error_type:
                print(f"âš ï¸ OpenAI API è¿æ¥é”™è¯¯: è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
            
            # é™çº§æ–¹æ¡ˆ
            return {
                "title": "Today's Reflection" if language == "English" else "ä»Šæ—¥è®°å½•",
                "polished_content": text
            }
    
    # ========================================================================
    # ğŸ”¥ GPT-4o-mini è°ƒç”¨ï¼ˆAI åé¦ˆï¼‰
    # ========================================================================
    
    async def _call_gpt4o_mini_for_feedback(
        self, 
        text: str,
        language: str,
        user_name: Optional[str] = None,
        image_urls: Optional[List[str]] = None
    ) -> str:
        """
        è°ƒç”¨ GPT-4o-mini ç”Ÿæˆæ¸©æš–çš„ AI åé¦ˆ
        
        ğŸ“š å­¦ä¹ ç‚¹ï¼šè¿™ä¸ªå‡½æ•°åŸºäºç”¨æˆ·çš„åŸå§‹æ–‡æœ¬ç”Ÿæˆåé¦ˆ
        - æ›´çœŸå®ï¼šä¿ç•™ç”¨æˆ·æœ€åŸå§‹çš„æƒ…æ„Ÿè¡¨è¾¾
        - æ›´å¿«ï¼šä¸éœ€è¦ç­‰å¾…æ¶¦è‰²å®Œæˆï¼ˆå¯ä»¥å¹¶è¡Œæ‰§è¡Œï¼‰
        - æ›´æ¸©æš–ï¼šAI å›åº”"çœŸå®çš„ä½ "è€Œä¸æ˜¯"å®Œç¾çš„æ–‡å­—"
        
        ä¸ºä»€ä¹ˆé€‰æ‹© GPT-4o-miniï¼Ÿ
        - å…±æƒ…èƒ½åŠ›ç¨³å®š
        - ä¸­è‹±æ–‡è¡¨è¾¾è‡ªç„¶
        - ä¸æ¶¦è‰²æ¨¡å‹ç»Ÿä¸€ï¼Œæ–¹ä¾¿ç»´æŠ¤
        
        è¿”å›:
            æ¸©æš–çš„åé¦ˆæ–‡å­—ï¼ˆç®€æ´æœ‰åŠ›ï¼Œä¸è¶…è¿‡ç”¨æˆ·è¾“å…¥é•¿åº¦ï¼‰
        """
        try:
            print(f"ğŸ’¬ GPT-4o-mini: å¼€å§‹ç”Ÿæˆåé¦ˆï¼ˆåŸºäºåŸå§‹æ–‡æœ¬ï¼‰...")
            print(f"ğŸ‘¤ ç”¨æˆ·åå­—: {user_name if user_name else 'æœªæä¾›'}")
            
            # è®¡ç®—ç”¨æˆ·è¾“å…¥é•¿åº¦ï¼Œç”¨äºåŠ¨æ€è°ƒæ•´åé¦ˆé•¿åº¦
            user_text_length = len(text.strip())
            # åé¦ˆé•¿åº¦ç­–ç•¥ï¼šä¸è¶…è¿‡ç”¨æˆ·è¾“å…¥é•¿åº¦ï¼Œä½†æœ€çŸ­ä¸å°‘äº20å­—ï¼ˆä¸­æ–‡ï¼‰æˆ–15è¯ï¼ˆè‹±æ–‡ï¼‰
            max_feedback_length = max(user_text_length, 20 if language == "Chinese" else 15)
            
            # æ„å»ºä¸ªæ€§åŒ–çš„åå­—ç§°å‘¼
            name_greeting = ""
            if user_name and user_name.strip():
                # æå–åå­—ï¼ˆå»æ‰å¯èƒ½çš„ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦ï¼‰
                import re
                first_name = re.split(r'\s+', user_name.strip())[0]
                if language == "Chinese":
                    name_greeting = f"ï¼Œ{first_name}"
                else:
                    name_greeting = f", {first_name}"
            
            # æ„å»º prompt
            if user_name and user_name.strip():
                # æœ‰ç”¨æˆ·åå­—æ—¶ï¼Œæ˜ç¡®è§„å®šå¿…é¡»ä½¿ç”¨åå­—
                system_prompt = f"""You are a warm, empathetic listener responding to {user_name}'s diary entry.

Language: IMPORTANT - Detect the user's language from their diary entry and respond in THE SAME LANGUAGE. If they write in Japanese, respond in Japanese. If Korean, respond in Korean. Match their language exactly. NEVER translate.

âš ï¸ CRITICAL RULE - YOU MUST FOLLOW THIS:
Your response MUST start with "{user_name}" (followed by a comma in English or a Chinese comma in Chinese), then your message. 
DO NOT use generic greetings like "Hi there", "Hello", or "Hi". 
DO NOT skip the name. 
ALWAYS start with "{user_name}".

Your style:
- Warm and genuine (like a close friend)
- **Keep it SHORT and POWERFUL** - never longer than the user's input (unless their input is very short, <20 chars)
- Maximum length: {max_feedback_length} characters (Chinese) or {max_feedback_length // 2} words (English)
- 1-2 complete sentences (prefer 1 sentence if user's input is short)
- **FIRST WORD MUST BE "{user_name}"** - No exceptions
- Acknowledge their feelings with warmth
- Offer gentle encouragement when appropriate
- Natural, conversational, intimate tone

Response format: Plain text only (NO JSON, NO quotes, NO markdown)

Example responses (MUST follow this exact format):
- Chinese (short input): "{user_name}ï¼Œè¿™ä»½ç®€å•çš„å¿«ä¹å¾ˆçè´µã€‚"
- Chinese (longer input): "{user_name}ï¼Œè¿™ä»½è®°å½•å¾ˆæ¸©æš–ã€‚ç”Ÿæ´»ä¸­çš„å°ç¡®å¹¸ï¼Œå¾€å¾€æ˜¯æœ€æ²»æ„ˆçš„æ—¶åˆ»ã€‚"
- English (short input): "{user_name}, this simple joy is precious."
- English (longer input): "{user_name}, this moment you captured is beautiful. Small joys like this are what make life meaningful."

REMEMBER: 
1. Your response MUST start with "{user_name}" (with comma or Chinese comma)
2. DO NOT use "Hi there", "Hello", "Hi", or any other greeting
3. DO NOT skip the name
4. Be warm, be brief, be personal. Quality over quantity."""
            else:
                # æ²¡æœ‰ç”¨æˆ·åå­—æ—¶ï¼Œä½¿ç”¨é€šç”¨æç¤º
                system_prompt = f"""You are a warm, empathetic listener responding to someone's diary entry.

Language: IMPORTANT - Detect the user's language from their diary entry and respond in THE SAME LANGUAGE. If they write in Japanese, respond in Japanese. If Korean, respond in Korean. Match their language exactly. NEVER translate.

Your style:
- Warm and genuine (like a close friend)
- **Keep it SHORT and POWERFUL** - never longer than the user's input (unless their input is very short, <20 chars)
- Maximum length: {max_feedback_length} characters (Chinese) or {max_feedback_length // 2} words (English)
- 1-2 complete sentences (prefer 1 sentence if user's input is short)
- Acknowledge their feelings with warmth
- Offer gentle encouragement when appropriate
- Natural, conversational, intimate tone

Response format: Plain text only (NO JSON, NO quotes, NO markdown)

Example responses (short and warm):
- Chinese (short input): "è¿™ä»½ç®€å•çš„å¿«ä¹å¾ˆçè´µã€‚"
- Chinese (longer input): "è¿™ä»½è®°å½•å¾ˆæ¸©æš–ã€‚ç”Ÿæ´»ä¸­çš„å°ç¡®å¹¸ï¼Œå¾€å¾€æ˜¯æœ€æ²»æ„ˆçš„æ—¶åˆ»ã€‚"
- English (short input): "This simple joy is precious."
- English (longer input): "This moment you captured is beautiful. Small joys like this are what make life meaningful."

Remember: Be warm, be brief, be personal. Quality over quantity."""

            # æ„å»ºä¸ªæ€§åŒ–çš„ç”¨æˆ·æç¤º
            user_content = []
            
            # å¦‚æœæœ‰å›¾ç‰‡ï¼Œæ·»åŠ å›¾ç‰‡åˆ°æ¶ˆæ¯ä¸­ï¼ˆä½¿ç”¨visionèƒ½åŠ›ï¼‰
            if image_urls and len(image_urls) > 0:
                print(f"ğŸ–¼ï¸ æ·»åŠ  {len(image_urls)} å¼ å›¾ç‰‡åˆ° Vision åé¦ˆè¯·æ±‚...")
                for image_url in image_urls:
                    # ä¸‹è½½å›¾ç‰‡å¹¶è½¬æ¢ä¸ºbase64
                    try:
                        image_data = await self._download_and_encode_image(image_url)
                        user_content.append({
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_data}"
                            }
                        })
                    except Exception as e:
                        print(f"âš ï¸ ä¸‹è½½å›¾ç‰‡å¤±è´¥ {image_url}: {e}")
                        # å¦‚æœå›¾ç‰‡ä¸‹è½½å¤±è´¥ï¼Œç»§ç»­å¤„ç†ï¼Œåªä½¿ç”¨æ–‡å­—
                
                # æ·»åŠ æ–‡å­—å†…å®¹
                if user_name:
                    text_content = f"{user_name} just shared this with you (including images):\n\n{text}\n\nRespond warmly and personally, considering both the images and the text:"
                else:
                    text_content = f"Someone just shared this with you (including images):\n\n{text}\n\nRespond with warmth and empathy, considering both the images and the text:"
                
                user_content.append({
                    "type": "text",
                    "text": text_content
                })
                user_prompt = user_content
            else:
                # åªæœ‰æ–‡å­—ï¼Œä½¿ç”¨çº¯æ–‡æœ¬
                if user_name:
                    user_prompt = f"{user_name} just shared this with you:\n\n{text}\n\nRespond warmly and personally:"
                else:
                    user_prompt = f"Someone just shared this with you:\n\n{text}\n\nRespond with warmth and empathy:"
            
            # è°ƒç”¨ OpenAI Chat Completions API
            # åŠ¨æ€è°ƒæ•´ max_tokensï¼šæ ¹æ®ç”¨æˆ·è¾“å…¥é•¿åº¦ï¼Œé¢„ç•™æ˜µç§°ä¸æç¤ºç©ºé—´
            estimated_output_length = max_feedback_length + 40
            image_tokens = len(image_urls) * 85 if image_urls else 0
            max_tokens = max(200, min(int(estimated_output_length * 1.2) + image_tokens, 800))

            print(f"ğŸ“¤ GPT-4o-mini: å‘é€è¯·æ±‚åˆ° OpenAI...")
            print(f"   æ¨¡å‹: {self.MODEL_CONFIG['sonnet']}")
            print(f"   ç”¨æˆ·åå­—: {user_name if user_name else 'æœªæä¾›'}")
            print(f"   å›¾ç‰‡æ•°é‡: {len(image_urls) if image_urls else 0}")
            print(f"   System prompt å‰100å­—ç¬¦: {system_prompt[:100]}...")

            # æ„å»ºæ¶ˆæ¯
            if image_urls and len(image_urls) > 0:
                # ä½¿ç”¨visionæ ¼å¼ï¼ˆåŒ…å«å›¾ç‰‡ï¼‰
                messages = [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ]
            else:
                # çº¯æ–‡æœ¬æ ¼å¼
                messages = [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ]

            response = await asyncio.to_thread(
                self.openai_client.chat.completions.create,
                model=self.MODEL_CONFIG["sonnet"],
                messages=messages,
                temperature=0.7,
                max_tokens=max_tokens,
            )

            content = response.choices[0].message.content if response.choices else ""
            if not content:
                raise ValueError("OpenAI è¿”å›ç©ºå“åº”")

            feedback = content.strip()
            print(f"âœ… GPT-4o-mini: æ”¶åˆ°åé¦ˆï¼Œé•¿åº¦ {len(feedback)} å­—ç¬¦")
            
            if user_name and user_name.strip():
                trimmed_feedback = feedback.lstrip()
                starts_with_name = trimmed_feedback.lower().startswith(user_name.lower())
                
                # æ™ºèƒ½åˆ†éš”ç¬¦ï¼šæ ¹æ®åé¦ˆå†…å®¹åˆ¤æ–­ç”¨ä¸­æ–‡é€—å·è¿˜æ˜¯è‹±æ–‡é€—å·
                # CJK å­—ç¬¦ï¼ˆä¸­æ—¥éŸ©ï¼‰ä½¿ç”¨ä¸­æ–‡é€—å·ï¼Œå…¶ä»–ä½¿ç”¨è‹±æ–‡é€—å·
                import re
                has_cjk = bool(re.search(r'[\u4e00-\u9fff\u3040-\u309f\u30a0-\u30ff\uac00-\ud7af]', trimmed_feedback))
                separator = "ï¼Œ" if has_cjk else ", "
                
                if not starts_with_name:
                    print(
                        f"âš ï¸ åé¦ˆæœªä»¥åå­—å¼€å¤´ï¼Œè‡ªåŠ¨ä¿®æ­£: user_name={user_name}, feedback='{feedback}'"
                    )
                    feedback = f"{user_name}{separator}{trimmed_feedback}"
                    print(f"âœ… ä¿®æ­£å: {feedback[:50]}...")
            
            print(f"âœ… GPT-4o-mini: åé¦ˆç”Ÿæˆå®Œæˆ")
            print(f"   åé¦ˆ: {feedback[:50]}...")
            
            return feedback
        
        except Exception as e:
            error_type = type(e).__name__
            error_msg = str(e)
            print(f"âŒ GPT-4o-mini åé¦ˆè°ƒç”¨å¤±è´¥: {error_type}: {error_msg}")
            
            # è¯¦ç»†é”™è¯¯ä¿¡æ¯
            import traceback
            error_trace = traceback.format_exc()
            print(f"ğŸ“ GPT-4o-mini åé¦ˆå®Œæ•´é”™è¯¯å †æ ˆ:")
            print(error_trace)
            
            # æ£€æŸ¥å¸¸è§é”™è¯¯ç±»å‹
            if "RateLimit" in error_type or "rate limit" in error_msg.lower():
                print(f"âš ï¸ OpenAI é™æµ: è¯·æ±‚é¢‘ç‡è¿‡é«˜ï¼Œå»ºè®®ç¨åé‡è¯•æˆ–è°ƒæ•´é€Ÿç‡")
            elif "AuthenticationError" in error_type or "InvalidApiKey" in error_type:
                print(f"âš ï¸ OpenAI API Key é”™è¯¯: è¯·æ£€æŸ¥ OPENAI_API_KEY ç¯å¢ƒå˜é‡")
            elif "APIConnectionError" in error_type:
                print(f"âš ï¸ OpenAI API è¿æ¥é”™è¯¯: è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
            
            # é™çº§æ–¹æ¡ˆ
            return "æ„Ÿè°¢åˆ†äº«ä½ çš„è¿™ä¸€åˆ»ã€‚" if language == "Chinese" else "Thanks for sharing this moment."
    
    # ========================================================================
    # éªŒè¯å’Œé™çº§é€»è¾‘ï¼ˆä¿æŒä¸å˜ï¼‰
    # ========================================================================
    
    def _validate_and_fix_result(
        self, 
        result: Dict[str, str], 
        original_text: str
    ) -> Dict[str, str]:
        """
        éªŒè¯å¹¶ä¿®æ­£AIè¾“å‡º - è´¨é‡æŠŠå…³
        
        ğŸ”¥ æ³¨æ„ï¼šè¿™ä¸ªæ–¹æ³•å®Œå…¨ä¿æŒä¸å˜
        """
        import re
        
        orig_len = len(original_text.strip())
        
        # æ£€æµ‹è¯­è¨€
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', original_text))
        is_chinese = chinese_chars > len(original_text) * 0.2
        
        print(f"ğŸ“Š åŸæ–‡è¯­è¨€æ£€æµ‹: æ€»é•¿åº¦={len(original_text)}, ä¸­æ–‡å­—ç¬¦={chinese_chars}, åˆ¤å®š={'ä¸­æ–‡' if is_chinese else 'è‹±æ–‡'}")
        
        # æå–å„éƒ¨åˆ†
        title = (result.get("title", "") or "").strip()
        polished = (result.get("polished_content", "") or "").strip()
        feedback = (result.get("feedback", "") or "").strip()
        
        # éªŒè¯è¯­è¨€ä¸€è‡´æ€§
        title_has_chinese = bool(re.search(r'[\u4e00-\u9fff]', title))
        feedback_has_chinese = bool(re.search(r'[\u4e00-\u9fff]', feedback))
        
        used_fallback = False
        
        if is_chinese != title_has_chinese:
            print(f"âš ï¸ æ ‡é¢˜è¯­è¨€ä¸ä¸€è‡´ï¼")
            title = "ä»Šæ—¥è®°å½•" if is_chinese else "Today's Reflection"
            used_fallback = True
        
        if is_chinese != feedback_has_chinese:
            print(f"âš ï¸ åé¦ˆè¯­è¨€ä¸ä¸€è‡´ï¼")
            feedback = "æ„Ÿè°¢åˆ†äº«ä½ çš„è¿™ä¸€åˆ»ã€‚" if is_chinese else "Thanks for sharing this moment."
            used_fallback = True
        
        # æ¸…ç†å‡½æ•°
        def clean_text(text: str) -> str:
            text = re.sub(r'[\U0001F300-\U0001FAFF\U00002700-\U000027BF]+', '', text)
            text = text.replace('ï¼', 'ã€‚').replace('!', '.')
            text = re.sub(r'\s+', ' ', text).strip()
            return text
        
        def trim_to_complete_sentences(text: str, max_len: int) -> str:
            if len(text) <= max_len:
                return text
            
            sentence_pattern = r"([ã€‚ï¼ï¼Ÿ.!?])(['\"\"ã€ã€)]?)\s*"
            sentences = []
            last_end = 0
            
            for match in re.finditer(sentence_pattern, text):
                end_pos = match.end()
                sentence = text[last_end:end_pos].strip()
                if sentence:
                    sentences.append(sentence)
                last_end = end_pos
            
            if last_end < len(text):
                remaining = text[last_end:].strip()
                if remaining:
                    sentences.append(remaining)
            
            if not sentences:
                for punct in ['ã€‚', '.', 'ï¼', '!', 'ï¼Ÿ', '?', 'ï¼›', ';']:
                    idx = text.rfind(punct, 0, max_len + 1)
                    if idx > max_len * 0.5:
                        return text[:idx + 1].strip()
                return text
            
            result = []
            current_len = 0
            
            for sentence in sentences:
                sentence_len = len(sentence)
                if current_len + sentence_len <= max_len:
                    result.append(sentence)
                    current_len += sentence_len
                else:
                    if len(result) == 0:
                        return text[:max_len].strip() if max_len < len(text) else text
                    break
            
            if not result:
                return text[:max_len].strip()
            
            has_chinese = any('\u4e00' <= char <= '\u9fff' for char in ''.join(result))
            separator = '' if has_chinese else ' '
            
            return separator.join(result).strip()
        
        # ä¿®æ­£æ ‡é¢˜
        title = clean_text(title)
        title = re.sub(r'[^\w\u4e00-\u9fff\s-]', '', title)
        title = re.sub(r'\s+', ' ', title).strip()
        
        if len(title) < self.LENGTH_LIMITS["title_min"]:
            title = "Today's Reflection" if any(ord(c) < 128 for c in original_text) else "ä»Šæ—¥è®°å½•"
        elif len(title) > self.LENGTH_LIMITS["title_max"]:
            max_len = self.LENGTH_LIMITS["title_max"]
            if ' ' in title and len(title) > max_len:
                words = title[:max_len].rsplit(' ', 1)
                title = words[0] if len(words[0]) > max_len * 0.6 else title[:max_len]
            else:
                title = title[:max_len]
        
        # ä¿®æ­£æ¶¦è‰²å†…å®¹
        polished = clean_text(polished)
        max_polished_len = int(orig_len * self.LENGTH_LIMITS["polished_ratio"])
        
        # âœ… æ·»åŠ é•¿åº¦æ£€æŸ¥æ—¥å¿—
        print(f"ğŸ“Š æ¶¦è‰²å†…å®¹éªŒè¯: åŸå§‹é•¿åº¦={orig_len}, æ¶¦è‰²åé•¿åº¦={len(polished)}, æœ€å¤§å…è®¸é•¿åº¦={max_polished_len}")
        
        # âš ï¸ å¦‚æœæ¶¦è‰²åå†…å®¹æ˜æ˜¾å°‘äºåŸå§‹å†…å®¹ï¼ˆå°äº80%ï¼‰ï¼Œå¯èƒ½æ˜¯è¢«æˆªæ–­äº†ï¼Œä½¿ç”¨åŸå§‹å†…å®¹
        if len(polished) < orig_len * 0.8:
            print(f"âš ï¸ è­¦å‘Šï¼šæ¶¦è‰²åå†…å®¹æ˜æ˜¾å°‘äºåŸå§‹å†…å®¹ï¼ˆ{len(polished)} < {orig_len * 0.8}ï¼‰ï¼Œä½¿ç”¨åŸå§‹å†…å®¹")
            polished = original_text.strip()
        
        # åªæœ‰åœ¨è¶…è¿‡æœ€å¤§é•¿åº¦æ—¶æ‰æˆªæ–­ï¼ˆä½†è¿™ç§æƒ…å†µä¸åº”è¯¥å‘ç”Ÿï¼Œå› ä¸ºæç¤ºè¯è¦æ±‚â‰¤115%ï¼‰
        if len(polished) > max_polished_len:
            print(f"âš ï¸ æ¶¦è‰²åå†…å®¹è¶…è¿‡æœ€å¤§é•¿åº¦ï¼ˆ{len(polished)} > {max_polished_len}ï¼‰ï¼ŒæŒ‰å®Œæ•´å¥å­æˆªæ–­")
            polished = trim_to_complete_sentences(polished, max_polished_len)
        
        # ä¿®æ­£åé¦ˆ
        feedback = clean_text(feedback)
        
        if not used_fallback and len(feedback) < self.LENGTH_LIMITS.get("feedback_min", 20):
            print(f"âš ï¸ åé¦ˆè¿‡çŸ­ï¼Œä½¿ç”¨é™çº§")
            feedback = "æ„Ÿè°¢åˆ†äº«ä½ çš„è¿™ä¸€åˆ»ã€‚" if is_chinese else "Thanks for sharing this moment."
        
        if len(feedback) > self.LENGTH_LIMITS["feedback_max"]:
            print(f"ğŸ“ åé¦ˆè¿‡é•¿ï¼ŒæŒ‰å®Œæ•´å¥å­æˆªæ–­")
            feedback = trim_to_complete_sentences(feedback, self.LENGTH_LIMITS["feedback_max"])
        
        is_english = any(ord(c) < 128 for c in original_text[:50])
        default_feedback = "Thank you for sharing." if is_english else "æ„Ÿè°¢åˆ†äº«ã€‚"
        
        return {
            "title": title,
            "polished_content": polished or original_text,
            "feedback": feedback or default_feedback
        }
    
    def _create_fallback_result(self, text: str) -> Dict[str, str]:
        """
        åˆ›å»ºé™çº§ç»“æœ
        
        ğŸ”¥ æ³¨æ„ï¼šè¿™ä¸ªæ–¹æ³•å®Œå…¨ä¿æŒä¸å˜
        """
        import re
        
        print("âš ï¸ ä½¿ç”¨é™çº§æ–¹æ¡ˆ")
        
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
        is_chinese = chinese_chars > len(text) * 0.2
        
        return {
            "title": "ä»Šæ—¥è®°å½•" if is_chinese else "Today's Reflection",
            "polished_content": text,
            "feedback": "æ„Ÿè°¢åˆ†äº«ã€‚" if is_chinese else "Thanks for sharing."
        }
    
    # ========================================================================
    # å‘åå…¼å®¹æ–¹æ³•ï¼ˆä¿æŒä¸å˜ï¼‰
    # ========================================================================
    
    def polish_text(self, text: str) -> str:
        """æ¶¦è‰²æ–‡æœ¬ï¼ˆæ—§APIï¼‰"""
        result = self.polish_content_multilingual(text)
        return result["polished_content"]
    
    def generate_feedback(self, diary_content: str) -> str:
        """ç”Ÿæˆåé¦ˆï¼ˆæ—§APIï¼‰"""
        result = self.polish_content_multilingual(diary_content)
        return result["feedback"]


    # ========================================================================
    # ğŸ”¥ å›¾ç‰‡ä¸‹è½½å’Œç¼–ç ï¼ˆç”¨äºVision APIï¼‰
    # ========================================================================
    
    async def _download_and_encode_image(self, image_url: str) -> str:
        """
        ä¸‹è½½å›¾ç‰‡å¹¶è½¬æ¢ä¸ºbase64ç¼–ç ï¼ˆç”¨äºOpenAI Vision APIï¼‰
        
        Args:
            image_url: å›¾ç‰‡çš„URLï¼ˆS3 URLæˆ–HTTP URLï¼‰
        
        Returns:
            base64ç¼–ç çš„å›¾ç‰‡æ•°æ®
        """
        try:
            print(f"ğŸ“¥ ä¸‹è½½å›¾ç‰‡: {image_url[:50]}...")
            
            # ä¸‹è½½å›¾ç‰‡
            response = await asyncio.to_thread(requests.get, image_url, timeout=10)
            response.raise_for_status()
            
            # è½¬æ¢ä¸ºbase64
            image_base64 = base64.b64encode(response.content).decode('utf-8')
            
            print(f"âœ… å›¾ç‰‡ä¸‹è½½å¹¶ç¼–ç å®Œæˆï¼Œå¤§å°: {len(image_base64)} å­—ç¬¦")
            return image_base64
            
        except Exception as e:
            print(f"âŒ ä¸‹è½½å›¾ç‰‡å¤±è´¥: {e}")
            raise

# ğŸ¯ ä½¿ç”¨ç¤ºä¾‹
"""
# 1. åˆå§‹åŒ–æœåŠ¡
service = OpenAIService()

# 2. è¯­éŸ³è½¬æ–‡å­—ï¼ˆWhisperï¼‰
text = await service.transcribe_audio(audio_bytes, "recording.m4a")

# 3. å¹¶è¡Œå¤„ç†ï¼šæ¶¦è‰²ï¼ˆhaiku å­—æ®µï¼‰+ åé¦ˆï¼ˆsonnet å­—æ®µï¼‰
result = await service.polish_content_multilingual(text)

# 4. ä½¿ç”¨ç»“æœ
print(f"æ ‡é¢˜: {result['title']}")        # GPT-4o-miniï¼ˆhaiku å­—æ®µï¼‰ç”Ÿæˆ
print(f"å†…å®¹: {result['polished_content']}")  # GPT-4o-miniï¼ˆhaiku å­—æ®µï¼‰æ¶¦è‰²
print(f"åé¦ˆ: {result['feedback']}")      # GPT-4o-miniï¼ˆsonnet å­—æ®µï¼‰ç”Ÿæˆ

# 5. å›¾ç‰‡+æ–‡å­—å¤„ç†ï¼ˆæ–°åŠŸèƒ½ï¼‰
result = await service.polish_content_multilingual(
    text="ä»Šå¤©å»äº†å…¬å›­",
    image_urls=["https://s3.../image1.jpg", "https://s3.../image2.jpg"]
)
"""