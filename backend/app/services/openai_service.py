"""
AI æœåŠ¡ - æ··åˆæ¨¡å‹ä¼˜åŒ–ç‰ˆæœ¬
ä½œè€…çµæ„Ÿæ¥æºï¼šä¹”å¸ƒæ–¯çš„ç®€çº¦å“²å­¦ + å¼ å°é¾™çš„å…‹åˆ¶è®¾è®¡

ğŸ”¥ é‡å¤§æ›´æ–°ï¼š
1. ä» OpenAI GPT-4o-mini è¿ç§»åˆ° AWS Bedrock Claude æ¨¡å‹
2. æ··åˆä½¿ç”¨ Haiku 3.5ï¼ˆæ¶¦è‰²ï¼‰+ Sonnet 3.5ï¼ˆåé¦ˆï¼‰
3. å¹¶è¡Œæ‰§è¡Œï¼Œé€Ÿåº¦æå‡ 40-50%
4. ä¿æŒ Whisper è¯­éŸ³è½¬æ–‡å­—ä¸å˜

æ ¸å¿ƒç†å¿µï¼š
1. ç®€å•ä½†ä¸ç®€é™‹ï¼ˆSimple but not simplisticï¼‰
2. å¼ºå¤§ä½†ä¸å¤æ‚ï¼ˆPowerful but not complicatedï¼‰
3. ä¼˜é›…ä½†ä¸ç‚«æŠ€ï¼ˆElegant but not showyï¼‰
"""

import tempfile
import os
import json
import asyncio  # ğŸ”¥ æ–°å¢ï¼šç”¨äºå¹¶è¡Œæ‰§è¡Œ
from typing import Dict, Optional
from openai import OpenAI
import boto3  # ğŸ”¥ æ–°å¢ï¼šAWS SDK
from botocore.exceptions import ClientError  # ğŸ”¥ æ–°å¢ï¼šç”¨äºæ•è· AWS é”™è¯¯

from ..config import get_settings


class OpenAIService:
    """
    AI æœåŠ¡ç±» - æ”¯æŒå¤šè¯­è¨€æ—¥è®°å¤„ç†
    
    è¿™ä¸ªç±»å°±åƒä¸€ä¸ªæ¸©æŸ”çš„æ—¥è®°åŠ©æ‰‹ï¼Œå®ƒä¼šï¼š
    1. å¬æ‡‚ä½ çš„å£°éŸ³ï¼ˆè¯­éŸ³è½¬æ–‡å­— - Whisperï¼‰
    2. ç¾åŒ–ä½ çš„æ–‡å­—ï¼ˆè½»åº¦æ¶¦è‰² - Claude Haiku 3.5ï¼‰
    3. ç»™ä½ æ¸©æš–çš„å›åº”ï¼ˆå¿ƒç†é™ªä¼´ - Claude Sonnet 3.5ï¼‰
    4. å¸®ä½ èµ·ä¸ªå¥½æ ‡é¢˜ï¼ˆç”»é¾™ç‚¹ç› - Claude Haiku 3.5ï¼‰
    
    ğŸ”¥ æ¨¡å‹é€‰æ‹©ç­–ç•¥ï¼š
    - Whisper: è¯­éŸ³è½¬æ–‡å­—ï¼ˆOpenAIï¼Œæ— å¯æ›¿ä»£ï¼‰
    - Haiku 3.5: æ¶¦è‰² + æ ‡é¢˜ï¼ˆå¿«é€Ÿã€ä¾¿å®œã€æ•ˆæœå¥½ï¼‰
    - Sonnet 3.5: AI åé¦ˆï¼ˆæ…¢ä¸€ç‚¹ä½†æ¸©æš–æœ‰æ·±åº¦ï¼‰
    """
    
    # ğŸ¯ æ¨¡å‹é…ç½®
    MODEL_CONFIG = {
        # è¯­éŸ³è½¬æ–‡å­—ï¼ˆä¿æŒä¸å˜ï¼‰
        "transcription": "whisper-1",
        
        # ğŸ”¥ æ–°å¢ï¼šClaude æ¨¡å‹é…ç½®
        # âš ï¸ ä¸´æ—¶ï¼šHaiku 3.5 æ­£åœ¨ç”³è¯· inference profileï¼Œæš‚æ—¶ä½¿ç”¨ GPT-4o-mini æ›¿ä»£ï¼ˆé¿å…é™æµï¼‰
        # TODO: ç”³è¯·é€šè¿‡åï¼Œä»å¤‡ä»½æ–‡ä»¶æ¢å¤ Haiku 3.5 è°ƒç”¨: openai_service.py.backup-sonnet-haiku
        "haiku": "gpt-4o-mini",  # ä¸´æ—¶ï¼šç”¨ GPT-4o-mini æ›¿ä»£ï¼ˆæ¶¦è‰² + æ ‡é¢˜ï¼‰
        "sonnet": "anthropic.claude-3-5-sonnet-20240620-v1:0",  # AI åé¦ˆï¼ˆæ¸©æš–ã€æœ‰æ·±åº¦ï¼‰
        
        # ğŸ¤ ä¸ºä»€ä¹ˆ Whisperï¼Ÿ
        # âœ… OpenAI å®˜æ–¹è¯­éŸ³è½¬æ–‡å­—æ¨¡å‹
        # âœ… æ”¯æŒ 100+ è¯­è¨€ï¼ˆä¸­è‹±æ–‡å®Œç¾ï¼‰
        # âœ… é«˜å‡†ç¡®åº¦ï¼Œä½å¹»è§‰ç‡
        
        # ğŸ¨ ä¸ºä»€ä¹ˆ Haiku æ¶¦è‰²ï¼Ÿ
        # âœ… é€Ÿåº¦å¿«ï¼ˆ1-2ç§’ï¼‰
        # âœ… ä¾¿å®œï¼ˆ$1/1M tokens inputï¼‰
        # âœ… è¶³å¤Ÿèªæ˜ï¼ˆæ—¥è®°æ¶¦è‰²ç»°ç»°æœ‰ä½™ï¼‰
        
        # ğŸ’¬ ä¸ºä»€ä¹ˆ Sonnet åé¦ˆï¼Ÿ
        # âœ… æ¸©æš–æœ‰æ·±åº¦ï¼ˆå…±æƒ…èƒ½åŠ›å¼ºï¼‰
        # âœ… ä¸­æ–‡è¡¨è¾¾è‡ªç„¶ï¼ˆæ¯” GPT æ›´å¥½ï¼‰
        # âœ… å€¼å¾—æ…¢ä¸€ç‚¹ï¼ˆç”¨æˆ·æœŸå¾…æœ‰æ·±åº¦çš„åé¦ˆï¼‰
    }
    
    # ğŸ“ é•¿åº¦é™åˆ¶ï¼ˆä¿æŒä¸å˜ï¼‰
    LENGTH_LIMITS = {
        "title_min": 4,
        "title_max": 50,
        "feedback_min": 30,
        "feedback_max": 250,
        "polished_ratio": 1.15,
        "min_audio_text": 5,
    }
    
    def __init__(self):
        """åˆå§‹åŒ–æœåŠ¡å®¢æˆ·ç«¯"""
        settings = get_settings()
        
        # OpenAI å®¢æˆ·ç«¯ï¼ˆç”¨äº Whisperï¼‰
        self.openai_client = OpenAI(api_key=settings.openai_api_key)
        
        # ğŸ”¥ æ–°å¢ï¼šAWS Bedrock å®¢æˆ·ç«¯
        # ä½¿ç”¨ settings ä¸­çš„ regionï¼Œè€Œä¸æ˜¯ç›´æ¥è¯»å–ç¯å¢ƒå˜é‡
        region = settings.aws_region or os.getenv('AWS_REGION', 'us-east-1')
        
        try:
            self.bedrock_client = boto3.client(
                service_name='bedrock-runtime',
                region_name=region
            )
            print(f"âœ… Bedrock å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ (åŒºåŸŸ: {region})")
        except Exception as e:
            print(f"âŒ Bedrock å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {type(e).__name__}: {e}")
            print(f"ğŸ“ æç¤º: è¯·æ£€æŸ¥ AWS å‡­è¯é…ç½®")
            import traceback
            traceback.print_exc()
            raise
        
        print(f"âœ… AI æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
        print(f"   - Whisper: è¯­éŸ³è½¬æ–‡å­—")
        print(f"   - Haiku 3.5: æ¶¦è‰² + æ ‡é¢˜ (æ¨¡å‹: {self.MODEL_CONFIG['haiku']}) âš ï¸ ä¸´æ—¶ä½¿ç”¨ GPT-4o-mini")
        print(f"   - Sonnet 3.5: AI åé¦ˆ (æ¨¡å‹: {self.MODEL_CONFIG['sonnet']})")
    
    # ========================================================================
    # è¯­éŸ³è½¬æ–‡å­—ï¼ˆä¿æŒä¸å˜ï¼‰
    # ========================================================================
    
    async def transcribe_audio(
        self, 
        audio_content: bytes, 
        filename: str
    ) -> str:
        """
        è¯­éŸ³è½¬æ–‡å­— - æŠŠä½ çš„å£°éŸ³å˜æˆæ–‡å­—
        
        ğŸ”¥ æ³¨æ„ï¼šè¿™ä¸ªæ–¹æ³•å®Œå…¨ä¸å˜ï¼Œç»§ç»­ä½¿ç”¨ Whisper
        
        å·¥ä½œæµç¨‹ï¼š
        1. æ”¶åˆ°éŸ³é¢‘ â†’ æ£€æŸ¥å¤§å°
        2. åˆ›å»ºä¸´æ—¶æ–‡ä»¶ â†’ ç¡®ä¿æ ¼å¼æ­£ç¡®
        3. å‘é€ç»™ Whisper â†’ å®ƒæ˜¯è¯­éŸ³è¯†åˆ«ä¸“å®¶
        4. æ£€æŸ¥ç»“æœ â†’ ç¡®ä¿ä¸æ˜¯ç©ºçš„
        5. æ¸…ç†ä¸´æ—¶æ–‡ä»¶ â†’ ä¿æŒæ•´æ´
        """
        temp_file_path = None
        
        try:
            # æ£€æŸ¥éŸ³é¢‘å¤§å°
            audio_size_kb = len(audio_content) / 1024
            print(f"ğŸ¤ æ”¶åˆ°éŸ³é¢‘: {filename}, å¤§å°: {audio_size_kb:.1f} KB")
            
            if audio_size_kb < 1:
                raise ValueError("éŸ³é¢‘æ–‡ä»¶å¤ªå°ï¼Œè¯·è¯´é•¿ä¸€ç‚¹")
            
            # å‡†å¤‡ä¸´æ—¶æ–‡ä»¶
            suffix = '.m4a' if not filename.endswith('.m4a') else ''
            with tempfile.NamedTemporaryFile(
                delete=False, 
                suffix=suffix or os.path.splitext(filename)[1]
            ) as temp_file:
                temp_file.write(audio_content)
                temp_file_path = temp_file.name
            
            print(f"âœ… ä¸´æ—¶æ–‡ä»¶å‡†å¤‡å®Œæˆ")
            
            # è°ƒç”¨ Whisper
            with open(temp_file_path, 'rb') as audio_file:
                print(f"ğŸ“¤ æ­£åœ¨è¯†åˆ«è¯­éŸ³...")
                transcription = self.openai_client.audio.transcriptions.create(
                    model=self.MODEL_CONFIG["transcription"],
                    file=audio_file,
                    language=None,
                )
            
            # éªŒè¯ç»“æœ
            text = (transcription.text or "").strip()
            
            if len(text) < self.LENGTH_LIMITS["min_audio_text"]:
                print(f"âŒ è½¬å½•å†…å®¹è¿‡çŸ­: '{text}'")
                raise ValueError("æœªè¯†åˆ«åˆ°æœ‰æ•ˆå†…å®¹ï¼Œè¯·è¯´æ¸…æ¥šä¸€äº›")
            
            print(f"âœ… è¯­éŸ³è¯†åˆ«æˆåŠŸ: '{text[:50]}...'")
            return text
            
        except Exception as e:
            print(f"âŒ è¯­éŸ³è½¬æ–‡å­—å¤±è´¥: {str(e)}")
            if "Invalid file format" in str(e):
                raise ValueError("éŸ³é¢‘æ ¼å¼ä¸æ”¯æŒï¼Œè¯·ä½¿ç”¨ m4a æ ¼å¼")
            elif "File too large" in str(e):
                raise ValueError("éŸ³é¢‘æ–‡ä»¶å¤ªå¤§ï¼Œè¯·æ§åˆ¶åœ¨ 2 åˆ†é’Ÿå†…")
            else:
                raise ValueError(f"è¯­éŸ³è¯†åˆ«å¤±è´¥: {str(e)}")
        
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if temp_file_path and os.path.exists(temp_file_path):
                try:
                    os.unlink(temp_file_path)
                    print(f"ğŸ§¹ ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†")
                except Exception as e:
                    print(f"âš ï¸ æ¸…ç†å¤±è´¥ï¼ˆä¸å½±å“åŠŸèƒ½ï¼‰: {e}")
    
    # ========================================================================
    # ğŸ”¥ æ ¸å¿ƒæ”¹åŠ¨ï¼šæ··åˆæ¨¡å‹å¤„ç†
    # ========================================================================
    
    async def polish_content_multilingual(
        self, 
        text: str,
        user_name: Optional[str] = None  # ç”¨æˆ·åå­—ï¼Œç”¨äºä¸ªæ€§åŒ–åé¦ˆ
    ) -> Dict[str, str]:
        """
        ğŸ”¥ é‡å¤§æ”¹åŠ¨ï¼šä»å•ä¸€æ¨¡å‹æ”¹ä¸ºæ··åˆæ¨¡å‹ + å¹¶è¡Œæ‰§è¡Œ
        
        æ—§é€»è¾‘ï¼š
        1. GPT-4o-mini ä¸€æ¬¡æ€§ç”Ÿæˆæ¶¦è‰² + æ ‡é¢˜ + åé¦ˆï¼ˆä¸²è¡Œï¼Œ3-5ç§’ï¼‰
        
        æ–°é€»è¾‘ï¼š
        1. Haiku ç”Ÿæˆæ¶¦è‰² + æ ‡é¢˜ï¼ˆ1-2ç§’ï¼‰
        2. Sonnet ç”Ÿæˆåé¦ˆï¼ˆåŸºäºåŸå§‹æ–‡æœ¬ï¼Œ2-3ç§’ï¼‰
        3. ä¸¤ä¸ªä»»åŠ¡å¹¶è¡Œæ‰§è¡Œï¼Œæ€»è€—æ—¶ = max(1-2, 2-3) = 2-3ç§’
        
        ä¸ºä»€ä¹ˆåŸºäºåŸå§‹æ–‡æœ¬ç”Ÿæˆåé¦ˆï¼Ÿ
        - æ›´çœŸå®ï¼šåŸå§‹æ–‡æœ¬ä¿ç•™äº†ç”¨æˆ·æœ€çœŸå®çš„æƒ…æ„Ÿ
        - æ›´å¿«ï¼šä¸éœ€è¦ç­‰æ¶¦è‰²å®Œæˆ
        - æ›´æ¸©æš–ï¼šAI å›åº”"çœŸå®çš„ä½ "è€Œä¸æ˜¯"å®Œç¾çš„æ–‡å­—"
        """
        try:
            # è¾“å…¥æ£€æŸ¥
            if not text or len(text.strip()) < 5:
                raise ValueError("å†…å®¹å¤ªçŸ­ï¼Œè¯·å¤šå†™ä¸€äº›")
            
            print(f"âœ¨ å¼€å§‹AIå¤„ç†ï¼ˆå¹¶è¡Œæ¨¡å¼ï¼‰: {text[:50]}...")
            
            # æ£€æµ‹è¯­è¨€
            import re
            chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
            is_chinese = chinese_chars > len(text) * 0.2
            detected_lang = "Chinese" if is_chinese else "English"
            
            print(f"ğŸŒ æ£€æµ‹åˆ°è¯­è¨€: {detected_lang}")
            
            # ğŸ”¥ å…³é”®æ”¹åŠ¨ï¼šå¹¶è¡Œæ‰§è¡Œä¸¤ä¸ªä»»åŠ¡
            print(f"ğŸš€ å¯åŠ¨å¹¶è¡Œå¤„ç†...")
            print(f"   - ä»»åŠ¡1: Haiku æ¶¦è‰² + æ ‡é¢˜")
            print(f"   - ä»»åŠ¡2: Sonnet åé¦ˆï¼ˆåŸºäºåŸå§‹æ–‡æœ¬ï¼‰")
            
            # åˆ›å»ºä¸¤ä¸ªå¼‚æ­¥ä»»åŠ¡
            polish_task = self._call_claude_haiku_for_polish(text, detected_lang)
            feedback_task = self._call_claude_sonnet_for_feedback(text, detected_lang, user_name)
            
            # å¹¶è¡Œæ‰§è¡Œå¹¶ç­‰å¾…ç»“æœ
            polish_result, feedback = await asyncio.gather(
                polish_task,
                feedback_task
            )
            
            print(f"âœ… å¹¶è¡Œå¤„ç†å®Œæˆ")
            
            # åˆå¹¶ç»“æœ
            result = {
                "title": polish_result['title'],
                "polished_content": polish_result['polished_content'],
                "feedback": feedback
            }
            
            # è´¨é‡æ£€æŸ¥
            result = self._validate_and_fix_result(result, text)
            
            print(f"âœ… å¤„ç†å®Œæˆ:")
            print(f"  - æ ‡é¢˜: {result['title']}")
            print(f"  - å†…å®¹é•¿åº¦: {len(result['polished_content'])} å­—")
            print(f"  - åé¦ˆé•¿åº¦: {len(result['feedback'])} å­—")
            
            return result
        
        except Exception as e:
            error_type = type(e).__name__
            error_msg = str(e)
            print(f"âŒ AIå¤„ç†å¤±è´¥: {error_type}: {error_msg}")
            import traceback
            error_trace = traceback.format_exc()
            print(f"ğŸ“ å®Œæ•´é”™è¯¯å †æ ˆ:")
            print(error_trace)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å¹¶è¡Œä»»åŠ¡ä¸­çš„é”™è¯¯
            if isinstance(e, (asyncio.TimeoutError, asyncio.CancelledError)):
                print(f"âš ï¸ å¹¶è¡Œä»»åŠ¡è¶…æ—¶æˆ–å–æ¶ˆ")
            elif isinstance(e, Exception):
                print(f"âš ï¸ å¹¶è¡Œä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
            
            return self._create_fallback_result(text)
    
    # ========================================================================
    # ğŸ”¥ æ–°å¢ï¼šClaude Haiku è°ƒç”¨ï¼ˆæ¶¦è‰² + æ ‡é¢˜ï¼‰
    # ========================================================================
    
    async def _call_claude_haiku_for_polish(
        self, 
        text: str,
        language: str
    ) -> Dict[str, str]:
        """
        âš ï¸ ä¸´æ—¶æ–¹æ³•ï¼šè°ƒç”¨ GPT-4o-mini è¿›è¡Œæ¶¦è‰²å’Œç”Ÿæˆæ ‡é¢˜ï¼ˆæ›¿ä»£ Haiku 3.5ï¼Œé¿å…é™æµï¼‰
        
        åŸè®¡åˆ’ä½¿ç”¨ Claude Haiku 3.5ï¼Œä½†æ­£åœ¨ç”³è¯· inference profileï¼Œæš‚æ—¶ä½¿ç”¨ GPT-4o-mini
        ç­‰ Haiku 3.5 ç”³è¯·é€šè¿‡åï¼Œä»å¤‡ä»½æ–‡ä»¶æ¢å¤: openai_service.py.backup-sonnet-haiku
        
        è¿”å›:
            {
                "title": "æ ‡é¢˜",
                "polished_content": "æ¶¦è‰²åçš„å†…å®¹"
            }
        """
        try:
            print(f"ğŸ¨ GPT-4o-mini: å¼€å§‹æ¶¦è‰²å’Œç”Ÿæˆæ ‡é¢˜...")
            
            # æ„å»º prompt
            system_prompt = f"""You are a gentle diary editor. Your task is to polish the user's diary entry and create a title.

Language: Keep everything in {language}. NEVER translate.

Your responsibilities:
1. Fix obvious grammar/typos
2. Make the text flow naturally
3. Keep it â‰¤115% of original length
4. **CRITICAL: Preserve ALL original content. Do NOT delete or omit any part of the user's entry.**
5. Create a short, warm, poetic, meaningful title (6-18 words)

Style: Natural, warm, authentic. Don't over-edit.

Response format (JSON only):
{{
  "title": "6-18 words in {language}",
  "polished_content": "fixed text, same language - MUST include all original content"
}}

Example:
Input: "ä»Šå¤©å¤©æ°”å¾ˆå¥½æˆ‘å»äº†å…¬å›­çœ‹åˆ°äº†å¾ˆå¤šèŠ±"
Output: {{"title": "å…¬å›­é‡Œçš„èŠ±", "polished_content": "ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œæˆ‘å»äº†å…¬å›­ï¼Œçœ‹åˆ°äº†å¾ˆå¤šèŠ±ã€‚"}}"""

            user_prompt = f"Please polish this diary entry (preserve ALL content):\n\n{text}"
            
            # âœ… åŠ¨æ€è®¡ç®— max_tokensï¼šç¡®ä¿è¶³å¤Ÿè¾“å‡ºå®Œæ•´å†…å®¹
            # åŸå§‹æ–‡æœ¬é•¿åº¦ + æ ‡é¢˜ + JSON æ ¼å¼å¼€é”€ + å®‰å…¨è¾¹è·
            original_length = len(text)
            # ä¼°ç®—ï¼šåŸå§‹æ–‡æœ¬ * 1.15ï¼ˆ115%é™åˆ¶ï¼‰ + æ ‡é¢˜ï¼ˆ50å­—ç¬¦ï¼‰ + JSONæ ¼å¼ï¼ˆ100å­—ç¬¦ï¼‰ + å®‰å…¨è¾¹è·ï¼ˆ500å­—ç¬¦ï¼‰
            estimated_output_length = int(original_length * 1.15) + 50 + 100 + 500
            # max_tokens å¤§çº¦æ˜¯å­—ç¬¦æ•°çš„ 0.75ï¼ˆä¸­æ–‡ï¼‰åˆ° 1.5ï¼ˆè‹±æ–‡ï¼‰ï¼Œå–ä¸­é—´å€¼ 1.0
            max_tokens = max(2000, int(estimated_output_length * 1.0))
            # ä½†ä¸è¦è¶…è¿‡ OpenAI çš„é™åˆ¶ï¼ˆGPT-4o-mini æ”¯æŒ 16384 tokensï¼‰
            max_tokens = min(max_tokens, 16000)
            
            print(f"ğŸ“¤ GPT-4o-mini: å‘é€è¯·æ±‚åˆ° OpenAI...")
            print(f"   æ¨¡å‹: {self.MODEL_CONFIG['haiku']}")
            print(f"   åŸå§‹æ–‡æœ¬é•¿åº¦: {original_length} å­—ç¬¦")
            print(f"   ä¼°ç®—è¾“å‡ºé•¿åº¦: {estimated_output_length} å­—ç¬¦")
            print(f"   è®¾ç½® max_tokens: {max_tokens}")
            
            # ä½¿ç”¨ OpenAI clientï¼ˆå·²ç»åœ¨ __init__ ä¸­åˆå§‹åŒ–ï¼‰
            response = await asyncio.to_thread(
                self.openai_client.chat.completions.create,
                model=self.MODEL_CONFIG["haiku"],
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.3,
                max_tokens=max_tokens,
                response_format={"type": "json_object"}  # å¼ºåˆ¶ JSON æ ¼å¼
            )
            
            # è§£æå“åº”
            content = response.choices[0].message.content
            if not content:
                raise ValueError("OpenAI è¿”å›ç©ºå“åº”")
            
            print(f"âœ… GPT-4o-mini: æ”¶åˆ°å“åº”")
            print(f"ğŸ“ GPT-4o-mini: å“åº”å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
            
            # è§£æ JSON
            try:
                result = json.loads(content)
                polished_content = result.get("polished_content", text)
                
                # âœ… æ·»åŠ é•¿åº¦å¯¹æ¯”æ—¥å¿—ï¼Œæ£€æŸ¥æ˜¯å¦è¢«æˆªæ–­
                original_length = len(text)
                polished_length = len(polished_content)
                length_ratio = polished_length / original_length if original_length > 0 else 0
                
                print(f"âœ… GPT-4o-mini: æ¶¦è‰²å®Œæˆ")
                print(f"ğŸ“Š é•¿åº¦å¯¹æ¯”: åŸå§‹={original_length} å­—ç¬¦, æ¶¦è‰²å={polished_length} å­—ç¬¦, æ¯”ä¾‹={length_ratio:.2%}")
                
                # âš ï¸ å¦‚æœæ¶¦è‰²åå†…å®¹æ˜æ˜¾å°‘äºåŸå§‹å†…å®¹ï¼ˆå°äº80%ï¼‰ï¼Œå¯èƒ½æ˜¯è¢«æˆªæ–­äº†
                if polished_length < original_length * 0.8:
                    print(f"âš ï¸ è­¦å‘Šï¼šæ¶¦è‰²åå†…å®¹æ˜æ˜¾å°‘äºåŸå§‹å†…å®¹ï¼Œå¯èƒ½è¢«æˆªæ–­ï¼")
                    print(f"   åŸå§‹å†…å®¹å‰100å­—ç¬¦: {text[:100]}...")
                    print(f"   æ¶¦è‰²åå†…å®¹å‰100å­—ç¬¦: {polished_content[:100]}...")
                    # å¦‚æœç¡®å®è¢«æˆªæ–­ï¼Œä½¿ç”¨åŸå§‹å†…å®¹ä½œä¸ºé™çº§æ–¹æ¡ˆ
                    polished_content = text
                    print(f"   ä½¿ç”¨åŸå§‹å†…å®¹ä½œä¸ºé™çº§æ–¹æ¡ˆ")
                
                return {
                    "title": result.get("title", "Today's Reflection"),
                    "polished_content": polished_content
                }
            except json.JSONDecodeError as e:
                print(f"âš ï¸ GPT-4o-mini: JSON è§£æå¤±è´¥: {e}")
                print(f"   åŸå§‹å“åº”: {content[:200]}...")
                # å°è¯•ä»æ–‡æœ¬ä¸­æå– JSON
                import re
                json_match = re.search(r'\{[^{}]*"title"[^{}]*"polished_content"[^{}]*\}', content)
                if json_match:
                    try:
                        result = json.loads(json_match.group())
                        return {
                            "title": result.get("title", "Today's Reflection"),
                            "polished_content": result.get("polished_content", text)
                        }
                    except:
                        pass
                
                # é™çº§æ–¹æ¡ˆ
                print(f"âš ï¸ GPT-4o-mini: ä½¿ç”¨é™çº§æ–¹æ¡ˆ")
                return {
                    "title": "Today's Reflection" if language == "English" else "ä»Šæ—¥è®°å½•",
                    "polished_content": text
                }
        
        except Exception as e:
            error_type = type(e).__name__
            error_msg = str(e)
            print(f"âŒ GPT-4o-mini è°ƒç”¨å¤±è´¥: {error_type}: {error_msg}")
            
            # è¯¦ç»†é”™è¯¯ä¿¡æ¯
            import traceback
            error_trace = traceback.format_exc()
            print(f"ğŸ“ GPT-4o-mini å®Œæ•´é”™è¯¯å †æ ˆ:")
            print(error_trace)
            
            # æ£€æŸ¥å¸¸è§é”™è¯¯ç±»å‹
            if "RateLimitError" in error_type or "rate_limit" in error_msg.lower():
                print(f"âš ï¸ OpenAI API é™æµ: è¯·æ±‚é¢‘ç‡è¿‡é«˜")
                print(f"ğŸ’¡ å»ºè®®: ç¨åé‡è¯•ï¼Œæˆ–æ£€æŸ¥ OpenAI è´¦æˆ·çš„é…é¢é™åˆ¶")
            elif "AuthenticationError" in error_type or "InvalidApiKey" in error_type:
                print(f"âš ï¸ OpenAI API Key é”™è¯¯: è¯·æ£€æŸ¥ OPENAI_API_KEY ç¯å¢ƒå˜é‡")
            elif "APIConnectionError" in error_type:
                print(f"âš ï¸ OpenAI API è¿æ¥é”™è¯¯: è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
            
            # é™çº§æ–¹æ¡ˆ
            return {
                "title": "Today's Reflection" if language == "English" else "ä»Šæ—¥è®°å½•",
                "polished_content": text
            }
    
    # ========================================================================
    # ğŸ”¥ æ–°å¢:Claude Sonnet è°ƒç”¨ï¼ˆAI åé¦ˆï¼‰
    # ========================================================================
    
    async def _call_claude_sonnet_for_feedback(
        self, 
        text: str,
        language: str,
        user_name: Optional[str] = None
    ) -> str:
        """
        ğŸ”¥ æ–°å¢æ–¹æ³•ï¼šè°ƒç”¨ Claude Sonnet ç”Ÿæˆæ¸©æš–çš„ AI åé¦ˆ
        
        ä¸ºä»€ä¹ˆç”¨ Sonnetï¼Ÿ
        - å…±æƒ…èƒ½åŠ›å¼ºï¼ˆç†è§£æƒ…æ„Ÿç»†è…»ï¼‰
        - ä¸­æ–‡è¡¨è¾¾è‡ªç„¶ï¼ˆæ¯” GPT æ›´å¥½ï¼‰
        - æ¸©æš–æœ‰æ·±åº¦ï¼ˆç¬¦åˆ Thankly å“ç‰Œè°ƒæ€§ï¼‰
        
        ä¸ºä»€ä¹ˆåŸºäºåŸå§‹æ–‡æœ¬ï¼Ÿ
        - æ›´çœŸå®çš„æƒ…æ„Ÿ
        - ä¸éœ€è¦ç­‰æ¶¦è‰²å®Œæˆï¼ˆå¹¶è¡Œï¼‰
        - AI å›åº”"çœŸå®çš„ä½ "
        
        è¿”å›:
            æ¸©æš–çš„åé¦ˆæ–‡å­—ï¼ˆç®€æ´æœ‰åŠ›ï¼Œä¸è¶…è¿‡ç”¨æˆ·è¾“å…¥é•¿åº¦ï¼‰
        """
        try:
            print(f"ğŸ’¬ Sonnet: å¼€å§‹ç”Ÿæˆåé¦ˆï¼ˆåŸºäºåŸå§‹æ–‡æœ¬ï¼‰...")
            print(f"ğŸ‘¤ ç”¨æˆ·åå­—: {user_name if user_name else 'æœªæä¾›'}")
            
            # è®¡ç®—ç”¨æˆ·è¾“å…¥é•¿åº¦ï¼Œç”¨äºåŠ¨æ€è°ƒæ•´åé¦ˆé•¿åº¦
            user_text_length = len(text.strip())
            # åé¦ˆé•¿åº¦ç­–ç•¥ï¼šä¸è¶…è¿‡ç”¨æˆ·è¾“å…¥é•¿åº¦ï¼Œä½†æœ€çŸ­ä¸å°‘äº20å­—ï¼ˆä¸­æ–‡ï¼‰æˆ–15è¯ï¼ˆè‹±æ–‡ï¼‰
            max_feedback_length = max(user_text_length, 20 if language == "Chinese" else 15)
            
            # æ„å»ºä¸ªæ€§åŒ–çš„åå­—ç§°å‘¼
            name_greeting = ""
            if user_name and user_name.strip():
                # æå–åå­—ï¼ˆå»æ‰å¯èƒ½çš„ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦ï¼‰
                import re
                first_name = re.split(r'\s+', user_name.strip())[0]
                if language == "Chinese":
                    name_greeting = f"ï¼Œ{first_name}"
                else:
                    name_greeting = f", {first_name}"
            
            # æ„å»º prompt
            if user_name and user_name.strip():
                # æœ‰ç”¨æˆ·åå­—æ—¶ï¼Œæ˜ç¡®è§„å®šå¿…é¡»ä½¿ç”¨åå­—
                system_prompt = f"""You are a warm, empathetic listener responding to {user_name}'s diary entry.

Language: Respond in {language} ONLY. NEVER translate.

âš ï¸ CRITICAL RULE - YOU MUST FOLLOW THIS:
Your response MUST start with "{user_name}" (followed by a comma in English or a Chinese comma in Chinese), then your message. 
DO NOT use generic greetings like "Hi there", "Hello", or "Hi". 
DO NOT skip the name. 
ALWAYS start with "{user_name}".

Your style:
- Warm and genuine (like a close friend)
- **Keep it SHORT and POWERFUL** - never longer than the user's input (unless their input is very short, <20 chars)
- Maximum length: {max_feedback_length} characters (Chinese) or {max_feedback_length // 2} words (English)
- 1-2 complete sentences (prefer 1 sentence if user's input is short)
- **FIRST WORD MUST BE "{user_name}"** - No exceptions
- Acknowledge their feelings with warmth
- Offer gentle encouragement when appropriate
- Natural, conversational, intimate tone

Response format: Plain text only (NO JSON, NO quotes, NO markdown)

Example responses (MUST follow this exact format):
- Chinese (short input): "{user_name}ï¼Œè¿™ä»½ç®€å•çš„å¿«ä¹å¾ˆçè´µã€‚"
- Chinese (longer input): "{user_name}ï¼Œè¿™ä»½è®°å½•å¾ˆæ¸©æš–ã€‚ç”Ÿæ´»ä¸­çš„å°ç¡®å¹¸ï¼Œå¾€å¾€æ˜¯æœ€æ²»æ„ˆçš„æ—¶åˆ»ã€‚"
- English (short input): "{user_name}, this simple joy is precious."
- English (longer input): "{user_name}, this moment you captured is beautiful. Small joys like this are what make life meaningful."

REMEMBER: 
1. Your response MUST start with "{user_name}" (with comma or Chinese comma)
2. DO NOT use "Hi there", "Hello", "Hi", or any other greeting
3. DO NOT skip the name
4. Be warm, be brief, be personal. Quality over quantity."""
            else:
                # æ²¡æœ‰ç”¨æˆ·åå­—æ—¶ï¼Œä½¿ç”¨é€šç”¨æç¤º
                system_prompt = f"""You are a warm, empathetic listener responding to someone's diary entry.

Language: Respond in {language} ONLY. NEVER translate.

Your style:
- Warm and genuine (like a close friend)
- **Keep it SHORT and POWERFUL** - never longer than the user's input (unless their input is very short, <20 chars)
- Maximum length: {max_feedback_length} characters (Chinese) or {max_feedback_length // 2} words (English)
- 1-2 complete sentences (prefer 1 sentence if user's input is short)
- Acknowledge their feelings with warmth
- Offer gentle encouragement when appropriate
- Natural, conversational, intimate tone

Response format: Plain text only (NO JSON, NO quotes, NO markdown)

Example responses (short and warm):
- Chinese (short input): "è¿™ä»½ç®€å•çš„å¿«ä¹å¾ˆçè´µã€‚"
- Chinese (longer input): "è¿™ä»½è®°å½•å¾ˆæ¸©æš–ã€‚ç”Ÿæ´»ä¸­çš„å°ç¡®å¹¸ï¼Œå¾€å¾€æ˜¯æœ€æ²»æ„ˆçš„æ—¶åˆ»ã€‚"
- English (short input): "This simple joy is precious."
- English (longer input): "This moment you captured is beautiful. Small joys like this are what make life meaningful."

Remember: Be warm, be brief, be personal. Quality over quantity."""

            # æ„å»ºä¸ªæ€§åŒ–çš„ç”¨æˆ·æç¤º
            if user_name:
                user_prompt = f"{user_name} just shared this with you:\n\n{text}\n\nRespond warmly and personally:"
            else:
                user_prompt = f"Someone just shared this with you:\n\n{text}\n\nRespond with warmth and empathy:"
            
            # è°ƒç”¨ Bedrock APIï¼ˆClaude 3.5 æ ¼å¼ï¼‰
            # åŠ¨æ€è°ƒæ•´ max_tokensï¼šæ ¹æ®ç”¨æˆ·è¾“å…¥é•¿åº¦ï¼Œä½†ä¸è¶…è¿‡200
            max_tokens = min(max(user_text_length // 2, 50), 200)
            
            request_body = {
                "anthropic_version": "bedrock-2023-05-31",
                "max_tokens": max_tokens,
                "temperature": 0.7,
                "system": system_prompt,
                "messages": [
                    {
                        "role": "user",
                        "content": user_prompt
                    }
                ]
            }
            
            # ğŸ”¥ æ ¸å¿ƒï¼šè°ƒç”¨ Bedrockï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼Œå¤„ç†é™æµï¼‰
            print(f"ğŸ“¤ Sonnet: å‘é€è¯·æ±‚åˆ° Bedrock...")
            print(f"   æ¨¡å‹: {self.MODEL_CONFIG['sonnet']}")
            print(f"   åŒºåŸŸ: {self.bedrock_client.meta.region_name}")
            print(f"   ç”¨æˆ·åå­—: {user_name if user_name else 'æœªæä¾›'}")
            print(f"   System prompt å‰100å­—ç¬¦: {system_prompt[:100]}...")
            
            # æ³¨æ„ï¼šboto3 invoke_model ä¼šè‡ªåŠ¨å¤„ç† content-type
            # éœ€è¦ç¡®ä¿ body æ˜¯ bytes æ ¼å¼
            request_bytes = json.dumps(request_body).encode('utf-8')
            
            # ğŸ”¥ å®ç°å¸¦æŒ‡æ•°é€€é¿çš„é‡è¯•æœºåˆ¶ï¼ˆä¸“é—¨å¤„ç†é™æµï¼‰
            # å¢åŠ é‡è¯•é—´éš”ï¼Œå‡å°‘é™æµæ¦‚ç‡
            max_retries = 5  # æœ€å¤šé‡è¯•5æ¬¡
            base_delay = 2.0  # åŸºç¡€å»¶è¿Ÿ2ç§’ï¼ˆä»1ç§’å¢åŠ åˆ°2ç§’ï¼Œå‡å°‘é™æµï¼‰
            
            for attempt in range(max_retries):
                try:
                    response = await asyncio.to_thread(
                        self.bedrock_client.invoke_model,
                        modelId=self.MODEL_CONFIG["sonnet"],
                        body=request_bytes
                    )
                    # æˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                    break
                    
                except ClientError as e:
                    error_code = e.response.get('Error', {}).get('Code', '')
                    
                    # å¦‚æœæ˜¯é™æµé”™è¯¯ï¼Œè¿›è¡Œé‡è¯•
                    if error_code == 'ThrottlingException' and attempt < max_retries - 1:
                        # æŒ‡æ•°é€€é¿ï¼š2ç§’ã€4ç§’ã€8ç§’ã€16ç§’ã€32ç§’ï¼ˆä»1ç§’åŸºç¡€å»¶è¿Ÿæ”¹ä¸º2ç§’ï¼‰
                        delay = base_delay * (2 ** attempt)
                        print(f"âš ï¸ Sonnet: é‡åˆ°é™æµï¼Œç­‰å¾… {delay:.1f} ç§’åé‡è¯• (å°è¯• {attempt + 1}/{max_retries})...")
                        print(f"   ğŸ’¡ æç¤ºï¼šSonnet é™æµé¢‘ç¹ï¼Œå¯èƒ½æ˜¯è¯·æ±‚é¢‘ç‡è¿‡é«˜ã€‚å»ºè®®ç¨åå†è¯•ã€‚")
                        await asyncio.sleep(delay)
                        continue
                    else:
                        # å…¶ä»–é”™è¯¯æˆ–é‡è¯•æ¬¡æ•°ç”¨å°½ï¼ŒæŠ›å‡ºå¼‚å¸¸
                        raise
            
            # è§£æå“åº”
            response_bytes = response['body'].read()
            if not response_bytes:
                raise ValueError("Bedrock è¿”å›ç©ºå“åº”")
            
            response_body = json.loads(response_bytes)
            print(f"âœ… Sonnet: æ”¶åˆ°å“åº”ï¼ŒçŠ¶æ€ç : {response.get('ResponseMetadata', {}).get('HTTPStatusCode', 'N/A')}")
            
            # æå–åé¦ˆå†…å®¹å¹¶æ‰“å°ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            if 'content' in response_body and len(response_body['content']) > 0:
                feedback_text = response_body['content'][0].get('text', '')
                print(f"ğŸ“ Sonnet åé¦ˆå†…å®¹: {feedback_text[:100]}...")
                # æ£€æŸ¥æ˜¯å¦åŒ…å«ç”¨æˆ·åå­—
                if user_name and user_name.strip():
                    if user_name.lower() in feedback_text.lower():
                        print(f"âœ… åé¦ˆä¸­åŒ…å«ç”¨æˆ·åå­— '{user_name}'")
                    else:
                        print(f"âš ï¸ è­¦å‘Šï¼šåé¦ˆä¸­æœªåŒ…å«ç”¨æˆ·åå­— '{user_name}'ï¼")
                        print(f"   åé¦ˆå†…å®¹: {feedback_text}")
            
            # æ£€æŸ¥å“åº”ç»“æ„
            if 'content' not in response_body:
                print(f"âš ï¸ Sonnet: å“åº”ç»“æ„å¼‚å¸¸: {response_body}")
                raise ValueError(f"Bedrock å“åº”æ ¼å¼é”™è¯¯: ç¼ºå°‘ 'content' å­—æ®µ")
            
            if not response_body['content'] or len(response_body['content']) == 0:
                print(f"âš ï¸ Sonnet: å“åº”å†…å®¹ä¸ºç©º")
                raise ValueError("Bedrock è¿”å›ç©ºå†…å®¹")
            
            feedback = response_body['content'][0]['text'].strip()
            
            print(f"âœ… Sonnet: åé¦ˆç”Ÿæˆå®Œæˆ")
            print(f"   åé¦ˆ: {feedback[:50]}...")
            
            return feedback
        
        except Exception as e:
            error_type = type(e).__name__
            error_msg = str(e)
            print(f"âŒ Sonnet è°ƒç”¨å¤±è´¥: {error_type}: {error_msg}")
            
            # è¯¦ç»†é”™è¯¯ä¿¡æ¯
            import traceback
            error_trace = traceback.format_exc()
            print(f"ğŸ“ Sonnet å®Œæ•´é”™è¯¯å †æ ˆ:")
            print(error_trace)
            
            # æ£€æŸ¥å¸¸è§é”™è¯¯ç±»å‹
            if "ThrottlingException" in error_type or "Throttling" in error_msg:
                print(f"âš ï¸ AWS Bedrock é™æµ: è¯·æ±‚é¢‘ç‡è¿‡é«˜ï¼Œå·²å°è¯•é‡è¯•ä½†ä»å¤±è´¥")
                print(f"ğŸ’¡ å»ºè®®: ç¨åé‡è¯•ï¼Œæˆ–æ£€æŸ¥ AWS è´¦æˆ·çš„ Bedrock é…é¢é™åˆ¶")
            elif "CredentialsError" in error_type or "NoCredentialsError" in error_type:
                print(f"âš ï¸ AWS å‡­è¯é”™è¯¯: è¯·é…ç½® AWS_ACCESS_KEY_ID å’Œ AWS_SECRET_ACCESS_KEY")
            elif "ValidationException" in error_type:
                print(f"âš ï¸ Bedrock API æ ¼å¼é”™è¯¯: è¯·æ£€æŸ¥æ¨¡å‹ ID å’Œè¯·æ±‚æ ¼å¼")
            elif "AccessDeniedException" in error_type:
                print(f"âš ï¸ æƒé™ä¸è¶³: è¯·æ£€æŸ¥ IAM æƒé™æ˜¯å¦åŒ…å« bedrock:InvokeModel")
            elif "ResourceNotFoundException" in error_type:
                print(f"âš ï¸ æ¨¡å‹ä¸å­˜åœ¨: è¯·æ£€æŸ¥æ¨¡å‹ ID æ˜¯å¦æ­£ç¡®")
            
            # é™çº§æ–¹æ¡ˆ
            return "æ„Ÿè°¢åˆ†äº«ä½ çš„è¿™ä¸€åˆ»ã€‚" if language == "Chinese" else "Thanks for sharing this moment."
    
    # ========================================================================
    # éªŒè¯å’Œé™çº§é€»è¾‘ï¼ˆä¿æŒä¸å˜ï¼‰
    # ========================================================================
    
    def _validate_and_fix_result(
        self, 
        result: Dict[str, str], 
        original_text: str
    ) -> Dict[str, str]:
        """
        éªŒè¯å¹¶ä¿®æ­£AIè¾“å‡º - è´¨é‡æŠŠå…³
        
        ğŸ”¥ æ³¨æ„ï¼šè¿™ä¸ªæ–¹æ³•å®Œå…¨ä¿æŒä¸å˜
        """
        import re
        
        orig_len = len(original_text.strip())
        
        # æ£€æµ‹è¯­è¨€
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', original_text))
        is_chinese = chinese_chars > len(original_text) * 0.2
        
        print(f"ğŸ“Š åŸæ–‡è¯­è¨€æ£€æµ‹: æ€»é•¿åº¦={len(original_text)}, ä¸­æ–‡å­—ç¬¦={chinese_chars}, åˆ¤å®š={'ä¸­æ–‡' if is_chinese else 'è‹±æ–‡'}")
        
        # æå–å„éƒ¨åˆ†
        title = (result.get("title", "") or "").strip()
        polished = (result.get("polished_content", "") or "").strip()
        feedback = (result.get("feedback", "") or "").strip()
        
        # éªŒè¯è¯­è¨€ä¸€è‡´æ€§
        title_has_chinese = bool(re.search(r'[\u4e00-\u9fff]', title))
        feedback_has_chinese = bool(re.search(r'[\u4e00-\u9fff]', feedback))
        
        used_fallback = False
        
        if is_chinese != title_has_chinese:
            print(f"âš ï¸ æ ‡é¢˜è¯­è¨€ä¸ä¸€è‡´ï¼")
            title = "ä»Šæ—¥è®°å½•" if is_chinese else "Today's Reflection"
            used_fallback = True
        
        if is_chinese != feedback_has_chinese:
            print(f"âš ï¸ åé¦ˆè¯­è¨€ä¸ä¸€è‡´ï¼")
            feedback = "æ„Ÿè°¢åˆ†äº«ä½ çš„è¿™ä¸€åˆ»ã€‚" if is_chinese else "Thanks for sharing this moment."
            used_fallback = True
        
        # æ¸…ç†å‡½æ•°
        def clean_text(text: str) -> str:
            text = re.sub(r'[\U0001F300-\U0001FAFF\U00002700-\U000027BF]+', '', text)
            text = text.replace('ï¼', 'ã€‚').replace('!', '.')
            text = re.sub(r'\s+', ' ', text).strip()
            return text
        
        def trim_to_complete_sentences(text: str, max_len: int) -> str:
            if len(text) <= max_len:
                return text
            
            sentence_pattern = r"([ã€‚ï¼ï¼Ÿ.!?])(['\"\"ã€ã€)]?)\s*"
            sentences = []
            last_end = 0
            
            for match in re.finditer(sentence_pattern, text):
                end_pos = match.end()
                sentence = text[last_end:end_pos].strip()
                if sentence:
                    sentences.append(sentence)
                last_end = end_pos
            
            if last_end < len(text):
                remaining = text[last_end:].strip()
                if remaining:
                    sentences.append(remaining)
            
            if not sentences:
                for punct in ['ã€‚', '.', 'ï¼', '!', 'ï¼Ÿ', '?', 'ï¼›', ';']:
                    idx = text.rfind(punct, 0, max_len + 1)
                    if idx > max_len * 0.5:
                        return text[:idx + 1].strip()
                return text
            
            result = []
            current_len = 0
            
            for sentence in sentences:
                sentence_len = len(sentence)
                if current_len + sentence_len <= max_len:
                    result.append(sentence)
                    current_len += sentence_len
                else:
                    if len(result) == 0:
                        return text[:max_len].strip() if max_len < len(text) else text
                    break
            
            if not result:
                return text[:max_len].strip()
            
            has_chinese = any('\u4e00' <= char <= '\u9fff' for char in ''.join(result))
            separator = '' if has_chinese else ' '
            
            return separator.join(result).strip()
        
        # ä¿®æ­£æ ‡é¢˜
        title = clean_text(title)
        title = re.sub(r'[^\w\u4e00-\u9fff\s-]', '', title)
        title = re.sub(r'\s+', ' ', title).strip()
        
        if len(title) < self.LENGTH_LIMITS["title_min"]:
            title = "Today's Reflection" if any(ord(c) < 128 for c in original_text) else "ä»Šæ—¥è®°å½•"
        elif len(title) > self.LENGTH_LIMITS["title_max"]:
            max_len = self.LENGTH_LIMITS["title_max"]
            if ' ' in title and len(title) > max_len:
                words = title[:max_len].rsplit(' ', 1)
                title = words[0] if len(words[0]) > max_len * 0.6 else title[:max_len]
            else:
                title = title[:max_len]
        
        # ä¿®æ­£æ¶¦è‰²å†…å®¹
        polished = clean_text(polished)
        max_polished_len = int(orig_len * self.LENGTH_LIMITS["polished_ratio"])
        
        # âœ… æ·»åŠ é•¿åº¦æ£€æŸ¥æ—¥å¿—
        print(f"ğŸ“Š æ¶¦è‰²å†…å®¹éªŒè¯: åŸå§‹é•¿åº¦={orig_len}, æ¶¦è‰²åé•¿åº¦={len(polished)}, æœ€å¤§å…è®¸é•¿åº¦={max_polished_len}")
        
        # âš ï¸ å¦‚æœæ¶¦è‰²åå†…å®¹æ˜æ˜¾å°‘äºåŸå§‹å†…å®¹ï¼ˆå°äº80%ï¼‰ï¼Œå¯èƒ½æ˜¯è¢«æˆªæ–­äº†ï¼Œä½¿ç”¨åŸå§‹å†…å®¹
        if len(polished) < orig_len * 0.8:
            print(f"âš ï¸ è­¦å‘Šï¼šæ¶¦è‰²åå†…å®¹æ˜æ˜¾å°‘äºåŸå§‹å†…å®¹ï¼ˆ{len(polished)} < {orig_len * 0.8}ï¼‰ï¼Œä½¿ç”¨åŸå§‹å†…å®¹")
            polished = original_text.strip()
        
        # åªæœ‰åœ¨è¶…è¿‡æœ€å¤§é•¿åº¦æ—¶æ‰æˆªæ–­ï¼ˆä½†è¿™ç§æƒ…å†µä¸åº”è¯¥å‘ç”Ÿï¼Œå› ä¸ºæç¤ºè¯è¦æ±‚â‰¤115%ï¼‰
        if len(polished) > max_polished_len:
            print(f"âš ï¸ æ¶¦è‰²åå†…å®¹è¶…è¿‡æœ€å¤§é•¿åº¦ï¼ˆ{len(polished)} > {max_polished_len}ï¼‰ï¼ŒæŒ‰å®Œæ•´å¥å­æˆªæ–­")
            polished = trim_to_complete_sentences(polished, max_polished_len)
        
        # ä¿®æ­£åé¦ˆ
        feedback = clean_text(feedback)
        
        if not used_fallback and len(feedback) < self.LENGTH_LIMITS.get("feedback_min", 20):
            print(f"âš ï¸ åé¦ˆè¿‡çŸ­ï¼Œä½¿ç”¨é™çº§")
            feedback = "æ„Ÿè°¢åˆ†äº«ä½ çš„è¿™ä¸€åˆ»ã€‚" if is_chinese else "Thanks for sharing this moment."
        
        if len(feedback) > self.LENGTH_LIMITS["feedback_max"]:
            print(f"ğŸ“ åé¦ˆè¿‡é•¿ï¼ŒæŒ‰å®Œæ•´å¥å­æˆªæ–­")
            feedback = trim_to_complete_sentences(feedback, self.LENGTH_LIMITS["feedback_max"])
        
        is_english = any(ord(c) < 128 for c in original_text[:50])
        default_feedback = "Thank you for sharing." if is_english else "æ„Ÿè°¢åˆ†äº«ã€‚"
        
        return {
            "title": title,
            "polished_content": polished or original_text,
            "feedback": feedback or default_feedback
        }
    
    def _create_fallback_result(self, text: str) -> Dict[str, str]:
        """
        åˆ›å»ºé™çº§ç»“æœ
        
        ğŸ”¥ æ³¨æ„ï¼šè¿™ä¸ªæ–¹æ³•å®Œå…¨ä¿æŒä¸å˜
        """
        import re
        
        print("âš ï¸ ä½¿ç”¨é™çº§æ–¹æ¡ˆ")
        
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
        is_chinese = chinese_chars > len(text) * 0.2
        
        return {
            "title": "ä»Šæ—¥è®°å½•" if is_chinese else "Today's Reflection",
            "polished_content": text,
            "feedback": "æ„Ÿè°¢åˆ†äº«ã€‚" if is_chinese else "Thanks for sharing."
        }
    
    # ========================================================================
    # å‘åå…¼å®¹æ–¹æ³•ï¼ˆä¿æŒä¸å˜ï¼‰
    # ========================================================================
    
    def polish_text(self, text: str) -> str:
        """æ¶¦è‰²æ–‡æœ¬ï¼ˆæ—§APIï¼‰"""
        result = self.polish_content_multilingual(text)
        return result["polished_content"]
    
    def generate_feedback(self, diary_content: str) -> str:
        """ç”Ÿæˆåé¦ˆï¼ˆæ—§APIï¼‰"""
        result = self.polish_content_multilingual(diary_content)
        return result["feedback"]


# ğŸ¯ ä½¿ç”¨ç¤ºä¾‹
"""
# 1. åˆå§‹åŒ–æœåŠ¡
service = OpenAIService()

# 2. è¯­éŸ³è½¬æ–‡å­—ï¼ˆWhisperï¼‰
text = await service.transcribe_audio(audio_bytes, "recording.m4a")

# 3. å¹¶è¡Œå¤„ç†ï¼šæ¶¦è‰²ï¼ˆHaikuï¼‰+ åé¦ˆï¼ˆSonnetï¼‰
result = await service.polish_content_multilingual(text)

# 4. ä½¿ç”¨ç»“æœ
print(f"æ ‡é¢˜: {result['title']}")        # Haiku ç”Ÿæˆ
print(f"å†…å®¹: {result['polished_content']}")  # Haiku æ¶¦è‰²
print(f"åé¦ˆ: {result['feedback']}")      # Sonnet ç”Ÿæˆ
"""