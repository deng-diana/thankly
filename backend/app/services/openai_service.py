"""
AI æœåŠ¡ - æ··åˆæ¨¡å‹ä¼˜åŒ–ç‰ˆæœ¬
ä½œè€…çµæ„Ÿæ¥æºï¼šä¹”å¸ƒæ–¯çš„ç®€çº¦å“²å­¦ + å¼ å°é¾™çš„å…‹åˆ¶è®¾è®¡

ğŸ”¥ æœ€æ–°æ›´æ–°ï¼š
1. AI æš–å¿ƒåé¦ˆä» Claude Sonnet å›å½’ OpenAI GPT-4o-miniï¼ˆTestFlight éªŒè¯ç¨³å®šç‰ˆï¼‰
2. æ¶¦è‰² + æ ‡é¢˜ä¸åé¦ˆç»Ÿä¸€ä½¿ç”¨ GPT-4o-miniï¼ˆé™ä½ç»´æŠ¤æˆæœ¬ï¼‰
3. å¹¶è¡Œæ‰§è¡Œç­–ç•¥ä¿æŒä¸å˜ï¼Œæ€§èƒ½ç»§ç»­ç¨³å®š
4. Whisper è¯­éŸ³è½¬æ–‡å­—æŒç»­æ²¿ç”¨ï¼Œä¿è¯è¯†åˆ«å‡†ç¡®åº¦

æ ¸å¿ƒç†å¿µï¼š
1. ç®€å•ä½†ä¸ç®€é™‹ï¼ˆSimple but not simplisticï¼‰
2. å¼ºå¤§ä½†ä¸å¤æ‚ï¼ˆPowerful but not complicatedï¼‰
3. ä¼˜é›…ä½†ä¸ç‚«æŠ€ï¼ˆElegant but not showyï¼‰
"""

import tempfile
import os
import json
import asyncio  # ğŸ”¥ ç”¨äºå¹¶è¡Œæ‰§è¡Œ
import re  # ç”¨äºæ–‡æœ¬å¤„ç†
import traceback  # ç”¨äºé”™è¯¯è¿½è¸ª
from typing import Dict, Optional, List, Any
from openai import OpenAI, AsyncOpenAI, APIError, RateLimitError, APIConnectionError
import io
import base64
import requests
import httpx  # âœ… ç»Ÿä¸€å¯¼å…¥ï¼Œç”¨äºå¼‚æ­¥ HTTP è¯·æ±‚
import time as time_module

# âœ… Phase 1.4: æ·»åŠ é‡è¯•æœºåˆ¶
from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type,
    before_sleep_log,
)
import logging

# é…ç½®æ—¥å¿—ç”¨äºé‡è¯•
logger = logging.getLogger(__name__)

from ..config import get_settings


class OpenAIService:
    """
    AI æœåŠ¡ç±» - æ”¯æŒå¤šè¯­è¨€æ—¥è®°å¤„ç†
    
    è¿™ä¸ªç±»å°±åƒä¸€ä¸ªæ¸©æŸ”çš„æ—¥è®°åŠ©æ‰‹ï¼Œå®ƒä¼šï¼š
    1. å¬æ‡‚ä½ çš„å£°éŸ³ï¼ˆè¯­éŸ³è½¬æ–‡å­— - Whisperï¼‰
    2. ç¾åŒ–ä½ çš„æ–‡å­—ï¼ˆè½»åº¦æ¶¦è‰² - GPT-4o-miniï¼‰
    3. å‡†ç¡®ç†è§£ä½ çš„æƒ…ç»ªï¼ˆæƒ…ç»ªåˆ†æ - GPT-4oï¼‰ğŸ”¥ å‡†ç¡®åº¦ä¼˜å…ˆ
    4. ç»™ä½ æ¸©æš–çš„å›åº”ï¼ˆå¿ƒç†é™ªä¼´ - GPT-4o-miniï¼‰
    5. å¸®ä½ èµ·ä¸ªå¥½æ ‡é¢˜ï¼ˆç”»é¾™ç‚¹ç› - GPT-4o-miniï¼‰
    
    ğŸ”¥ æ¨¡å‹é€‰æ‹©ç­–ç•¥ï¼ˆ2026-01-27 v2ï¼‰ï¼š
    - Whisper: è¯­éŸ³è½¬æ–‡å­—ï¼ˆOpenAIï¼Œæ— å¯æ›¿ä»£ï¼‰
    - GPT-4o-mini: æ¶¦è‰² + æ ‡é¢˜ï¼ˆé€Ÿåº¦ä¼˜å…ˆï¼Œä¼˜åŒ–æç¤ºè¯ä¿è¯è´¨é‡ï¼‰
    - GPT-4o: æƒ…ç»ªåˆ†æï¼ˆğŸ”¥ å‡†ç¡®åº¦ä¼˜å…ˆï¼Œå½±å“æƒ…ç»ªæ—¥å†/å¹¸ç¦ç½ï¼‰
    - GPT-4o-mini: AI åé¦ˆï¼ˆé€Ÿåº¦ä¼˜å…ˆï¼Œä¼˜åŒ–æç¤ºè¯ä¿è¯æ¸©åº¦ï¼‰
    """
    
    # ğŸ¯ æ¨¡å‹é…ç½® - OpenAI Models Only
    MODEL_CONFIG = {
        # è¯­éŸ³è½¬æ–‡å­—
        "transcription": "whisper-1",
        
        # ğŸ”¥ GPT æ¨¡å‹é…ç½® - 2026-01-27 v2 ä¼˜åŒ–ç‰ˆ
        # ç­–ç•¥: é€Ÿåº¦æ•æ„Ÿä»»åŠ¡ç”¨ miniï¼Œå‡†ç¡®åº¦æ•æ„Ÿä»»åŠ¡ç”¨ 4o
        "polish": "gpt-4o-mini",         # æ¶¦è‰² + æ ‡é¢˜: é€Ÿåº¦ä¼˜å…ˆï¼Œä¼˜åŒ–æç¤ºè¯ä¿è¯è´¨é‡
        "emotion": "gpt-4o",             # ğŸ”¥ æƒ…ç»ªåˆ†æ: å‡†ç¡®åº¦ä¼˜å…ˆï¼ˆå½±å“æƒ…ç»ªæ—¥å†/å¹¸ç¦ç½ï¼‰
        "emotion_fast": "gpt-4o-mini",   # âœ… æƒ…ç»ªåˆ†æå¿«é€Ÿæ¨¡å‹ï¼ˆä½ç½®ä¿¡åº¦å†ç”¨ gpt-4o å¤æ ¸ï¼‰
        "feedback": "gpt-4o-mini",       # æ¸©æš–åé¦ˆ: é€Ÿåº¦ä¼˜å…ˆï¼Œä¼˜åŒ–æç¤ºè¯ä¿è¯æ¸©åº¦
        
        # ğŸ¤ ä¸ºä»€ä¹ˆ Whisperï¼Ÿ
        # âœ… OpenAI å®˜æ–¹è¯­éŸ³è½¬æ–‡å­—æ¨¡å‹
        # âœ… æ”¯æŒ 100+ è¯­è¨€ï¼ˆä¸­è‹±æ–‡å®Œç¾ï¼‰
        # âœ… é«˜å‡†ç¡®åº¦ï¼Œä½å¹»è§‰ç‡
        
        # ğŸ¨ ä¸ºä»€ä¹ˆ Polish ç”¨ gpt-4oï¼Ÿï¼ˆä¿æŒé«˜è´¨é‡ï¼‰
        # âœ… è¯­è¨€è´¨é‡æå‡ 3-5 å€ - è¾¾åˆ°æ¯è¯­æ°´å¹³
        # âœ… å®Œç¾å¤„ç†è¯­æ°”è¯å’Œåœé¡¿ - é€‚åˆè¯­è¨€å­¦ä¹ 
        # âœ… ç»†èŠ‚æ‰“ç£¨ç²¾è‡´ - å£è¯­è½¬ä¹¦é¢è¯­èƒ½åŠ›å¼º
        # âœ… æ•™å­¦çº§åˆ«è¾“å‡º - ç”¨æˆ·å¯é€šè¿‡å¯¹æ¯”å­¦ä¹ è‹±è¯­
        # âœ… ç”¨æˆ·ä½“éªŒä¼˜å…ˆ - æ¶¦è‰²æ˜¯æœ€ç›´æ¥çš„æ„Ÿå—
        
        # ğŸ¯ ä¸ºä»€ä¹ˆ Emotion ç”¨ gpt-4o-miniï¼Ÿï¼ˆé€Ÿåº¦ä¸è´¨é‡å¹³è¡¡ï¼‰
        # âœ… é€Ÿåº¦å¿« 3 å€ (2.5s â†’ 0.8s)
        # âœ… æˆæœ¬é™ä½ 15 å€
        # âœ… 24ç§æƒ…ç»ªä¸­ï¼Œ80%æ˜¯æ˜æ˜¾çš„ï¼ˆ"å¼€å¿ƒ"ã€"éš¾è¿‡"ï¼‰
        # âœ… å‡†ç¡®åº¦ä¾ç„¶å¾ˆé«˜ï¼ˆ85-90%ï¼‰
        # âœ… é…åˆä¼˜åŒ–çš„æç¤ºè¯ï¼ˆFew-Shotï¼‰ï¼Œå‡†ç¡®åº¦å¯è¾¾90%
        
        # ğŸ’¬ ä¸ºä»€ä¹ˆ Feedback ç”¨ gpt-4o-miniï¼Ÿï¼ˆé€Ÿåº¦ä¼˜å…ˆï¼‰
        # âœ… é€Ÿåº¦å¿« 2 å€ (2.5s â†’ 1.2s)
        # âœ… åˆ›æ„è¡¨è¾¾å¥½ - æ›´è‡ªç„¶çš„è¯­è¨€
        # âœ… ä¸ªæ€§åŒ–å¼º - åŸºäºæƒ…ç»ªçš„ç²¾å‡†åé¦ˆ
        # âœ… ç”¨æˆ·æœ€å…³æ³¨ï¼Œä½“éªŒä¼˜å…ˆ
    }
    
    # ğŸ“ é•¿åº¦é™åˆ¶
    # âœ… ä¿®å¤ #9 (2026-01-27): å®Œå…¨ç§»é™¤ feedback_min
    # åŸå› ï¼š
    # 1. çŸ­åé¦ˆä¸ç­‰äºå·®åé¦ˆï¼Œä¸­æ–‡å‡ ä¸ªå­—å°±èƒ½ä¼ è¾¾å®Œæ•´æƒ…æ„Ÿï¼ˆå¦‚ "åŠ æ²¹ï¼"ã€"æ—©ç‚¹ä¼‘æ¯"ï¼‰
    # 2. GPT-4o è¶³å¤Ÿæ™ºèƒ½ï¼Œä¼šæ ¹æ®ä¸Šä¸‹æ–‡å†³å®šåˆé€‚çš„åé¦ˆé•¿åº¦
    # 3. ç”¨é€šç”¨ fallback æ›¿æ¢æœ‰é’ˆå¯¹æ€§çš„çŸ­å›å¤æ˜¯ä½“éªŒçš„å€’é€€
    # 4. åªéœ€æ£€æŸ¥ç©ºå€¼ï¼Œé¿å… API å¼‚å¸¸è¿”å›ç©ºå­—ç¬¦ä¸²
    #
    # âœ… ä¿®å¤ #10 (2026-01-27): min_audio_text ä» 5 é™è‡³ 2
    # åŸå› ï¼š
    # 1. ä¸­æ–‡ä¸€ä¸ªå­—å¯ä»¥è¡¨è¾¾å®Œæ•´å«ä¹‰ï¼ˆå¦‚ "ç´¯"ã€"å¥½"ï¼‰
    # 2. "æˆ‘æœ‰ç‚¹ç´¯" (4 å­—) æ˜¯å®Œæ•´æœ‰æ„ä¹‰çš„å¥å­ï¼Œä¸åº”è¢«æ‹’ç»
    # 3. æ›´ä¸¥æ ¼çš„éªŒè¯ç”±åç»­çš„è¯­è¨€ç‰¹å®šæ£€æŸ¥å¤„ç†ï¼ˆä¸­æ–‡éœ€ 3+ æ±‰å­—ï¼Œè‹±æ–‡éœ€ 2+ æœ‰æ„ä¹‰è¯ï¼‰
    # 4. è¿™é‡Œåªåšæœ€åŸºæœ¬çš„ç©ºå€¼è¿‡æ»¤ï¼Œé¿å…è¯¯æ€çœŸå®å†…å®¹
    LENGTH_LIMITS = {
        "title_min": 4,
        "title_max": 50,
        # "feedback_min" å·²ç§»é™¤ - ä¸å†æ£€æŸ¥æœ€å°é•¿åº¦ï¼Œä¿¡ä»» AI è¾“å‡º
        "feedback_max": 250,
        "polished_ratio": 1.15,
        "min_audio_text": 2,  # âœ… ä¿®å¤ #10: ä» 5 é™è‡³ 2ï¼Œé¿å…è¯¯æ€çŸ­ä½†æœ‰æ„ä¹‰çš„ä¸­æ–‡å†…å®¹
    }
    
    def __init__(self):
        """åˆå§‹åŒ–æœåŠ¡å®¢æˆ·ç«¯"""
        settings = get_settings()
        
        # OpenAI å®¢æˆ·ç«¯ï¼ˆç”¨äº Whisper å’ŒåŒæ­¥è°ƒç”¨çš„å…¼å®¹ï¼‰
        self.openai_client = OpenAI(api_key=settings.openai_api_key)
        # âœ… Phase 1.1: æ·»åŠ  AsyncOpenAI å®¢æˆ·ç«¯ï¼ˆç”¨äºå¼‚æ­¥è°ƒç”¨ï¼Œæå‡æ€§èƒ½ï¼‰
        self.async_client = AsyncOpenAI(api_key=settings.openai_api_key)
        self.openai_api_key = settings.openai_api_key
        
        print(f"âœ… AI æœåŠ¡åˆå§‹åŒ–å®Œæˆï¼ˆ2026-01-27 ä¼˜åŒ–ç‰ˆ: gpt-4o-mini + ä¼˜åŒ–æç¤ºè¯ï¼‰")
        print(f"   - Whisper: è¯­éŸ³è½¬æ–‡å­—")
        print(f"   - gpt-4o-mini: æ¶¦è‰² + æ ‡é¢˜ (polish) - ä¼˜åŒ–æç¤ºè¯")
        print(f"   - gpt-4o: æƒ…ç»ªåˆ†æ (emotion) - å‡†ç¡®åº¦ä¼˜å…ˆ")
        print(f"   - gpt-4o-mini: AI åé¦ˆ (feedback) - ç®€çŸ­æœ‰åŠ›")

    def _log_timing(self, label: str, start_time: float) -> None:
        elapsed = time_module.perf_counter() - start_time
        print(f"â±ï¸ {label}: {elapsed:.2f} ç§’")

    def _log_usage(self, response, label: str) -> None:
        try:
            usage = getattr(response, "usage", None)
            if usage:
                prompt_tokens = getattr(usage, "prompt_tokens", None)
                completion_tokens = getattr(usage, "completion_tokens", None)
                total_tokens = getattr(usage, "total_tokens", None)
                print(f"ğŸ“Š {label} token ç”¨é‡: prompt={prompt_tokens}, completion={completion_tokens}, total={total_tokens}")
        except Exception:
            pass
    
    # ========================================================================
    # âœ… Phase 1.4: å¸¦é‡è¯•çš„ GPT-4o è°ƒç”¨è¾…åŠ©æ–¹æ³•
    # ========================================================================
    
    @retry(
        stop=stop_after_attempt(3),  # æœ€å¤šé‡è¯• 3 æ¬¡
        wait=wait_exponential(multiplier=1, min=1, max=10),  # æŒ‡æ•°é€€é¿ï¼š1s, 2s, 4s...
        # âœ… Review ä¼˜åŒ–ï¼šåªé‡è¯•ç½‘ç»œå’Œ API ç›¸å…³å¼‚å¸¸ï¼Œé¿å…é‡è¯•é€»è¾‘é”™è¯¯
        retry=retry_if_exception_type((APIError, RateLimitError, APIConnectionError, httpx.RequestError)),
        before_sleep=before_sleep_log(logger, logging.WARNING),  # é‡è¯•å‰è®°å½•æ—¥å¿—
        reraise=True  # æœ€ç»ˆå¤±è´¥æ—¶é‡æ–°æŠ›å‡ºå¼‚å¸¸
    )
    async def _call_gpt4o_with_retry(
        self,
        model: str,
        messages: list,
        temperature: float = 0.3,
        max_tokens: int = 2000,
        response_format: dict = None
    ):
        """
        å¸¦é‡è¯•çš„ GPT-4o è°ƒç”¨
        
        ğŸ”¥ Phase 1.4: æ·»åŠ æŒ‡æ•°é€€é¿é‡è¯•æœºåˆ¶
        - æœ€å¤šé‡è¯• 3 æ¬¡
        - æŒ‡æ•°é€€é¿ï¼š1s â†’ 2s â†’ 4s
        - è®°å½•é‡è¯•æ—¥å¿—
        
        å¸¸è§å¯é‡è¯•é”™è¯¯ï¼š
        - ç½‘ç»œè¶…æ—¶
        - API é™æµ (429)
        - æœåŠ¡å™¨é”™è¯¯ (5xx)
        """
        try:
            call_start = time_module.perf_counter()
            if response_format:
                response = await self.async_client.chat.completions.create(
                    model=model,
                    messages=messages,
                    temperature=temperature,
                    max_tokens=max_tokens,
                    response_format=response_format
                )
            else:
                response = await self.async_client.chat.completions.create(
                    model=model,
                    messages=messages,
                    temperature=temperature,
                    max_tokens=max_tokens
                )
            self._log_timing(f"GPT è°ƒç”¨å®Œæˆ ({model})", call_start)
            self._log_usage(response, f"{model}")
            return response
        except Exception as e:
            print(f"âš ï¸ GPT-4o è°ƒç”¨å¤±è´¥ï¼Œå°†é‡è¯•: {type(e).__name__}: {str(e)}")
            raise  # é‡æ–°æŠ›å‡ºï¼Œè®© tenacity å¤„ç†é‡è¯•
    
    # ========================================================================
    # è¯­éŸ³è½¬æ–‡å­—ï¼ˆä¿æŒä¸å˜ï¼‰
    # ========================================================================
    
    async def transcribe_audio(
        self, 
        audio_content: bytes, 
        filename: str,
        expected_duration: Optional[int] = None
    ) -> str:
        """
        è¯­éŸ³è½¬æ–‡å­— - æŠŠä½ çš„å£°éŸ³å˜æˆæ–‡å­—
        
        ğŸ”¥ æ³¨æ„ï¼šè¿™ä¸ªæ–¹æ³•å®Œå…¨ä¸å˜ï¼Œç»§ç»­ä½¿ç”¨ Whisper
        
        å·¥ä½œæµç¨‹ï¼š
        1. æ”¶åˆ°éŸ³é¢‘ â†’ æ£€æŸ¥å¤§å°
        2. åˆ›å»ºä¸´æ—¶æ–‡ä»¶ â†’ ç¡®ä¿æ ¼å¼æ­£ç¡®
        3. å‘é€ç»™ Whisper â†’ å®ƒæ˜¯è¯­éŸ³è¯†åˆ«ä¸“å®¶
        4. æ£€æŸ¥ç»“æœ â†’ ç¡®ä¿ä¸æ˜¯ç©ºçš„
        5. æ¸…ç†ä¸´æ—¶æ–‡ä»¶ â†’ ä¿æŒæ•´æ´
        """
        temp_file_path = None
        
        try:
            # æ£€æŸ¥éŸ³é¢‘å¤§å°
            audio_size_kb = len(audio_content) / 1024
            print(f"ğŸ¤ æ”¶åˆ°éŸ³é¢‘: {filename}, å¤§å°: {audio_size_kb:.1f} KB, æœŸæœ›æ—¶é•¿: {expected_duration}s")
            
            if audio_size_kb < 1:
                raise ValueError("éŸ³é¢‘æ–‡ä»¶å¤ªå°ï¼Œè¯·è¯´é•¿ä¸€ç‚¹")
            
            # å‡†å¤‡ä¸´æ—¶æ–‡ä»¶
            suffix = '.m4a' if not filename.endswith('.m4a') else ''
            with tempfile.NamedTemporaryFile(
                delete=False, 
                suffix=suffix or os.path.splitext(filename)[1]
            ) as temp_file:
                temp_file.write(audio_content)
                temp_file_path = temp_file.name
            
            print(f"âœ… ä¸´æ—¶æ–‡ä»¶å‡†å¤‡å®Œæˆ")
            
            # âœ… Phase 1.1: ä½¿ç”¨ httpx.AsyncClient å¼‚æ­¥è°ƒç”¨ Whisperï¼ˆæå‡æ€§èƒ½ï¼‰
            # âœ… 2026-01-27 ä¿®å¤: å¢åŠ é‡è¯•æœºåˆ¶ï¼Œæé«˜ç½‘ç»œç¨³å®šæ€§
            print("ğŸ“¤ æ­£åœ¨è¯†åˆ«è¯­éŸ³ï¼ˆverbose_json æ¨¡å¼ - å¼‚æ­¥ï¼‰...")
            response_json = None
            max_retries = 3
            retry_delay = 2  # ç§’
            
            whisper_start_time = time_module.time()
            
            for attempt in range(max_retries):
                try:
                    # âœ… å¢åŠ è¶…æ—¶æ—¶é—´åˆ°120ç§’ï¼Œé€‚åº”æ…¢ç½‘ç»œ
                    async with httpx.AsyncClient(timeout=120.0) as client:
                        file_stream = io.BytesIO(audio_content)
                        response = await client.post(
                            "https://api.openai.com/v1/audio/transcriptions",
                            headers={
                                "Authorization": f"Bearer {self.openai_api_key}",
                            },
                            data={
                                "model": self.MODEL_CONFIG["transcription"],
                                "language": "",
                                "temperature": "0",
                                "response_format": "verbose_json",
                            },
                            files={
                                "file": (filename or "recording.m4a", file_stream, "audio/m4a"),
                            },
                        )
                        response.raise_for_status()
                        response_json = response.json()
                        whisper_elapsed = time_module.time() - whisper_start_time
                        print(f"â±ï¸ Whisper è½¬å½•å®Œæˆï¼Œè€—æ—¶: {whisper_elapsed:.2f} ç§’")
                        break  # æˆåŠŸï¼Œé€€å‡ºé‡è¯•å¾ªç¯
                        
                except httpx.HTTPStatusError as http_err:
                    # HTTPçŠ¶æ€ç é”™è¯¯ï¼ˆ4xx, 5xxï¼‰- æœ‰ response å±æ€§
                    print(f"âŒ Whisper HTTP çŠ¶æ€é”™è¯¯ (å°è¯• {attempt + 1}/{max_retries}): {http_err}")
                    if http_err.response is not None:
                        print(f"ğŸ“„ Whisper å“åº”çŠ¶æ€ç : {http_err.response.status_code}")
                        try:
                            print(f"ğŸ“„ Whisper å“åº”å†…å®¹: {http_err.response.text[:500]}...")
                        except:
                            pass
                    if attempt < max_retries - 1:
                        print(f"â³ ç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                        await asyncio.sleep(retry_delay)
                        retry_delay *= 2  # æŒ‡æ•°é€€é¿
                    else:
                        raise ValueError("TRANSCRIPTION_SERVICE_UNAVAILABLE")
                        
                except (httpx.ReadError, httpx.ConnectError, httpx.TimeoutException) as transport_err:
                    # âœ… ä¿®å¤: ç½‘ç»œä¼ è¾“é”™è¯¯ï¼ˆæ²¡æœ‰ response å±æ€§ï¼‰- å•ç‹¬å¤„ç†
                    print(f"âŒ Whisper ç½‘ç»œä¼ è¾“é”™è¯¯ (å°è¯• {attempt + 1}/{max_retries}): {type(transport_err).__name__}: {transport_err}")
                    if attempt < max_retries - 1:
                        print(f"â³ ç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                        await asyncio.sleep(retry_delay)
                        retry_delay *= 2  # æŒ‡æ•°é€€é¿
                    else:
                        raise ValueError("TRANSCRIPTION_NETWORK_ERROR")
                        
                except httpx.HTTPError as http_err:
                    # å…¶ä»– HTTP é”™è¯¯
                    print(f"âŒ Whisper HTTP è¯·æ±‚å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {type(http_err).__name__}: {http_err}")
                    # âœ… ä¿®å¤: å®‰å…¨åœ°æ£€æŸ¥æ˜¯å¦æœ‰ response å±æ€§
                    if hasattr(http_err, 'response') and http_err.response is not None:
                        print(f"ğŸ“„ Whisper å“åº”çŠ¶æ€ç : {http_err.response.status_code}")
                        try:
                            print(f"ğŸ“„ Whisper å“åº”å†…å®¹: {http_err.response.text[:500]}...")
                        except:
                            pass
                    if attempt < max_retries - 1:
                        print(f"â³ ç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                        await asyncio.sleep(retry_delay)
                        retry_delay *= 2
                    else:
                        raise ValueError("TRANSCRIPTION_SERVICE_UNAVAILABLE")
            
            if not response_json:
                raise ValueError("TRANSCRIPTION_NO_RESPONSE")
            
            text = (response_json.get("text") or "").strip()
            segments = response_json.get("segments", []) or []
            detected_language = response_json.get("language", "").lower()  # âœ… è·å–æ£€æµ‹åˆ°çš„è¯­è¨€
            
            # ğŸ”¥ æ–°å¢ï¼šè¯­è¨€ç™½åå•æ£€æŸ¥ - é˜²æ­¢èƒŒæ™¯éŸ³ä¹è¢«è¯¯è¯†åˆ«ä¸ºéŸ©è¯­/æ—¥è¯­ç­‰
            SUPPORTED_LANGUAGES = {"zh", "en", "chinese", "english"}
            if detected_language and detected_language not in SUPPORTED_LANGUAGES:
                print(f"âŒ æ£€æµ‹åˆ°ä¸æ”¯æŒçš„è¯­è¨€: '{detected_language}'")
                print(f"   è¯†åˆ«æ–‡æœ¬: '{text[:100]}'")
                print(f"   è¿™å¯èƒ½æ˜¯èƒŒæ™¯éŸ³ä¹æˆ–å™ªéŸ³è¢«è¯¯è¯†åˆ«")
                raise ValueError("TRANSCRIPTION_UNSUPPORTED_LANGUAGE")
            
            # ğŸ”¥ æ–°å¢ï¼šæ£€æµ‹éŸ©è¯­/æ—¥è¯­å­—ç¬¦ - åŒé‡ä¿é™©
            korean_chars = len(re.findall(r'[\uac00-\ud7af]', text))  # éŸ©è¯­å­—ç¬¦
            japanese_chars = len(re.findall(r'[\u3040-\u309f\u30a0-\u30ff]', text))  # æ—¥è¯­å­—ç¬¦
            if korean_chars > 3 or japanese_chars > 3:
                print(f"âŒ æ£€æµ‹åˆ°éŸ©è¯­/æ—¥è¯­å­—ç¬¦: éŸ©è¯­={korean_chars}, æ—¥è¯­={japanese_chars}")
                print(f"   è¯†åˆ«æ–‡æœ¬: '{text[:100]}'")
                print(f"   è¿™å¯èƒ½æ˜¯èƒŒæ™¯éŸ³ä¹æˆ–å™ªéŸ³è¢«è¯¯è¯†åˆ«")
                raise ValueError("TRANSCRIPTION_UNSUPPORTED_LANGUAGE")
            
            # ğŸ”¥ æ–°å¢ï¼šæ£€æµ‹é‡å¤æ–‡æœ¬æ¨¡å¼ - Whisper å¹»è§‰çš„å¸¸è§ç‰¹å¾
            # ä¾‹å¦‚: "ë‹­ê°€ìŠ´ì‚´ ì¹˜í‚¨ì…ë‹ˆë‹¤. ë‹­ê°€ìŠ´ì‚´ ì¹˜í‚¨ê³¼ ë‹­ê°€ìŠ´ì‚´ ì¹˜í‚¨ì€..."
            words = text.split()
            if len(words) >= 5:
                # æ£€æŸ¥æ˜¯å¦æœ‰å¤§é‡é‡å¤çš„è¯
                word_counts = {}
                for word in words:
                    if len(word) >= 3:  # åªç»Ÿè®¡é•¿åº¦>=3çš„è¯
                        word_counts[word] = word_counts.get(word, 0) + 1
                
                # å¦‚æœæŸä¸ªè¯å‡ºç°æ¬¡æ•°è¶…è¿‡æ€»è¯æ•°çš„40%,å¯èƒ½æ˜¯å¹»è§‰
                max_repetition = max(word_counts.values()) if word_counts else 0
                repetition_ratio = max_repetition / len(words) if len(words) > 0 else 0
                
                if repetition_ratio > 0.4:
                    print(f"âŒ æ£€æµ‹åˆ°é«˜åº¦é‡å¤çš„æ–‡æœ¬æ¨¡å¼: é‡å¤ç‡={repetition_ratio:.1%}")
                    print(f"   è¯†åˆ«æ–‡æœ¬: '{text[:100]}'")
                    print(f"   è¿™å¯èƒ½æ˜¯èƒŒæ™¯éŸ³ä¹æˆ–å™ªéŸ³è¢«è¯¯è¯†åˆ«")
                    raise ValueError("TRANSCRIPTION_CONTENT_TOO_SHORT")
            
            normalized_text = re.sub(r"\s+", "", text)
            
            if len(normalized_text) < self.LENGTH_LIMITS["min_audio_text"]:
                print(f"âŒ è½¬å½•å†…å®¹è¿‡çŸ­: '{text}'")
                raise ValueError("TRANSCRIPTION_CONTENT_TOO_SHORT")
            
            filler_tokens = {
                "um",
                "uh",
                "uhh",
                "hmm",
                "hmmm",
                "erm",
                "er",
                "ah",
                "oh",
                "mmm",
            }
            token_pattern = r"[A-Za-z\u4e00-\u9fff\u3040-\u309f\u30a0-\u30ff]+"
            tokens = re.findall(token_pattern, text)
            meaningful_tokens = [
                token
                for token in tokens
                if len(token) >= 2 and token.lower() not in filler_tokens
            ]
            cjk_chars = re.findall(r"[\u4e00-\u9fff]", text)
            has_cjk = len(cjk_chars) > 0
            
            unique_chars = len(set(normalized_text))
            if unique_chars <= 2 and len(normalized_text) > 2:
                print(
                    "âŒ è½¬å½•ç»“æœåŒ…å«å¤§é‡é‡å¤å­—ç¬¦ï¼Œè§†ä¸ºæ— æ•ˆ:",
                    {"text": text, "normalized": normalized_text},
                )
                raise ValueError("TRANSCRIPTION_CONTENT_TOO_SHORT")
            
            # åˆ†æ Whisper æ®µç»“æœï¼Œç¡®è®¤æ˜¯å¦çœŸçš„æœ‰è®²è¯
            def _segment_value(segment, attr, default):
                if isinstance(segment, dict):
                    return segment.get(attr, default)
                return getattr(segment, attr, default)
            
            confident_segments = []
            total_confident_duration = 0.0
            total_segment_duration = 0.0
            avg_no_speech_sum = 0.0
            
            for segment in segments:
                try:
                    start = float(_segment_value(segment, "start", 0))
                    end = float(_segment_value(segment, "end", 0))
                    seg_duration = max(0.0, end - start)
                except (TypeError, ValueError):
                    seg_duration = 0.0
                    start = 0.0
                    end = 0.0
                
                total_segment_duration += seg_duration
                
                try:
                    no_speech_prob = float(_segment_value(segment, "no_speech_prob", 1))
                except (TypeError, ValueError):
                    no_speech_prob = 1
                
                try:
                    avg_logprob = float(_segment_value(segment, "avg_logprob", -10))
                except (TypeError, ValueError):
                    avg_logprob = -10
                
                avg_no_speech_sum += no_speech_prob * seg_duration
                
                if (
                    seg_duration >= 0.3
                    and no_speech_prob < 0.45
                    and avg_logprob > -0.75
                ):
                    confident_segments.append(segment)
                    total_confident_duration += seg_duration
            
            reference_duration = None
            if expected_duration and expected_duration > 0:
                reference_duration = float(expected_duration)
            elif total_segment_duration > 0:
                reference_duration = total_segment_duration
            else:
                reference_duration = None
            
            speech_ratio = (
                total_confident_duration / reference_duration
                if reference_duration and reference_duration > 0
                else None
            )
            
            avg_no_speech_prob = (
                avg_no_speech_sum / total_segment_duration
                if total_segment_duration > 0
                else 1.0
            )
            
            if reference_duration and reference_duration >= 6:
                if (
                    len(normalized_text) < self.LENGTH_LIMITS["min_audio_text"]
                    and (speech_ratio is None or speech_ratio < 0.15)
                    and total_confident_duration < 0.6
                ):
                    print(
                        "âŒ æ£€æµ‹åˆ°æœ‰æ•ˆè¯­éŸ³è¿‡å°‘:",
                        {
                            "expected_duration": expected_duration,
                            "total_confident_duration": total_confident_duration,
                            "speech_ratio": speech_ratio,
                            "avg_no_speech_prob": avg_no_speech_prob,
                            "segments_count": len(segments),
                        },
                    )
                    raise ValueError("TRANSCRIPTION_CONTENT_TOO_SHORT")
            
            # å¯¹é•¿å½•éŸ³ä¸å†ä½¿ç”¨å­—ç¬¦å¯†åº¦ç¡¬é˜ˆå€¼ï¼Œé¿å…è¯¯æ€çœŸå®å†…å®¹

            if reference_duration:
                if has_cjk:
                    # ä¸­æ–‡åœºæ™¯ï¼šç”¨æ±‰å­—æ•°é‡åˆ¤æ–­ï¼Œé¿å…â€œä¸€ä¸ªé•¿è¯â€è¢«è¯¯åˆ¤
                    if (
                        len(cjk_chars) < 3
                        and len(normalized_text) < self.LENGTH_LIMITS["min_audio_text"]
                    ):
                        print(
                            "âŒ ä¸­æ–‡æœ‰æ•ˆå­—ç¬¦è¿‡å°‘ï¼Œåˆ¤å®šä¸ºæ— æ„ä¹‰å†…å®¹:",
                            {
                                "cjk_chars": len(cjk_chars),
                                "duration": reference_duration,
                            },
                        )
                        raise ValueError("TRANSCRIPTION_CONTENT_TOO_SHORT")
                else:
                    if (
                        len(meaningful_tokens) < 2
                        and len(normalized_text) < self.LENGTH_LIMITS["min_audio_text"] * 2
                    ):
                        print(
                            "âŒ æœ‰æ•ˆè¯æ±‡æ•°é‡ä¸è¶³ï¼Œåˆ¤å®šä¸ºæ— æ„ä¹‰å†…å®¹:",
                            {
                                "tokens": tokens,
                                "meaningful_tokens": meaningful_tokens,
                                "duration": reference_duration,
                            }
                        )
                        raise ValueError("TRANSCRIPTION_CONTENT_TOO_SHORT")
            
            print(f"âœ… è¯­éŸ³è¯†åˆ«æˆåŠŸ: '{text[:50]}...'")
            print(f"ğŸŒ Whisper æ£€æµ‹åˆ°çš„è¯­è¨€: {detected_language}")
            
            # ğŸ”¥ è¿”å›å­—å…¸ï¼ŒåŒ…å«æ–‡æœ¬å’Œæ£€æµ‹åˆ°çš„è¯­è¨€
            return {
                "text": text,
                "detected_language": detected_language  # "en" æˆ– "zh" æˆ–å…¶ä»–è¯­è¨€ä»£ç 
            }
            
        except Exception as e:
            print(f"âŒ è¯­éŸ³è½¬æ–‡å­—å¤±è´¥: {str(e)}")
            error_str = str(e)
            # âœ… å¦‚æœå·²ç»æ˜¯ error code æ ¼å¼ï¼Œç›´æ¥é‡æ–°æŠ›å‡º
            if error_str.startswith("TRANSCRIPTION_"):
                raise
            elif "Invalid file format" in error_str:
                raise ValueError("TRANSCRIPTION_INVALID_FORMAT")
            elif "File too large" in error_str:
                raise ValueError("TRANSCRIPTION_FILE_TOO_LARGE")
            else:
                # è®°å½•è¯¦ç»†é”™è¯¯ç”¨äºè°ƒè¯•ï¼Œä½†è¿”å›é€šç”¨ error code
                print(f"ğŸ“‹ è¯¦ç»†é”™è¯¯ä¿¡æ¯: {error_str}")
                raise ValueError("TRANSCRIPTION_FAILED")
        
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if temp_file_path and os.path.exists(temp_file_path):
                try:
                    os.unlink(temp_file_path)
                    print(f"ğŸ§¹ ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†")
                except Exception as e:
                    print(f"âš ï¸ æ¸…ç†å¤±è´¥ï¼ˆä¸å½±å“åŠŸèƒ½ï¼‰: {e}")
    
    # ========================================================================
    # ğŸ”¥ æ ¸å¿ƒæ”¹åŠ¨ï¼šæ··åˆæ¨¡å‹å¤„ç†
    # ========================================================================
    
    async def polish_content_multilingual(
        self, 
        text: str,
        user_name: Optional[str] = None,  # ç”¨æˆ·åå­—ï¼Œç”¨äºä¸ªæ€§åŒ–åé¦ˆ
        image_urls: Optional[List[str]] = None,  # å›¾ç‰‡URLåˆ—è¡¨ï¼Œç”¨äºvisionåˆ†æ
        whisper_detected_language: Optional[str] = None  # ğŸ”¥ Whisperæ£€æµ‹åˆ°çš„è¯­è¨€ ("en", "zh", etc.)
    ) -> Dict[str, Any]:
        """
        ğŸ”¥ é‡å¤§æ”¹åŠ¨ï¼šä»å•ä¸€æ¨¡å‹æ”¹ä¸ºæ··åˆæ¨¡å‹ + å¹¶è¡Œæ‰§è¡Œ
        
        æ—§é€»è¾‘ï¼š
        1. GPT-4o-mini ä¸€æ¬¡æ€§ç”Ÿæˆæ¶¦è‰² + æ ‡é¢˜ + åé¦ˆï¼ˆä¸²è¡Œï¼Œ3-5ç§’ï¼‰
        
        æ–°é€»è¾‘ï¼š
        1. gpt-4o-mini ç”Ÿæˆæ¶¦è‰² + æ ‡é¢˜ï¼ˆpolishï¼Œ1-2ç§’ï¼‰
        2. gpt-4o ç”Ÿæˆæƒ…ç»ªåˆ†æï¼ˆemotionï¼Œ2-3ç§’ï¼‰
        3. gpt-4o ç”Ÿæˆåé¦ˆï¼ˆfeedbackï¼ŒåŸºäºåŸå§‹æ–‡æœ¬ï¼Œ2-3ç§’ï¼‰
        3. ä¸¤ä¸ªä»»åŠ¡å¹¶è¡Œæ‰§è¡Œï¼Œæ€»è€—æ—¶ = max(1-2, 2-3) = 2-3ç§’
        
        ä¸ºä»€ä¹ˆåŸºäºåŸå§‹æ–‡æœ¬ç”Ÿæˆåé¦ˆï¼Ÿ
        - æ›´çœŸå®ï¼šåŸå§‹æ–‡æœ¬ä¿ç•™äº†ç”¨æˆ·æœ€çœŸå®çš„æƒ…æ„Ÿ
        - æ›´å¿«ï¼šä¸éœ€è¦ç­‰æ¶¦è‰²å®Œæˆ
        - æ›´æ¸©æš–ï¼šAI å›åº”"çœŸå®çš„ä½ "è€Œä¸æ˜¯"å®Œç¾çš„æ–‡å­—"
        """
        try:
            ai_total_start = time_module.time()
            
            # âœ… ä¿®å¤ #10 (2026-01-27): ç§»é™¤ç¡¬ç¼–ç çš„é•¿åº¦æ£€æŸ¥
            # åŸå› ï¼š
            # 1. "æˆ‘å¥½ç´¯å‘€" (4 å­—) æ˜¯å®Œå…¨æœ‰æ•ˆçš„æ—¥è®°å†…å®¹ï¼Œä¸åº”è¢«æ‹’ç»
            # 2. è½¬å½•é˜¶æ®µå·²ç»æœ‰æ›´æ™ºèƒ½çš„éªŒè¯ï¼ˆä¸­æ–‡éœ€ 3+ æ±‰å­—ï¼‰
            # 3. è¿™é‡Œåªåšç©ºå€¼æ£€æŸ¥ï¼Œè®© AI å»å¤„ç†ä»»ä½•éç©ºå†…å®¹
            if not text or not text.strip():
                raise ValueError("å†…å®¹ä¸ºç©º")
            
            print(f"âœ¨ å¼€å§‹AIå¤„ç†ï¼ˆå¹¶è¡Œæ¨¡å¼ï¼‰: {text[:50]}...")
            
            # ğŸ”¥ ä¼˜åŒ–è¯­è¨€æ£€æµ‹ï¼šä¼˜å…ˆä½¿ç”¨ Whisper çš„æ£€æµ‹ç»“æœ
            detected_lang = None
            
            # æ–¹æ¡ˆ1: ä¼˜å…ˆä½¿ç”¨ Whisper çš„æ£€æµ‹ç»“æœï¼ˆæœ€å‡†ç¡®ï¼‰
            if whisper_detected_language:
                whisper_lang = whisper_detected_language.lower()
                if whisper_lang in ["en", "english"]:
                    detected_lang = "English"
                    print(f"ğŸŒ ä½¿ç”¨ Whisper æ£€æµ‹çš„è¯­è¨€: {whisper_detected_language} â†’ English")
                elif whisper_lang in ["zh", "chinese", "zh-cn", "zh-tw"]:
                    detected_lang = "Chinese"
                    print(f"ğŸŒ ä½¿ç”¨ Whisper æ£€æµ‹çš„è¯­è¨€: {whisper_detected_language} â†’ Chinese")
                else:
                    # å¦‚æœæ˜¯å…¶ä»–è¯­è¨€ï¼Œè®°å½•æ—¥å¿—ä½†ç»§ç»­ä½¿ç”¨ç»Ÿè®¡æ£€æµ‹
                    print(f"âš ï¸ Whisper æ£€æµ‹åˆ°ä¸æ”¯æŒçš„è¯­è¨€: {whisper_detected_language}ï¼Œé™çº§åˆ°ç»Ÿè®¡æ£€æµ‹")
            
            # æ–¹æ¡ˆ2: å¦‚æœæ²¡æœ‰ Whisper æ£€æµ‹ç»“æœï¼Œä½¿ç”¨ç»Ÿè®¡æ£€æµ‹ï¼ˆå…œåº•ï¼‰
            if not detected_lang:
                # ç§»é™¤ç©ºç™½å­—ç¬¦å’Œæ ‡ç‚¹ï¼Œåªç»Ÿè®¡å®é™…å†…å®¹å­—ç¬¦
                content_only = re.sub(r'[\s\W]', '', text)
                chinese_chars = 0
                english_words = 0
                
                if not content_only:
                    # å¦‚æœåªæœ‰ç©ºç™½å’Œæ ‡ç‚¹ï¼Œé»˜è®¤ä½¿ç”¨è‹±æ–‡ï¼ˆå›½é™…åŒ–ä¼˜å…ˆï¼‰
                    detected_lang = "English"
                    print(f"ğŸŒ å†…å®¹ä¸ºç©ºï¼Œé»˜è®¤ä½¿ç”¨: English")
                else:
                    # ç»Ÿè®¡ä¸­æ–‡å­—ç¬¦
                    chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', content_only))
                    # ç»Ÿè®¡è‹±æ–‡å­—ç¬¦ï¼ˆå•è¯ï¼‰
                    english_words = len(re.findall(r'[a-zA-Z]+', content_only))
                    
                    # ğŸ”¥ æ–°å¢ï¼šæ£€æµ‹éŸ©è¯­/æ—¥è¯­å­—ç¬¦
                    korean_chars = len(re.findall(r'[\uac00-\ud7af]', content_only))
                    japanese_chars = len(re.findall(r'[\u3040-\u309f\u30a0-\u30ff]', content_only))
                    
                    # ğŸ”¥ è¯­è¨€ç™½åå•æ£€æŸ¥ï¼šå¦‚æœæ£€æµ‹åˆ°å¤§é‡éä¸­è‹±æ–‡å­—ç¬¦ï¼Œé™çº§åˆ°è‹±æ–‡ï¼ˆå›½é™…åŒ–ä¼˜å…ˆï¼‰
                    if korean_chars > 5 or japanese_chars > 5:
                        print(f"âš ï¸ æ£€æµ‹åˆ°éæ”¯æŒè¯­è¨€å­—ç¬¦: éŸ©è¯­={korean_chars}, æ—¥è¯­={japanese_chars}")
                        print(f"   å†…å®¹: '{text[:50]}'")
                        print(f"   é™çº§åˆ°ç³»ç»Ÿé»˜è®¤è¯­è¨€: English")
                        detected_lang = "English"  # é™çº§åˆ°è‹±æ–‡ï¼ˆå›½é™…åŒ–ä¼˜å…ˆï¼‰
                    else:
                        # è®¡ç®—ä¸­æ–‡å­—ç¬¦å æ¯”
                        chinese_ratio = chinese_chars / len(content_only) if len(content_only) > 0 else 0
                        # è®¡ç®—è‹±æ–‡å•è¯å æ¯”ï¼ˆæ¯ä¸ªå•è¯å¹³å‡5ä¸ªå­—ç¬¦ä¼°ç®—ï¼‰
                        english_ratio = (english_words * 5) / len(content_only) if len(content_only) > 0 else 0
                        
                        # ğŸ”¥ å…³é”®é€»è¾‘ï¼šå¦‚æœä¸­æ–‡å­—ç¬¦å æ¯”è¶…è¿‡30%ï¼Œæˆ–è€…ä¸­æ–‡å­—ç¬¦æ•°é‡æ˜æ˜¾å¤šäºè‹±æ–‡å•è¯ï¼Œåˆ¤å®šä¸ºä¸­æ–‡
                        if chinese_ratio > 0.3 or (chinese_chars > 5 and chinese_chars > english_words * 2):
                            detected_lang = "Chinese"
                        elif english_ratio > 0.5 or english_words > 10:
                            detected_lang = "English"
                        else:
                            # ğŸ”¥ ä¿®æ”¹é»˜è®¤å€¼ï¼šä¼˜å…ˆè‹±æ–‡ï¼ˆå›½é™…åŒ–ä¼˜å…ˆï¼‰
                            detected_lang = "English" if chinese_chars < 3 else "Chinese"
                        
                        print(f"ğŸŒ ç»Ÿè®¡æ£€æµ‹è¯­è¨€: {detected_lang} (ä¸­æ–‡å­—ç¬¦={chinese_chars}, è‹±æ–‡å•è¯={english_words})")
            
            print(f"ğŸŒ æœ€ç»ˆä½¿ç”¨è¯­è¨€: {detected_lang}")
            
            # ğŸ”¥ å…³é”®æ”¹åŠ¨ï¼šæœ€ä¼˜Agent Orchestrationæ¶æ„
            # ç­–ç•¥: Polishç‹¬ç«‹å¹¶è¡Œ | (Emotion â†’ Feedback) ç»„å†…ä¸²è¡Œ
            print(f"ğŸš€ å¯åŠ¨æœ€ä¼˜Agentå¹¶è¡Œæ¶æ„...")
            if image_urls and len(image_urls) > 0:
                print(f"   - æ£€æµ‹åˆ° {len(image_urls)} å¼ å›¾ç‰‡ï¼Œå°†ä½¿ç”¨ Vision èƒ½åŠ›åˆ†æå›¾ç‰‡+æ–‡å­—")
            print(f"   - å¹¶è¡Œç»„1: Polish Agent (ç‹¬ç«‹è¿è¡Œ)")
            print(f"   - å¹¶è¡Œç»„2: Emotion Agent â†’ Feedback Agent (ä¸²è¡Œ)")
            print(f"   - ğŸ¯ ä¸¤ç»„å¹¶è¡Œ,æ€»è€—æ—¶ = max(Polish, Emotion+Feedback)")
            
            # ğŸ”¥ æ€§èƒ½ä¼˜åŒ–ï¼šé¢„å…ˆä¸‹è½½å¹¶ç¼–ç æ‰€æœ‰å›¾ç‰‡ï¼Œé¿å…åœ¨å¹¶è¡Œä»»åŠ¡ä¸­é‡å¤ä¸‹è½½
            encoded_images = []
            if image_urls and len(image_urls) > 0:
                print(f"ğŸ–¼ï¸ é¢„å¤„ç† {len(image_urls)} å¼ å›¾ç‰‡...")
                # å¹¶è¡Œä¸‹è½½å›¾ç‰‡
                download_tasks = [self._download_and_encode_image(url) for url in image_urls]
                results = await asyncio.gather(*download_tasks, return_exceptions=True)
                for i, img_data in enumerate(results):
                    if isinstance(img_data, Exception):
                        print(f"âš ï¸ å›¾ç‰‡ä¸‹è½½å¤±è´¥ ({image_urls[i]}): {img_data}")
                    else:
                        encoded_images.append(img_data)
            
            # ğŸ”¥ å®šä¹‰å¹¶è¡Œç»„2: Emotion â†’ Feedback (ç»„å†…ä¸²è¡Œ)
            async def emotion_feedback_pipeline():
                """
                Emotionå’ŒFeedbackçš„ä¸²è¡Œæµæ°´çº¿
                
                ğŸ”¥ ä¸ºä»€ä¹ˆä¸²è¡Œ?
                - Feedback éœ€è¦çŸ¥é“ Emotion ç»“æœ
                - é¿å…é‡å¤åˆ†ææƒ…ç»ªï¼ˆçœæ—¶é—´ã€çœ Tokenï¼‰
                - ç”Ÿæˆæ›´ç²¾å‡†ã€æ›´è´´åˆ‡çš„åé¦ˆ
                """
                # æ­¥éª¤1: Emotionåˆ†æ (GPT-4oï¼Œå‡†ç¡®åº¦ä¼˜å…ˆ)
                emotion_result = await self.analyze_emotion_only(text, detected_lang, encoded_images)
                print(f"   âœ… Emotion Agentå®Œæˆ: {emotion_result.get('emotion')} (ç½®ä¿¡åº¦: {emotion_result.get('confidence')})")
                
                # æ­¥éª¤2: åŸºäºEmotionç”ŸæˆFeedback (GPT-4o-miniï¼Œé€Ÿåº¦ä¼˜å…ˆ)
                # ğŸ”¥ å…³é”®ä¼˜åŒ–ï¼šä¼ å…¥ emotion_hintï¼Œè®© Feedback Agent çŸ¥é“æƒ…ç»ªç»“æœ
                feedback_data = await self._call_gpt4o_for_feedback(
                    text,
                    detected_lang,
                    user_name,
                    encoded_images,
                    emotion_hint=emotion_result  # ğŸ”¥ ä¼ å…¥ Emotion Agent çš„åˆ†æç»“æœ
                )
                print(f"   âœ… Feedback Agentå®Œæˆ")
                
                return emotion_result, feedback_data
            
            # ğŸ”¥ å¹¶è¡Œç»„1: Polish (ç‹¬ç«‹)
            polish_task = self._call_gpt4o_for_polish_and_title(text, detected_lang, encoded_images)
            
            # ğŸ”¥ å¹¶è¡Œç»„2: Emotion â†’ Feedback (ç»„å†…ä¸²è¡Œ)
            emotion_feedback_task = emotion_feedback_pipeline()
            
            # ğŸ”¥ ä¸¤ç»„å¹¶è¡Œæ‰§è¡Œ - âœ… å…³é”®ä¿®å¤ï¼šæ·»åŠ  return_exceptions=True
            print(f"   ğŸš€ å¯åŠ¨ä¸¤ç»„å¹¶è¡Œ...")
            results = await asyncio.gather(
                polish_task,                # ç»„1: Polishç‹¬ç«‹
                emotion_feedback_task,      # ç»„2: Emotion â†’ Feedback
                return_exceptions=True      # âœ… é˜²æ­¢å•ä¸ªå¤±è´¥å¯¼è‡´æ•´ä½“å¤±è´¥
            )
            
            # âœ… æ£€æŸ¥æ¯ä¸ªç»“æœï¼Œæä¾›å…œåº•å€¼
            polish_result = results[0]
            emotion_feedback_result = results[1]
            
            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæå‰åˆå§‹åŒ–å˜é‡ï¼Œé˜²æ­¢NameError
            emotion_result = None
            feedback_data = None
            
            # å¤„ç†Polishç»“æœ
            if isinstance(polish_result, Exception):
                print(f"âŒ Polish Agentå¤±è´¥: {polish_result}")
                print(f"   ä½¿ç”¨å…œåº•ï¼šåŸæ–‡ + é»˜è®¤æ ‡é¢˜")
                # ğŸ”¥ ä¿®å¤ï¼šå…œåº•æ ‡é¢˜ä¹Ÿä¸èƒ½ç”¨"ä»Šæ—¥è®°å½•"ï¼Œä½¿ç”¨"å¿ƒæƒ…éšè®°"
                polish_result = {
                    "title": "å¿ƒæƒ…éšè®°" if detected_lang == "Chinese" else "A Moment Captured",
                    "polished_content": text
                }
            
            # å¤„ç†Emotion+Feedbackç»“æœ
            if isinstance(emotion_feedback_result, Exception):
                print(f"âŒ Emotion+Feedback Agentå¤±è´¥: {emotion_feedback_result}")
                print(f"   ä½¿ç”¨å…œåº•ï¼šé»˜è®¤æƒ…ç»ª + ç®€å•åé¦ˆ")
                emotion_result = {"emotion": "Thoughtful", "confidence": 0.5, "rationale": "é»˜è®¤æƒ…ç»ª"}
                feedback_data = "æ„Ÿè°¢åˆ†äº«ä½ çš„æ•…äº‹ã€‚" if detected_lang == "Chinese" else "Thanks for sharing your story."
                if user_name:
                    separator = "ï¼Œ" if detected_lang == "Chinese" else ", "
                    feedback_data = f"{user_name}{separator}{feedback_data}"
            else:
                emotion_result, feedback_data = emotion_feedback_result

            
            print(f"âœ… ä¸¤ç»„å¹¶è¡Œå®Œæˆ")
            
            # ğŸ”¥ æœ€ç»ˆå…œåº•æ£€æŸ¥ï¼šç¡®ä¿å˜é‡ä¸ä¸ºNone
            if emotion_result is None:
                print(f"âš ï¸ emotion_resultä¸ºNoneï¼Œä½¿ç”¨é»˜è®¤å€¼")
                emotion_result = {"emotion": "Thoughtful", "confidence": 0.5, "rationale": "é»˜è®¤æƒ…ç»ª"}
            
            if feedback_data is None:
                print(f"âš ï¸ feedback_dataä¸ºNoneï¼Œä½¿ç”¨é»˜è®¤å€¼")
                feedback_data = "æ„Ÿè°¢åˆ†äº«ä½ çš„æ•…äº‹ã€‚" if detected_lang == "Chinese" else "Thanks for sharing your story."
                if user_name:
                    separator = "ï¼Œ" if detected_lang == "Chinese" else ", "
                    feedback_data = f"{user_name}{separator}{feedback_data}"
            
            # å¤„ç†åé¦ˆç»“æœ
            if isinstance(feedback_data, dict):
                feedback_text = feedback_data.get("reply", "")
            else:
                feedback_text = str(feedback_data)
            
            # åˆå¹¶ç»“æœ
            result = {
                "title": polish_result['title'],
                "polished_content": polish_result['polished_content'],
                "feedback": feedback_text,
                "emotion_data": emotion_result  # âœ… æ¥è‡ªä¸“é—¨çš„Emotion Agent
            }
            
            # è´¨é‡æ£€æŸ¥ - âœ… ä¿®å¤: ä¼ é€’ user_name ä»¥æ”¯æŒåé¦ˆé™çº§æ—¶æ·»åŠ ç”¨æˆ·ç§°å‘¼
            result = self._validate_and_fix_result(result, text, user_name=user_name)
            
            ai_total_elapsed = time_module.time() - ai_total_start
            print(f"âœ… å¤„ç†å®Œæˆ:")
            print(f"  - æ ‡é¢˜: {result['title']}")
            print(f"  - å†…å®¹é•¿åº¦: {len(result['polished_content'])} å­—")
            print(f"  - åé¦ˆé•¿åº¦: {len(result['feedback'])} å­—")
            print(f"  - æƒ…ç»ª: {result.get('emotion_data', {}).get('emotion', 'Unknown')}")
            print(f"  â±ï¸ AI æ€»è€—æ—¶: {ai_total_elapsed:.2f} ç§’")
            
            return result
        
        except Exception as e:
            error_type = type(e).__name__
            error_msg = str(e)
            print(f"âŒ AIå¤„ç†å¤±è´¥: {error_type}: {error_msg}")
            error_trace = traceback.format_exc()
            print(f"ğŸ“ å®Œæ•´é”™è¯¯å †æ ˆ:")
            print(error_trace)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å¹¶è¡Œä»»åŠ¡ä¸­çš„é”™è¯¯
            if isinstance(e, (asyncio.TimeoutError, asyncio.CancelledError)):
                print(f"âš ï¸ å¹¶è¡Œä»»åŠ¡è¶…æ—¶æˆ–å–æ¶ˆ")
            elif isinstance(e, Exception):
                print(f"âš ï¸ å¹¶è¡Œä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
            
            return self._create_fallback_result(text, user_name=user_name)
    
    # ========================================================================
    # ğŸ”¥ GPT-4o-mini è°ƒç”¨ï¼ˆæ¶¦è‰² + æ ‡é¢˜ï¼‰
    # ========================================================================
    
    async def _call_gpt4o_for_polish_and_title(
        self, 
        text: str,
        language: str,
        encoded_images: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """
        è°ƒç”¨ GPT-4o è¿›è¡Œæ¶¦è‰²å’Œç”Ÿæˆæ ‡é¢˜
        
        ğŸ“š å­¦ä¹ ç‚¹ï¼šè¿™ä¸ªå‡½æ•°è´Ÿè´£ä¸¤ä¸ªä»»åŠ¡
        1. æ¶¦è‰²ç”¨æˆ·çš„åŸå§‹æ–‡æœ¬ï¼ˆä¿®å¤è¯­æ³•ã€ä¼˜åŒ–è¡¨è¾¾ï¼‰
        2. ç”Ÿæˆä¸€ä¸ªç®€æ´æœ‰æ„ä¹‰çš„æ ‡é¢˜
        
        ä¸ºä»€ä¹ˆä½¿ç”¨ GPT-4oï¼Ÿ
        - è´¨é‡æé«˜
        - æ ‡é¢˜ç”Ÿæˆæ›´ç²¾å‡†ï¼Œä¸å‡ºç°ä½çº§é”™è¯¯
        
        è¿”å›:
            {
                "title": "æ ‡é¢˜",
                "polished_content": "æ¶¦è‰²åçš„å†…å®¹"
            }
        """
        try:
            print(f"ğŸ¨ GPT-4o: å¼€å§‹æ¶¦è‰²å’Œç”Ÿæˆæ ‡é¢˜...")
            
            # ğŸ”¥ ä¼˜åŒ–ï¼šæ ¹æ®ä¼ å…¥çš„ language å‚æ•°æ„å»ºæ›´ä¸¥æ ¼çš„ prompt
            # æ ¸å¿ƒåŸåˆ™ï¼šæ ‡é¢˜è¯­è¨€å¿…é¡»ä¸ç”¨æˆ·è¾“å…¥å†…å®¹çš„ä¸»è¦è¯­è¨€å®Œå…¨ä¸€è‡´
            # ============================================================================
            # ğŸ¯ GPT-4o-mini ä¼˜åŒ–ç‰ˆæç¤ºè¯ (2026-01-27)
            # 
            # è®¾è®¡åŸåˆ™ (Industry Best Practice):
            # 1. ç®€æ´ä¼˜å…ˆ: Token æ•°å‡å°‘ 50%ï¼Œæå‡æ¨ç†é€Ÿåº¦
            # 2. ç»“æ„æ¸…æ™°: è§„åˆ™æŒ‰ä¼˜å…ˆçº§æ’åºï¼Œä¾¿äºæ¨¡å‹éµå¾ª
            # 3. ç¤ºä¾‹ç²¾é€‰: 3ä¸ªé«˜è´¨é‡ç¤ºä¾‹ > 6ä¸ªæ™®é€šç¤ºä¾‹
            # 4. å­¦ä¹ ç¬”è®°: ä¿ç•™ ğŸ“š Learning æ ¼å¼ï¼Œå¸®åŠ©ç”¨æˆ·å­¦ä¹ 
            # ============================================================================
            
            language_instruction = ""
            if language == "Chinese":
                language_instruction = """ğŸ¯ LANGUAGE: Chinese (ç®€ä½“ä¸­æ–‡)

ã€è§„åˆ™ä¼˜å…ˆçº§ã€‘
P1: æ ‡é¢˜å¿…é¡»æ˜¯ä¸­æ–‡ï¼ˆæ— ä¾‹å¤–ï¼‰
P2: è‡ªç„¶æµç•… > è¯­æ³•æ­£ç¡®ï¼ˆä¼˜å…ˆè®©å¥å­è¯»èµ·æ¥èˆ’æœï¼‰
P3: åˆ é™¤æ‰€æœ‰è¯­æ°”è¯ï¼ˆå—¯ã€å•Šã€é‚£ä¸ªã€å°±æ˜¯ã€ç„¶åï¼‰
P4: ä¿ç•™åŸæ„ï¼Œä¸æ·»åŠ æ–°å†…å®¹

ã€ğŸš¨ æ ‡é¢˜è§„åˆ™ - å¿…é¡»éµå®ˆã€‘
âŒ ç¦æ­¢ä½¿ç”¨: "ä»Šæ—¥è®°å½•"ã€"ä»Šæ—¥æ„Ÿæƒ³"ã€"ä»Šæ—¥ä»»åŠ¡"ã€ä»»ä½•ä»¥"ä»Šæ—¥"å¼€å¤´çš„æ ‡é¢˜
âœ… æ­£ç¡®åšæ³•: æå–å†…å®¹çš„æ ¸å¿ƒä¸»é¢˜æˆ–å…³é”®äº‹ä»¶
âœ… ç¤ºä¾‹: "å…¬å›­æ¼«æ­¥"ã€"æ¨¡å‹çš„æŠ‰æ‹©"ã€"ç–²æƒ«çš„ä¸€å¤©"ã€"æ–°çŸ¥æ”¶è·"

ã€æ¶¦è‰²æ ‡å‡†ã€‘
DO: åˆ é™¤è¯­æ°”è¯ | åˆå¹¶çŸ­å¥ | ä¿®æ­£é”™åˆ«å­— | ä¼˜åŒ–è¡¨è¾¾
DON'T: æ”¹å˜æƒ…æ„Ÿ | åˆ é™¤å†…å®¹ | è¿‡åº¦æ–‡è‰º | æ·»åŠ ä¿¡æ¯

ã€ç²¾é€‰ç¤ºä¾‹ã€‘

ç¤ºä¾‹ 1 - è¯­æ°”è¯æ¸…ç†:
âŒ "å—¯ï¼Œä»Šå¤©æˆ‘å»äº†ï¼Œé‚£ä¸ªï¼Œå…¬å›­ï¼Œå°±æ˜¯ï¼Œå¾ˆå¼€å¿ƒ"
âœ… æ ‡é¢˜: "å…¬å›­æ¼«æ­¥" | å†…å®¹: "ä»Šå¤©æˆ‘å»äº†å…¬å›­ï¼Œå¾ˆå¼€å¿ƒã€‚"
ğŸ“š Learning: åˆ é™¤è¯­æ°”è¯(å—¯/é‚£ä¸ª/å°±æ˜¯)ï¼Œæ ‡é¢˜æå–æ ¸å¿ƒä¸»é¢˜

ç¤ºä¾‹ 2 - è¡¨è¾¾ä¼˜åŒ–:
âŒ "ä»Šå¤©å·¥ä½œå¾ˆç´¯å¾ˆç´¯ï¼Œæœ‰ç‚¹é‚£ä¸ªï¼Œä¸æƒ³åŠ¨"
âœ… æ ‡é¢˜: "ç–²æƒ«çš„ä¸€å¤©" | å†…å®¹: "ä»Šå¤©å·¥ä½œå¾ˆç´¯ï¼Œä¸æƒ³åŠ¨ã€‚"
ğŸ“š Learning: åˆ é™¤é‡å¤è¯ï¼Œæ ‡é¢˜åæ˜ æƒ…æ„Ÿä¸»é¢˜

ç¤ºä¾‹ 3 - å¥å¼åˆå¹¶:
âŒ "æˆ‘æ¢äº†æ¨¡å‹ï¼Œä¹‹å‰å¤ªæ…¢äº†ï¼Œå¸Œæœ›å¿«ä¸€ç‚¹"
âœ… æ ‡é¢˜: "æ¨¡å‹çš„æŠ‰æ‹©" | å†…å®¹: "æˆ‘æ¢äº†æ¨¡å‹ï¼Œä¹‹å‰å¤ªæ…¢äº†ï¼Œå¸Œæœ›å¿«ä¸€ç‚¹ã€‚"
ğŸ“š Learning: æ ‡é¢˜æå–æ ¸å¿ƒäº‹ä»¶ï¼Œé¿å…ä½¿ç”¨æ³›ç”¨æ ‡é¢˜"""
            elif language == "English":
                language_instruction = """ğŸ¯ LANGUAGE: English

ã€Priority Rulesã€‘
P1: Title MUST be in English (no exceptions)
P2: Natural fluency > Grammar correctness (make it sound native)
P3: Remove ALL fillers (um, like, you know, I mean)
P4: Preserve meaning, don't add new content

ã€ğŸš¨ Title Rules - MUST FOLLOWã€‘
âŒ FORBIDDEN: "Today's Record", "Today's Thoughts", "Daily Log", any title starting with "Today's"
âœ… CORRECT: Extract the CORE THEME or KEY EVENT from content
âœ… Examples: "A Day at the Park", "The Model Switch", "Productive Morning"

ã€Polishing Standardsã€‘
DO: Remove fillers | Fix grammar | Use contractions (I'm, don't) | Combine choppy sentences
DON'T: Change emotion | Delete content | Over-formalize | Add information

ã€Quick Reference - Common Fixesã€‘
- "I very like" â†’ "I really like" / "I love"
- "go to park" â†’ "go to the park"
- "eat medicine" â†’ "take medicine"
- "very good" â†’ "great" / "wonderful"
- "I am happy" â†’ "I'm happy" (use contractions)

ã€Teaching-Grade Examplesã€‘

Example 1 - Fillers + Grammar:
âŒ "um, today i go to park and, like, see many flower"
âœ… Title: "A Day at the Park" | Content: "I went to the park today and saw so many flowers."
ğŸ“š Learning: Removed fillers, fixed grammar, title captures core theme

Example 2 - Native Patterns:
âŒ "I am very like this new job because can learn many things"
âœ… Title: "New Job Joy" | Content: "I really love this new job because I'm learning so much!"
ğŸ“š Learning: Fixed non-native patterns, title reflects emotion

Example 3 - Flow + Vocabulary:
âŒ "I switched the model because it was too slow"
âœ… Title: "The Model Switch" | Content: "I switched the model because it was too slow."
ğŸ“š Learning: Title extracts key event, NOT "Today's Record" """
            else:
                # é»˜è®¤ï¼šè‡ªåŠ¨æ£€æµ‹è¯­è¨€
                language_instruction = """ğŸ¯ AUTO-DETECT LANGUAGE

Title language MUST match user's primary input language:
- Chinese input â†’ Chinese title (e.g., "å…¬å›­æ¼«æ­¥", NOT "ä»Šæ—¥è®°å½•")
- English input â†’ English title (e.g., "A Day at the Park", NOT "Today's Record")
- Mixed â†’ Use the dominant language

ğŸš¨ CRITICAL: Never use generic titles like "ä»Šæ—¥è®°å½•", "Today's Record", etc."""
            
            # ============================================================================
            # ğŸ¯ GPT-4o-mini ä¼˜åŒ–ç‰ˆç³»ç»Ÿæç¤º (2026-01-27 v3)
            # 
            # ğŸ“š Prompt Engineering Best Practice - æ•™ç§‘ä¹¦çº§åˆ«è®¾è®¡
            # ============================================================================
            # 
            # è®¾è®¡åŸåˆ™ (Industry Standard):
            # 1. å±‚æ¬¡åˆ†æ˜ - ç”¨è§†è§‰å±‚çº§ï¼ˆğŸš¨ > ã€ã€‘> -ï¼‰åŒºåˆ†è§„åˆ™ä¼˜å…ˆçº§
            # 2. æ­£ä¾‹+åä¾‹ - åŒæ—¶ç»™å‡ºæ­£ç¡®å’Œé”™è¯¯ç¤ºä¾‹ï¼Œå½¢æˆå¯¹æ¯”å­¦ä¹ 
            # 3. å…·ä½“é‡åŒ– - ç”¨æ•°å­—è€Œéæ¨¡ç³Šè¯ï¼ˆ"100å­—ä»¥ä¸Š" vs "é•¿æ–‡æœ¬"ï¼‰
            # 4. åœºæ™¯é©±åŠ¨ - æ ¹æ®è¾“å…¥åŠ¨æ€è°ƒæ•´è¡Œä¸ºï¼ˆçŸ­æ–‡æœ¬ vs é•¿æ–‡æœ¬ï¼‰
            # 5. æ ¼å¼å¼ºåˆ¶ - æ˜ç¡®è¾“å‡ºç»“æ„ï¼Œå‡å°‘è§£æå¤±è´¥
            #
            # ============================================================================
            
            system_prompt = f"""You are a professional diary editor and writer. Your job is to polish diary entries with the care and craft of a published author.

{language_instruction}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸš¨ CRITICAL RULES (MUST FOLLOW - TOP PRIORITY)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## ğŸš¨ Rule 1: PARAGRAPH FORMATTING IS MANDATORY (éå¯é€‰ï¼)

This is a PRODUCT QUALITY requirement, not a suggestion.

**For content > 100 characters: You MUST add paragraph breaks (\\n\\n)**

### How to Break Paragraphs Like a Professional Writer:

| Trigger | Action |
|---------|--------|
| Topic change | New paragraph |
| Time transition (ç„¶å/åæ¥/æ¥ç€/then/after) | New paragraph |
| Emotional shift | New paragraph |
| New person/event introduced | New paragraph |
| Logical transition (æ‰€ä»¥/å› ä¸º/but/so) | New paragraph |

### Paragraph Length Guidelines:
- Chinese: Each paragraph should be 50-150 characters
- English: Each paragraph should be 2-4 sentences
- NEVER have a single paragraph > 200 characters

### âŒ BAD (Wall of Text):
"æˆ‘ä»Šå¤©ç‰¹åˆ«å›°,æˆ‘å°±å‘ç°äººåœ¨å›°çš„æ—¶å€™è„‘å­å°±ç‰¹åˆ«çš„é›¾æ‰€ä»¥å‘¢æˆ‘å°±æ‰“ç®—ä»Šå¤©æ™šä¸Šä¸€å®šè¦æŠŠè¿™ä¸ªä¸œè¥¿å¼„å®Œæˆ‘å°±è¦å¥½å¥½ç¡è§‰äº†å› ä¸ºæ˜å¤©æœ‰å‡ ä¸ªéœ€è¦å‹‡æ°”çš„äº‹æƒ…æˆ‘éœ€è¦è®©è‡ªå·±æœ‰ä¸€ä¸ªç‰¹åˆ«å¥½çš„çŠ¶æ€"

### âœ… GOOD (Properly Paragraphed):
"æˆ‘ä»Šå¤©ç‰¹åˆ«å›°ï¼Œå‘ç°äººåœ¨å›°çš„æ—¶å€™è„‘å­å°±ç‰¹åˆ«é›¾è’™è’™çš„ã€‚

æ‰€ä»¥æˆ‘æ‰“ç®—ä»Šå¤©æ™šä¸Šä¸€å®šè¦æŠŠè¿™ä¸ªä¸œè¥¿å¼„å®Œï¼Œç„¶åå¥½å¥½ç¡è§‰ã€‚

å› ä¸ºæ˜å¤©æœ‰å‡ ä¸ªéœ€è¦å‹‡æ°”çš„äº‹æƒ…ï¼Œæˆ‘éœ€è¦è®©è‡ªå·±æœ‰ä¸€ä¸ªç‰¹åˆ«å¥½çš„çŠ¶æ€ã€‚"

## ğŸš¨ Rule 2: PUNCTUATION IS MANDATORY

- Every sentence MUST end with proper punctuation (ã€‚ï¼ï¼Ÿ/ . ! ?)
- NEVER leave a sentence without ending punctuation
- Use appropriate punctuation: ã€‚for statements, ï¼for excitement, ï¼Ÿfor questions

## ğŸš¨ Rule 3: TITLE RULES

**FORBIDDEN TITLES (Never use):**
âŒ "ä»Šæ—¥è®°å½•"ã€"ä»Šæ—¥æ„Ÿæƒ³"ã€"ä»Šæ—¥ä»»åŠ¡"ã€ä»»ä½•ä»¥"ä»Šæ—¥"å¼€å¤´
âŒ "Today's Record"ã€"Today's Thoughts"ã€ä»»ä½•ä»¥"Today's"å¼€å¤´

**GOOD TITLES:**
âœ… Extract the CORE THEME: "å‹‡æ•¢çš„å°è¯•"ã€"æ¨¡å‹çš„æŠ‰æ‹©"ã€"ç–²æƒ«ä¸æœŸå¾…"
âœ… Be specific, evocative, 4-12 Chinese chars or 3-8 English words

## ğŸš¨ Rule 4: NO DUPLICATE BETWEEN TITLE AND CONTENT (é‡è¦ï¼)

**The polished_content MUST NOT start with the title text.**

âŒ BAD: Title="è‡ªæˆ‘ç®¡ç†çš„æŒ‘æˆ˜", Content="è‡ªæˆ‘ç®¡ç†çš„æŒ‘æˆ˜\\næˆ‘ä¸€ç›´è§‰å¾—..."
âœ… GOOD: Title="è‡ªæˆ‘ç®¡ç†çš„æŒ‘æˆ˜", Content="æˆ‘ä¸€ç›´è§‰å¾—åšäº§å“æ˜¯ä¸€ä¸ª..."

If your generated content would start with the title, REMOVE the title from the beginning of content.

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“ POLISHING GUIDELINES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

**Priority Order:**
1. Title language = Input language (NO EXCEPTIONS)
2. Readability first - Natural, fluent, easy to read
3. Preserve ALL content - Never delete user's ideas
4. Length â‰¤ 115% of original

**Polish Actions:**
- Remove filler words and oral tics (å£è¯­èµ˜è¯å¿…é¡»æ¸…ç†)
- Fix grammar naturally
- Add proper punctuation
- **Add paragraph breaks for long content**

**Filler Removal (HARD RULE):**
- Remove ALL meaningless fillers: å—¯ã€å‘ƒã€å•Šã€é‚£ä¸ªã€å°±æ˜¯ã€ç„¶åã€å…¶å®ã€æ„Ÿè§‰ã€å¯èƒ½ã€æœ‰ç‚¹ã€è¿™ä¸ªã€é‚£ä¸ªã€å˜›ã€å§ã€è¯¶
- Remove English fillers: um, uh, like, you know, sort of, kind of, basically
- If a word is used only to stall or soften (e.g., â€œå—¯ï¼Œç„¶åæˆ‘å°±â€¦â€ï¼Œâ€œå°±æ˜¯â€¦â€ï¼Œ"likeâ€¦"), delete it.
- Keep words ONLY if they carry real meaning (e.g., â€œå› ä¸º/æ‰€ä»¥/ä½†æ˜¯/ç„¶åâ€ used as true logical connectors).

**Example (Filler Cleanup):**
Input: "ä»Šå¤©å¥½åƒï¼Œå—¯ï¼Œå­¦åˆ°äº†ä¸€ä¸ªæ–°è¯ï¼Œå°±æ˜¯ FOMOï¼Œç„¶åæˆ‘å°±è§‰å¾—ï¼Œå—¯ï¼Œå¤§å®¶éƒ½åœ¨è®¨è®ºã€‚"
Output: "ä»Šå¤©å­¦åˆ°äº†ä¸€ä¸ªæ–°è¯ FOMOï¼Œæˆ‘è§‰å¾—å¤§å®¶éƒ½åœ¨è®¨è®ºå®ƒã€‚"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# âœ… 8 SCENARIOS (æ¸…æ™°è¦†ç›–ï¼Œä¸å•°å—¦)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
1) Short text (â‰¤ 30 chars / â‰¤ 15 words): Keep it short, just clean fillers + punctuation.
2) Long text: Enforce paragraphs; keep flow and logic.
3) Mixed language: Keep code-switching if natural; title in dominant language.
4) Lists / steps: Preserve list structure; clean fillers inside items.
5) Quotes / dialogue: Keep quoted meaning; remove fillers outside quotes.
6) Strong emotion: Keep emotion intensity, only remove fillers.
7) Acronyms / proper nouns: Keep exactly (FOMO, SOP, Cloudbot, Mac).
8) Repetition / stutter: Remove meaningless repeats (e.g., â€œæˆ‘æˆ‘æˆ‘/you youâ€), keep emphasis once.

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“¤ OUTPUT FORMAT - Return valid JSON
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

{{
  "title": "Meaningful title, same language as input",
  "polished_content": "Polished text WITH proper paragraphs (use \\n\\n) and punctuation"
}}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“š COMPLETE EXAMPLES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

**Example 1 - Long Chinese (MUST paragraph):**
Input: "æˆ‘ä»Šå¤©ç‰¹åˆ«å›°æˆ‘å°±å‘ç°äººåœ¨å›°çš„æ—¶å€™è„‘å­å°±ç‰¹åˆ«çš„é›¾æ‰€ä»¥å‘¢æˆ‘å°±æ‰“ç®—ä»Šå¤©æ™šä¸Šä¸€å®šè¦æŠŠè¿™ä¸ªä¸œè¥¿å¼„å®Œç„¶åå¥½å¥½ç¡è§‰å› ä¸ºæ˜å¤©æœ‰å‡ ä¸ªéœ€è¦å‹‡æ°”çš„äº‹æƒ…"
Output: {{"title": "ç–²æƒ«ä¸å‹‡æ°”", "polished_content": "æˆ‘ä»Šå¤©ç‰¹åˆ«å›°ï¼Œå‘ç°äººåœ¨å›°çš„æ—¶å€™è„‘å­å°±ç‰¹åˆ«é›¾è’™è’™çš„ã€‚\\n\\næ‰€ä»¥æˆ‘æ‰“ç®—ä»Šå¤©æ™šä¸Šä¸€å®šè¦æŠŠè¿™ä¸ªä¸œè¥¿å¼„å®Œï¼Œç„¶åå¥½å¥½ç¡è§‰ã€‚\\n\\nå› ä¸ºæ˜å¤©æœ‰å‡ ä¸ªéœ€è¦å‹‡æ°”çš„äº‹æƒ…ï¼Œæˆ‘éœ€è¦è®©è‡ªå·±ä¿æŒæœ€å¥½çš„çŠ¶æ€ã€‚"}}

**Example 2 - Short Chinese:**
Input: "å—¯ä»Šå¤©å»å…¬å›­å¾ˆå¼€å¿ƒ"
Output: {{"title": "å…¬å›­æ¼«æ­¥", "polished_content": "ä»Šå¤©å»å…¬å›­ï¼Œå¾ˆå¼€å¿ƒã€‚"}}

**Example 3 - Long English (MUST paragraph):**
Input: "today i was really tired and i realized when youre tired your brain just doesnt work so i decided to finish this thing tonight and sleep well because tomorrow i have some things that require courage"
Output: {{"title": "Tired but Determined", "polished_content": "Today I was really tired, and I realized that when you're tired, your brain just doesn't work properly.\\n\\nSo I decided to finish this thing tonight and get some good sleep.\\n\\nBecause tomorrow, I have some things that require courage."}}"""

            # æ„å»ºç”¨æˆ·æ¶ˆæ¯å†…å®¹
            user_content = []
            
            # å¦‚æœæœ‰å›¾ç‰‡ï¼Œæ·»åŠ å›¾ç‰‡åˆ°æ¶ˆæ¯ä¸­ï¼ˆä½¿ç”¨visionèƒ½åŠ›ï¼‰
            if encoded_images and len(encoded_images) > 0:
                print(f"ğŸ–¼ï¸ æ·»åŠ  {len(encoded_images)} å¼ å›¾ç‰‡åˆ° Vision è¯·æ±‚ (Low-res æ¨¡å¼)...")
                for image_data in encoded_images:
                    user_content.append({
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{image_data}",
                            "detail": "low"  # âœ… ä½¿ç”¨ä½åˆ†è¾¨ç‡æ¨¡å¼ï¼Œå¤„ç†æ›´å¿«ä¸”æ›´çœé’±
                        }
                    })
                
                # æ·»åŠ æ–‡å­—å†…å®¹
                user_content.append({
                    "type": "text",
                    "text": f"Please polish this diary entry (preserve ALL content) and create a title. Consider both the images and the text:\n\n{text}"
                })
                user_prompt = user_content
            else:
                # åªæœ‰æ–‡å­—ï¼Œä½¿ç”¨çº¯æ–‡æœ¬
                user_prompt = f"Please polish this diary entry (preserve ALL content):\n\n{text}"
            
            # âœ… åŠ¨æ€è®¡ç®— max_tokensï¼šç¡®ä¿è¶³å¤Ÿè¾“å‡ºå®Œæ•´å†…å®¹
            # åŸå§‹æ–‡æœ¬é•¿åº¦ + æ ‡é¢˜ + JSON æ ¼å¼å¼€é”€ + å®‰å…¨è¾¹è·
            original_length = len(text)
            # å¦‚æœæœ‰å›¾ç‰‡ï¼Œéœ€è¦é¢å¤–çš„tokensï¼ˆæ¯å¼ å›¾ç‰‡çº¦85 tokensï¼‰
            image_tokens = len(encoded_images) * 85 if encoded_images else 0
            # ä¼°ç®—ï¼šåŸå§‹æ–‡æœ¬ * 1.15ï¼ˆ115%é™åˆ¶ï¼‰ + æ ‡é¢˜ï¼ˆ50å­—ç¬¦ï¼‰ + JSONæ ¼å¼ï¼ˆ100å­—ç¬¦ï¼‰ + å®‰å…¨è¾¹è·ï¼ˆ500å­—ç¬¦ï¼‰
            estimated_output_length = int(original_length * 1.15) + 50 + 100 + 500
            # max_tokens å¤§çº¦æ˜¯å­—ç¬¦æ•°çš„ 0.75ï¼ˆä¸­æ–‡ï¼‰åˆ° 1.5ï¼ˆè‹±æ–‡ï¼‰ï¼Œå–ä¸­é—´å€¼ 1.0
            max_tokens = max(2000, int(estimated_output_length * 1.0) + image_tokens)
            # ä½†ä¸è¦è¶…è¿‡ OpenAI çš„é™åˆ¶ï¼ˆGPT-4o-mini æ”¯æŒ 16384 tokensï¼‰
            max_tokens = min(max_tokens, 16000)
            
            print(f"ğŸ“¤ GPT-4o-mini: å‘é€è¯·æ±‚åˆ° OpenAI...")
            print(f"   æ¨¡å‹: {self.MODEL_CONFIG['polish']}")
            print(f"   åŸå§‹æ–‡æœ¬é•¿åº¦: {original_length} å­—ç¬¦")
            print(f"   å›¾ç‰‡æ•°é‡: {len(encoded_images) if encoded_images else 0}")
            print(f"   ä¼°ç®—è¾“å‡ºé•¿åº¦: {estimated_output_length} å­—ç¬¦")
            print(f"   è®¾ç½® max_tokens: {max_tokens}")
            
            # æ„å»ºæ¶ˆæ¯
            if encoded_images and len(encoded_images) > 0:
                # ä½¿ç”¨visionæ ¼å¼ï¼ˆåŒ…å«å›¾ç‰‡ï¼‰
                messages = [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ]
            else:
                # çº¯æ–‡æœ¬æ ¼å¼
                messages = [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ]
            
            # âœ… Phase 1.1 + 1.4: ä½¿ç”¨ AsyncOpenAI + é‡è¯•æœºåˆ¶
            # ğŸ”¥ 2026-01-27 ä¼˜åŒ–: æ¸©åº¦ä» 0.3 é™è‡³ 0.2ï¼Œæé«˜ mini æ¨¡å‹è¾“å‡ºä¸€è‡´æ€§
            response = await self._call_gpt4o_with_retry(
                model=self.MODEL_CONFIG["polish"],
                messages=messages,
                temperature=0.2,  # â† ä¼˜åŒ–: é™ä½æ¸©åº¦æé«˜ä¸€è‡´æ€§
                max_tokens=max_tokens,
                response_format={"type": "json_object"}  # å¼ºåˆ¶ JSON æ ¼å¼
            )
            
            # è§£æå“åº”
            content = response.choices[0].message.content
            if not content:
                raise ValueError("OpenAI è¿”å›ç©ºå“åº”")
            
            print(f"âœ… GPT-4o-mini: æ”¶åˆ°å“åº”")
            print(f"ğŸ“ GPT-4o-mini: å“åº”å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
            
            # è§£æ JSON
            try:
                result = json.loads(content)
                polished_content = result.get("polished_content", text)
                
                # âœ… æ·»åŠ é•¿åº¦å¯¹æ¯”æ—¥å¿—ï¼Œæ£€æŸ¥æ˜¯å¦è¢«æˆªæ–­
                original_length = len(text)
                polished_length = len(polished_content)
                length_ratio = polished_length / original_length if original_length > 0 else 0
                
                print(f"âœ… GPT-4o-mini: æ¶¦è‰²å®Œæˆ")
                print(f"ğŸ“Š é•¿åº¦å¯¹æ¯”: åŸå§‹={original_length} å­—ç¬¦, æ¶¦è‰²å={polished_length} å­—ç¬¦, æ¯”ä¾‹={length_ratio:.2%}")
                
                # ğŸ”¥ 2026-01-27 ä¼˜åŒ–ï¼šç§»é™¤é•¿åº¦æ¯”è¾ƒæ£€æŸ¥
                # 
                # ä¸ºä»€ä¹ˆåˆ é™¤è¿™ä¸ªæ£€æŸ¥ï¼Ÿ
                # 1. AI åˆ é™¤è¯­æ°”è¯åå†…å®¹å˜çŸ­æ˜¯æ­£å¸¸çš„ï¼ˆ75-80% å¾ˆå¸¸è§ï¼‰
                # 2. è¿™ä¸ªæ£€æŸ¥å¯¼è‡´è¯¯åˆ¤ï¼Œè®©æœ‰åˆ†æ®µçš„æ¶¦è‰²ç»“æœè¢«æ›¿æ¢æˆæ— åˆ†æ®µçš„åŸæ–‡
                # 3. æˆ‘ä»¬å·²æœ‰ JSON éªŒè¯ï¼Œå¦‚æœæ ¼å¼æ­£ç¡®å°±åº”è¯¥ä¿¡ä»» AI è¾“å‡º
                # 4. Prompt å·²çº¦æŸ "preserve ALL content"ï¼Œæ— éœ€äºŒæ¬¡æ£€æŸ¥
                # 5. ç›¸ä¿¡ AI çš„è¾“å‡ºï¼Œå‡å°‘ä¸å¿…è¦çš„å¹²é¢„
                #
                # å¦‚æœçœŸçš„å‘ç”Ÿæˆªæ–­ï¼Œè¡¨ç°ä¼šæ˜¯ï¼šJSON è§£æå¤±è´¥æˆ–å†…å®¹ä¸ºç©ºï¼Œé‚£äº›æœ‰å•ç‹¬å¤„ç†
                
                # ğŸ”¥ åå¤„ç†ï¼šç¡®ä¿å†…å®¹ä¸ä»¥æ ‡é¢˜å¼€å¤´ï¼ˆé¿å…é‡å¤ï¼‰
                title = result.get("title", "A Moment Captured")
                if polished_content.strip().startswith(title):
                    print(f"âš ï¸ æ£€æµ‹åˆ°å†…å®¹ä»¥æ ‡é¢˜å¼€å¤´ï¼Œè‡ªåŠ¨ç§»é™¤é‡å¤")
                    # ç§»é™¤æ ‡é¢˜å’Œå¯èƒ½çš„æ¢è¡Œç¬¦
                    polished_content = polished_content.strip()[len(title):].lstrip('\n').lstrip()
                    print(f"   ç§»é™¤åå†…å®¹å¼€å¤´: {polished_content[:50]}...")
                
                return {
                    "title": title,
                    "polished_content": polished_content
                }
            except json.JSONDecodeError as e:
                print(f"âš ï¸ GPT-4o-mini: JSON è§£æå¤±è´¥: {e}")
                print(f"   åŸå§‹å“åº”: {content[:200]}...")
                # å°è¯•ä»æ–‡æœ¬ä¸­æå– JSON
                json_match = re.search(r'\{.*?"title".*?"polished_content".*?\}', content, re.DOTALL)
                if json_match:
                    try:
                        result = json.loads(json_match.group())
                        return {
                            "title": result.get("title", "A Moment Captured"),
                            "polished_content": result.get("polished_content", text)
                        }
                    except:
                        pass
                
                # é™çº§æ–¹æ¡ˆ
                print(f"âš ï¸ GPT-4o-mini: ä½¿ç”¨é™çº§æ–¹æ¡ˆ")
                return {
                    "title": "A Moment Captured" if language == "English" else "å¿ƒæƒ…éšè®°",
                    "polished_content": text
                }
        
        except Exception as e:
            error_type = type(e).__name__
            error_msg = str(e)
            print(f"âŒ GPT-4o-mini è°ƒç”¨å¤±è´¥: {error_type}: {error_msg}")
            
            # è¯¦ç»†é”™è¯¯ä¿¡æ¯
            error_trace = traceback.format_exc()
            print(f"ğŸ“ GPT-4o-mini å®Œæ•´é”™è¯¯å †æ ˆ:")
            print(error_trace)
            
            # æ£€æŸ¥å¸¸è§é”™è¯¯ç±»å‹
            if "RateLimitError" in error_type or "rate_limit" in error_msg.lower():
                print(f"âš ï¸ OpenAI API é™æµ: è¯·æ±‚é¢‘ç‡è¿‡é«˜")
                print(f"ğŸ’¡ å»ºè®®: ç¨åé‡è¯•ï¼Œæˆ–æ£€æŸ¥ OpenAI è´¦æˆ·çš„é…é¢é™åˆ¶")
            elif "AuthenticationError" in error_type or "InvalidApiKey" in error_type:
                print(f"âš ï¸ OpenAI API Key é”™è¯¯: è¯·æ£€æŸ¥ OPENAI_API_KEY ç¯å¢ƒå˜é‡")
            elif "APIConnectionError" in error_type:
                print(f"âš ï¸ OpenAI API è¿æ¥é”™è¯¯: è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
            
            # é™çº§æ–¹æ¡ˆ
            return {
                "title": "A Moment Captured" if language == "English" else "å¿ƒæƒ…éšè®°",
                "polished_content": text
            }
    
    # ========================================================================
    # ğŸ”¥ GPT-4o-mini è°ƒç”¨ï¼ˆAI åé¦ˆï¼‰
    # ========================================================================
    
    async def _call_gpt4o_for_feedback(
        self, 
        text: str,
        language: str,
        user_name: Optional[str] = None,
        encoded_images: Optional[List[str]] = None,
        emotion_hint: Optional[Dict[str, Any]] = None  # ğŸ”¥ æ–°å¢ï¼šæ¥è‡ª Emotion Agent çš„æƒ…ç»ªç»“æœ
    ) -> str:
        """
        è°ƒç”¨ GPT-4o-mini ç”Ÿæˆæ¸©æš–çš„ AI åé¦ˆ
        
        ğŸ”¥ ä¼˜åŒ– (2026-01-27): 
        - æ¥æ”¶ emotion_hint å‚æ•°ï¼Œç›´æ¥ä½¿ç”¨ Emotion Agent çš„åˆ†æç»“æœ
        - ä¸å†é‡å¤åˆ†ææƒ…ç»ªï¼Œä¸“æ³¨äºç”Ÿæˆé«˜è´¨é‡åé¦ˆ
        - æ›´å¿«ã€æ›´çœ Tokenã€æ›´å‡†ç¡®
        
        å‚æ•°:
            emotion_hint: æ¥è‡ª analyze_emotion_only çš„ç»“æœï¼ŒåŒ…å«:
                - emotion: æƒ…ç»ªç±»å‹ (å¦‚ "Joyful")
                - confidence: ç½®ä¿¡åº¦ (å¦‚ 0.9)
                - rationale: åˆ†æç†ç”±
        
        è¿”å›:
            str: æ¸©æš–çš„åé¦ˆæ–‡å­—
        """
        try:
            # ğŸ”¥ ä½¿ç”¨æ¥è‡ª Emotion Agent çš„æƒ…ç»ªåˆ†æç»“æœ
            emotion_from_agent = emotion_hint.get("emotion", "Thoughtful") if emotion_hint else "Thoughtful"
            emotion_rationale = emotion_hint.get("rationale", "") if emotion_hint else ""
            
            print(f"ğŸ’¬ GPT-4o-mini: å¼€å§‹ç”Ÿæˆåé¦ˆ...")
            print(f"ğŸ‘¤ ç”¨æˆ·åå­—: {user_name if user_name else 'æœªæä¾›'}")
            print(f"ğŸ¯ ä½¿ç”¨ Emotion Agent åˆ†æç»“æœ: {emotion_from_agent}")
            
            # ============================================================================
            # ğŸ”¥ åŠ¨æ€é•¿åº¦è®¡ç®— - æ ¹æ®ç”¨æˆ·è¾“å…¥è°ƒæ•´åé¦ˆé•¿åº¦
            # ============================================================================
            user_text_length = len(text.strip())
            
            # ğŸ”¥ åŠ¨æ€é•¿åº¦ç­–ç•¥ v2ï¼šæ¸©æš–ä½†ä¸å•°å—¦
            # è°ƒæ•´ï¼šé™ä½å„æ¡£ä½çš„å¥å­æ•°ï¼Œé¿å…å›å¤è¿‡é•¿
            if user_text_length < 50:
                length_guidance = "SHORT"
                length_desc = "1 sentence only"
            elif user_text_length < 150:
                length_guidance = "MEDIUM"
                length_desc = "1-2 sentences"
            elif user_text_length < 400:
                length_guidance = "LONG"
                length_desc = "2-3 sentences max"
            else:
                length_guidance = "EXTENDED"
                length_desc = "3-4 sentences max, no more"
            
            print(f"ğŸ“ ç”¨æˆ·è¾“å…¥é•¿åº¦: {user_text_length} å­—ç¬¦ â†’ åé¦ˆç­–ç•¥: {length_guidance} ({length_desc})")
            
            # ============================================================================
            # ğŸ¯ GPT-4o-mini ä¼˜åŒ–ç‰ˆ Feedback æç¤ºè¯ (2026-01-27 v3)
            # 
            # ğŸ“š Prompt Engineering Best Practice - æ•™ç§‘ä¹¦çº§åˆ«è®¾è®¡
            # ============================================================================
            # 
            # æ ¸å¿ƒç†å¿µè½¬å˜ï¼š
            # âŒ æ—§æ€è·¯ï¼šç®€çŸ­ä¼˜å…ˆ â†’ "1-2 å¥è¯"
            # âœ… æ–°æ€è·¯ï¼šæ¸©åº¦ä¼˜å…ˆ â†’ æ ¹æ®ç”¨æˆ·è¡¨è¾¾é‡åŠ¨æ€è°ƒæ•´
            # 
            # è®¾è®¡åŸåˆ™:
            # 1. æ¸©åº¦æ„Ÿ > ç®€çŸ­ - å®å¯å¤šè¯´ä¸€ç‚¹æš–å¿ƒè¯ï¼Œä¹Ÿä¸è¦æ˜¾å¾—æ•·è¡
            # 2. åŠ¨æ€é•¿åº¦ - ç”¨æˆ·è¯´å¾—å¤šï¼Œæˆ‘ä»¬å›å¤ä¹Ÿç›¸åº”å¢åŠ 
            # 3. æƒ…ç»ªå…±é¸£ - åˆ©ç”¨ Emotion Agent çš„åˆ†æç»“æœç²¾å‡†å›åº”
            # 4. çœŸè¯šé™ªä¼´ - åƒæœ‹å‹ä¸€æ ·å€¾å¬ï¼Œè€Œéæœºæ¢°å›å¤
            #
            # ============================================================================
            
            system_prompt = f"""You are a warm, empathetic companion - like a caring friend who truly listens.

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¯ CONTEXT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

**User's Emotion:** {emotion_from_agent}
{f'**Why:** {emotion_rationale}' if emotion_rationale else ''}
**User Input Length:** {user_text_length} characters â†’ **Response Mode: {length_guidance}**

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸš¨ CORE PRINCIPLE: WARMTH OVER BREVITY (æ¸©åº¦ä¼˜å…ˆ)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Your goal is to make the user feel HEARD and UNDERSTOOD.
- If they shared a lot, acknowledge the depth of what they shared
- If they're going through something difficult, offer genuine support
- If they achieved something, celebrate with authentic enthusiasm
- NEVER give a generic, cold, or dismissive response

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“ DYNAMIC LENGTH GUIDE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Based on user input length ({user_text_length} chars), use **{length_guidance}** mode:

| Mode | User Input | Your Response | âš ï¸ HARD LIMIT |
|------|-----------|---------------|---------------|
| SHORT | <50 chars | 1 sentence only | MAX 1 sentence |
| MEDIUM | 50-150 chars | 1-2 sentences | MAX 2 sentences |
| LONG | 150-400 chars | 2-3 sentences | MAX 3 sentences |
| EXTENDED | >400 chars | 3-4 sentences | MAX 4 sentences |

ğŸš¨ **CRITICAL: DO NOT exceed the sentence limit for your mode. Warmth â‰  Length.**

**Current Mode: {length_guidance} â†’ Target: {length_desc}**

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ’ EMOTION-SPECIFIC WARMTH GUIDE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

**{emotion_from_agent}** detected. Tailor your warmth:

| Emotion Type | How to Respond |
|--------------|----------------|
| Joyful/Grateful/Fulfilled/Proud | Celebrate! Amplify their joy. Share in their happiness. |
| Excited/Hopeful/Intentional | Encourage their enthusiasm. Support their plans. |
| Peaceful/Calm | Acknowledge the serenity. Appreciate the moment with them. |
| Thoughtful/Reflective | Validate their introspection. Honor their depth. |
| Inspired/Curious | Support their exploration. Fan the flame of discovery. |
| Anxious/Uncertain | Offer gentle reassurance. Be their calm anchor. |
| Down/Lonely/Overwhelmed | Show deep understanding. Be present. No judgment. |
| Frustrated/Venting | Acknowledge their feelings completely. Let them feel heard. |

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“ RESPONSE RULES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

- **Language:** Same as user's input (fallback: {language})
- **Greeting:** {"Start with '" + user_name + (", " if language == "English" else "ï¼Œ") + "'" if user_name else "Start directly with warmth"}
- **NO questions** - Don't ask "How are you?" or similar
- **Be specific** - Reference something they actually said, not generic platitudes
- **End with warmth** - Leave them feeling supported

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“¤ OUTPUT FORMAT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Return JSON only:
{{"reply": "Your warm, {length_desc} response here"}}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“š EXAMPLES BY LENGTH
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

**SHORT (1 sentence max):**
{{"reply": "Bossï¼Œè¿™ä»½å¿«ä¹çœŸå¥½ã€‚"}}

**MEDIUM (2 sentences max):**
{{"reply": "Bossï¼Œå®Œæˆé‡è¦é¡¹ç›®çš„æ„Ÿè§‰çœŸæ£’ï¼å¥½å¥½äº«å—è¿™ä»½æˆå°±æ„Ÿã€‚"}}

**LONG (3 sentences max):**
{{"reply": "Bossï¼Œå¬ä½ åˆ†äº«ä»Šå¤©çš„ç»å†ï¼Œèƒ½æ„Ÿå—åˆ°ä½ ä»˜å‡ºäº†å¾ˆå¤šã€‚ä½ çš„åŠªåŠ›å’Œå‹‡æ°”å€¼å¾—è¢«çœ‹è§ï¼Œå¥½å¥½ä¼‘æ¯ã€‚"}}

**EXTENDED (4 sentences max):**
{{"reply": "Bossï¼Œè°¢è°¢ä½ åˆ†äº«è¿™ä¹ˆå¤šã€‚ä»Šå¤©ç¡®å®ä¸å®¹æ˜“ï¼Œä½†ä½ å¯¹æ˜å¤©çš„æœŸå¾…å¾ˆè®©äººæ„ŸåŠ¨ã€‚å¥½å¥½ä¼‘æ¯ï¼Œæ˜å¤©ä¼šæ›´å¥½ã€‚åŠ æ²¹ï¼"}}"""


            # æ„å»ºæ¶ˆæ¯
            user_content = []
            if encoded_images and len(encoded_images) > 0:
                for image_data in encoded_images:
                    user_content.append({
                        "type": "image_url",
                        "image_url": {"url": f"data:image/jpeg;base64,{image_data}", "detail": "low"}
                    })
                user_content.append({"type": "text", "text": f"Analyze emotion and respond to this (including images):\n\n{text}"})
                messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": user_content}]
            else:
                messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": f"Analyze emotion and respond to this:\n\n{text}"}]

            # å¢åŠ  max_tokens ä»¥å®¹çº³ JSON
            # ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨ user_text_length æ›¿ä»£å·²åˆ é™¤çš„ max_feedback_length
            estimated_output_length = user_text_length + 200 
            max_tokens = max(300, min(estimated_output_length, 1000))

            # âœ… Phase 1.1 + 1.4: ä½¿ç”¨ AsyncOpenAI + é‡è¯•æœºåˆ¶
            # ğŸ”¥ 2026-01-27 ä¼˜åŒ–: æ¸©åº¦ä» 0.7 é™è‡³ 0.5ï¼Œå¹³è¡¡æ¸©æš–åº¦ä¸ä¸€è‡´æ€§
            response = await self._call_gpt4o_with_retry(
                model=self.MODEL_CONFIG["feedback"],  # gpt-4o-mini + ä¼˜åŒ–æç¤ºè¯
                messages=messages,
                temperature=0.5,  # â† ä¼˜åŒ–: é™ä½æ¸©åº¦ï¼Œä»ä¿æŒæ¸©æš–ä½†æ›´ä¸€è‡´
                max_tokens=max_tokens,
                response_format={"type": "json_object"}
            )

            content = response.choices[0].message.content
            if not content:
                raise ValueError("OpenAI è¿”å›ç©ºå“åº”")

            try:
                result = json.loads(content)
                reply = result.get("reply", "").strip()
                
                # âœ… æ·»åŠ è°ƒè¯•æ—¥å¿—
                print(f"ğŸ” [DEBUG] åå­—å‰ç¼€æ£€æŸ¥:")
                print(f"   user_name å‚æ•°: '{user_name}'")
                print(f"   AI åŸå§‹å›å¤: '{reply}'")
                print(f"   ä½¿ç”¨æƒ…ç»ª: {emotion_from_agent}")
                
                # åå­—å‰ç¼€æ£€æŸ¥
                if user_name and user_name.strip():
                    trimmed_reply = reply.lstrip()
                    if not trimmed_reply.lower().startswith(user_name.lower()):
                        has_cjk = bool(re.search(r'[\u4e00-\u9fff]', trimmed_reply))
                        separator = "ï¼Œ" if has_cjk else ", "
                        reply = f"{user_name}{separator}{trimmed_reply}"
                
                print(f"âœ… åé¦ˆç”Ÿæˆ: {reply[:30]}... (åŸºäºæƒ…ç»ª: {emotion_from_agent})")
                return reply  # ğŸ”¥ ç›´æ¥è¿”å›å­—ç¬¦ä¸²ï¼Œæƒ…ç»ªå·²ç»ç”± Emotion Agent æä¾›
                
            except json.JSONDecodeError:
                print("âš ï¸ JSON è§£æå¤±è´¥ï¼Œå›é€€åˆ°çº¯æ–‡æœ¬å¤„ç†")
                return content.strip()  # ğŸ”¥ ç›´æ¥è¿”å›çº¯æ–‡æœ¬
        
        except Exception as e:
            print(f"âŒ åé¦ˆç”Ÿæˆå¤±è´¥: {e}")
            fallback_reply = "æ„Ÿè°¢åˆ†äº«ä½ çš„è¿™ä¸€åˆ»ã€‚" if language == "Chinese" else "Thanks for sharing this moment."
            
            # âœ… å³ä½¿åœ¨å¤±è´¥çš„æƒ…å†µä¸‹ï¼Œä¹Ÿå°½é‡å¸¦ä¸Šç”¨æˆ·åå­—
            if user_name and user_name.strip():
                separator = "ï¼Œ" if language == "Chinese" else ", "
                fallback_reply = f"{user_name}{separator}{fallback_reply}"
                
            return fallback_reply  # ğŸ”¥ ç›´æ¥è¿”å›å­—ç¬¦ä¸²
    
    # ========================================================================
    # ğŸ”¥ æ–°å¢: ä¸“é—¨çš„æƒ…ç»ªåˆ†æAgent (Agent Orchestration æ¶æ„)
    # ========================================================================
    
    async def analyze_emotion_only(
        self,
        text: str,
        language: str,
        encoded_images: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """
        âœ… æ–°å¢: ä¸“é—¨çš„æƒ…ç»ªåˆ†æAgent
        
        èŒè´£: åªåšæƒ…ç»ªåˆ†æ,ä¸ç”Ÿæˆåé¦ˆ
        ä¼˜åŠ¿: 
        - Promptæ›´çŸ­ (300 tokens vs 1050 tokens)
        - æ›´ä¸“æ³¨,å‡†ç¡®åº¦æ›´é«˜
        - å¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„åˆ†æé€»è¾‘
        
        è¿”å›:
            {
                "emotion": "Fulfilled",
                "confidence": 0.92,
                "rationale": "ç”¨æˆ·å®Œæˆäº†é¡¹ç›®,è¡¨è¾¾äº†æˆå°±æ„Ÿå’Œæ»¡è¶³æ„Ÿ"
            }
        """
        try:
            print(f"ğŸ¯ Emotion Agent: å¼€å§‹æƒ…ç»ªåˆ†æï¼ˆä¸¤æ®µå¼ï¼‰...")

            # âœ… ç²¾ç®€ç‰ˆæç¤ºè¯ï¼ˆminiä¼˜å…ˆï¼‰
            fast_prompt = """You are an expert emotion analyst. Return the MOST specific emotion with a confidence score.

EMOTIONS (24):
Positive: Joyful, Grateful, Fulfilled, Proud, Surprised, Excited, Loved, Peaceful, Hopeful
Neutral: Thoughtful, Reflective, Intentional, Inspired, Curious, Nostalgic, Calm
Negative: Uncertain, Misunderstood, Lonely, Down, Anxious, Overwhelmed, Venting, Frustrated

Rules:
1) Choose most specific emotion
2) If unclear â†’ Thoughtful (0.4-0.6)
3) Short text â†’ conservative
4) Mixed emotions â†’ pick dominant (>60%)
5) Use keywords + context

Key pairs:
- Fulfilled=achievement, Joyful=pure happiness
- Loved=receiving love, Grateful=expressing thanks
- Anxious=future worry, Overwhelmed=too much now

Return JSON:
{"emotion":"Fulfilled","confidence":0.85,"rationale":"..."}"""

            # âœ… é«˜ç²¾åº¦æç¤ºè¯ï¼ˆ4oå…œåº•ï¼Œä¿æŒç­–ç•¥ä½†ç¼©çŸ­ï¼‰
            system_prompt = """You are an expert emotion analyst specializing in psychological assessment.
Your ONLY task: Analyze the user's emotion with MAXIMUM accuracy.

EMOTIONS (24):
Positive: Joyful, Grateful, Fulfilled, Proud, Surprised, Excited, Loved, Peaceful, Hopeful
Neutral: Thoughtful, Reflective, Intentional, Inspired, Curious, Nostalgic, Calm
Negative: Uncertain, Misunderstood, Lonely, Down, Anxious, Overwhelmed, Venting, Frustrated

Rules:
1) Choose most specific emotion
2) Fulfilledâ‰ Joyful, Anxiousâ‰ Overwhelmed, Lovedâ‰ Grateful
3) If unclear â†’ Thoughtful (0.4-0.6)
4) Mixed â†’ pick dominant (>60%)
5) Short text â†’ conservative

Key definitions:
Loved=receiving love/care; Grateful=expressing thanks
Fulfilled=completion/achievement; Joyful=pure happiness
Anxious=future worry; Overwhelmed=too much now

Return JSON:
{"emotion":"Fulfilled","confidence":0.92,"rationale":"..."}"""

            # æ„å»ºæ¶ˆæ¯ï¼ˆminiï¼‰
            fast_messages = [{"role": "system", "content": fast_prompt}]
            
            # æ„å»ºç”¨æˆ·æ¶ˆæ¯
            user_content = []
            
            # å¦‚æœæœ‰å›¾ç‰‡,æ·»åŠ å›¾ç‰‡
            if encoded_images and len(encoded_images) > 0:
                print(f"ğŸ–¼ï¸ æ·»åŠ  {len(encoded_images)} å¼ å›¾ç‰‡åˆ°æƒ…ç»ªåˆ†æ...")
                for image_data in encoded_images:
                    user_content.append({
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{image_data}",
                            "detail": "low"
                        }
                    })
                
                user_content.append({
                    "type": "text",
                    "text": f"è¯·åˆ†æä»¥ä¸‹å†…å®¹çš„æƒ…ç»ª(è€ƒè™‘å›¾ç‰‡å’Œæ–‡å­—):\\n\\n{text}"
                })
                user_prompt = user_content
            else:
                user_prompt = f"è¯·åˆ†æä»¥ä¸‹å†…å®¹çš„æƒ…ç»ª:\\n\\n{text}"

            fast_messages.append({"role": "user", "content": user_prompt})

            # 1) å…ˆç”¨ mini
            fast_response = await self._call_gpt4o_with_retry(
                model=self.MODEL_CONFIG["emotion_fast"],
                messages=fast_messages,
                temperature=0.3,
                max_tokens=400,
                response_format={"type": "json_object"}
            )
            fast_result = json.loads(fast_response.choices[0].message.content)
            fast_conf = float(fast_result.get("confidence") or 0.0)
            print(f"âœ… Emotion(micro) å®Œæˆ: {fast_result.get('emotion')} (ç½®ä¿¡åº¦: {fast_conf})")

            # 2) ä½ç½®ä¿¡åº¦å†ç”¨ 4o å¤æ ¸
            if fast_conf < 0.75:
                print(f"âš ï¸ æƒ…ç»ªç½®ä¿¡åº¦ä½ï¼Œå¯ç”¨ gpt-4o å¤æ ¸")
                messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}]
                response = await self._call_gpt4o_with_retry(
                    model=self.MODEL_CONFIG["emotion"],
                    messages=messages,
                    temperature=0.3,
                    max_tokens=500,
                    response_format={"type": "json_object"}
                )
                result = json.loads(response.choices[0].message.content)
                print(f"âœ… Emotion(4o) å®Œæˆ: {result.get('emotion')} (ç½®ä¿¡åº¦: {result.get('confidence')})")
                return result

            return fast_result
            
        except Exception as e:
            print(f"âŒ Emotion Agent å¤±è´¥: {str(e)}")
            # è¿”å›é»˜è®¤å€¼
            return {
                "emotion": "Thoughtful",
                "confidence": 0.5,
                "rationale": "åˆ†æå¤±è´¥,ä½¿ç”¨é»˜è®¤æƒ…ç»ª"
            }
    # ========================================================================
    # éªŒè¯å’Œé™çº§é€»è¾‘ï¼ˆä¿æŒä¸å˜ï¼‰
    # ========================================================================
    
    def _validate_and_fix_result(
        self, 
        result: Dict[str, str], 
        original_text: str,
        user_name: str = None  # âœ… ä¿®å¤: æ·»åŠ  user_name å‚æ•°ä»¥æ”¯æŒåé¦ˆé™çº§æ—¶æ·»åŠ ç”¨æˆ·å
    ) -> Dict[str, str]:
        """
        éªŒè¯å¹¶ä¿®æ­£AIè¾“å‡º - è´¨é‡æŠŠå…³
        
        Args:
            result: AIå¤„ç†ç»“æœå­—å…¸
            original_text: åŸå§‹æ–‡æœ¬
            user_name: ç”¨æˆ·åå­—ï¼Œç”¨äºåé¦ˆé™çº§æ—¶æ·»åŠ ç§°å‘¼
        """
        
        orig_len = len(original_text.strip())
        
        # æ£€æµ‹è¯­è¨€
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', original_text))
        is_chinese = chinese_chars > len(original_text) * 0.2
        
        print(f"ğŸ“Š åŸæ–‡è¯­è¨€æ£€æµ‹: æ€»é•¿åº¦={len(original_text)}, ä¸­æ–‡å­—ç¬¦={chinese_chars}, åˆ¤å®š={'ä¸­æ–‡' if is_chinese else 'è‹±æ–‡'}")
        
        # æå–å„éƒ¨åˆ†
        title = (result.get("title", "") or "").strip()
        polished = (result.get("polished_content", "") or "").strip()
        feedback = (result.get("feedback", "") or "").strip()
        emotion_data = result.get("emotion_data", {"emotion": "Reflective"}) # âœ… ä¿ç•™æƒ…ç»ªæ•°æ®
        
        # ğŸ”¥ ä¼˜åŒ–ï¼šè¯­è¨€ä¸€è‡´æ€§éªŒè¯ - æ›´å®½å®¹çš„æ£€æµ‹é€»è¾‘
        title_has_chinese = bool(re.search(r'[\u4e00-\u9fff]', title))
        title_has_english = bool(re.search(r'[a-zA-Z]', title))
        feedback_has_chinese = bool(re.search(r'[\u4e00-\u9fff]', feedback))
        feedback_has_english = bool(re.search(r'[a-zA-Z]', feedback))
        
        used_fallback = False
        
        # ğŸ”¥ æ›´å®½å®¹çš„æ ‡é¢˜è¯­è¨€æ£€æŸ¥ï¼ˆåªåœ¨å®Œå…¨é”™è¯¯æ—¶æ‰fallbackï¼‰
        title_language_mismatch = False
        if is_chinese:
            # ç”¨æˆ·è¾“å…¥æ˜¯ä¸­æ–‡ï¼Œä½†æ ‡é¢˜100%æ˜¯è‹±æ–‡ï¼ˆæ²¡æœ‰ä¸€ä¸ªä¸­æ–‡å­—ç¬¦ï¼‰
            if not title_has_chinese and title_has_english and len(title) > 3:
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ··åˆè¯­è¨€ï¼ˆä¾‹å¦‚ï¼š"Project å®Œæˆ"ï¼‰
                # å¦‚æœæ ‡é¢˜ä¸­æœ‰è‡³å°‘ä¸€ä¸ªä¸­æ–‡å­—ç¬¦ï¼Œå°±è®¤ä¸ºæ˜¯æ­£å¸¸çš„
                title_language_mismatch = True
                print(f"âš ï¸ æ ‡é¢˜è¯­è¨€ä¸ä¸€è‡´ï¼ç”¨æˆ·è¾“å…¥æ˜¯ä¸­æ–‡ï¼Œä½†æ ‡é¢˜æ˜¯çº¯è‹±æ–‡: '{title}'")
        else:
            # ç”¨æˆ·è¾“å…¥æ˜¯è‹±æ–‡ï¼Œä½†æ ‡é¢˜100%æ˜¯ä¸­æ–‡ï¼ˆæ²¡æœ‰ä¸€ä¸ªè‹±æ–‡å­—ç¬¦ï¼‰
            if not title_has_english and title_has_chinese and len(title) > 3:
                title_language_mismatch = True
                print(f"âš ï¸ æ ‡é¢˜è¯­è¨€ä¸ä¸€è‡´ï¼ç”¨æˆ·è¾“å…¥æ˜¯è‹±æ–‡ï¼Œä½†æ ‡é¢˜æ˜¯çº¯ä¸­æ–‡: '{title}'")
        
        if title_language_mismatch:
            # ä½¿ç”¨é™çº§æ–¹æ¡ˆï¼Œç¡®ä¿è¯­è¨€ä¸€è‡´
            title = "å¿ƒæƒ…éšè®°" if is_chinese else "A Moment Captured"
            used_fallback = True
            print(f"âœ… å·²ä¿®æ­£æ ‡é¢˜ä¸º: '{title}'")
        
        # ğŸ”¥ ä¼˜åŒ–ï¼šåé¦ˆè¯­è¨€æ£€æŸ¥ - æ›´å®½å®¹çš„é€»è¾‘
        # åªæœ‰åœ¨åé¦ˆä¸åŸæ–‡è¯­è¨€å®Œå…¨ç›¸åæ—¶æ‰fallback
        feedback_language_mismatch = False
        if is_chinese:
            # ç”¨æˆ·æ˜¯ä¸­æ–‡ï¼Œä½†åé¦ˆæ˜¯çº¯è‹±æ–‡ï¼ˆæ²¡æœ‰ä¸€ä¸ªä¸­æ–‡å­—ç¬¦ï¼Œä½†æœ‰è‹±æ–‡ï¼‰
            if not feedback_has_chinese and feedback_has_english and len(feedback) > 10:
                feedback_language_mismatch = True
                print(f"âš ï¸ åé¦ˆè¯­è¨€ä¸ä¸€è‡´ï¼ç”¨æˆ·è¾“å…¥æ˜¯ä¸­æ–‡ï¼Œä½†åé¦ˆæ˜¯çº¯è‹±æ–‡: '{feedback[:50]}'")
        else:
            # ç”¨æˆ·æ˜¯è‹±æ–‡ï¼Œä½†åé¦ˆæ˜¯çº¯ä¸­æ–‡ï¼ˆæ²¡æœ‰ä¸€ä¸ªè‹±æ–‡å­—ç¬¦ï¼Œä½†æœ‰ä¸­æ–‡ï¼‰
            if not feedback_has_english and feedback_has_chinese and len(feedback) > 10:
                feedback_language_mismatch = True
                print(f"âš ï¸ åé¦ˆè¯­è¨€ä¸ä¸€è‡´ï¼ç”¨æˆ·è¾“å…¥æ˜¯è‹±æ–‡ï¼Œä½†åé¦ˆæ˜¯çº¯ä¸­æ–‡: '{feedback[:50]}'")
        
        if feedback_language_mismatch:
            print(f"âš ï¸ ä½¿ç”¨è¯­è¨€ä¸ä¸€è‡´ fallback")
            feedback = "æ„Ÿè°¢åˆ†äº«ä½ çš„è¿™ä¸€åˆ»ã€‚" if is_chinese else "Thanks for sharing this moment."
            # âœ… å³ä½¿æ˜¯ fallbackï¼Œä¹Ÿè¦åŠ ä¸Šç”¨æˆ·åå­—
            if user_name and user_name.strip():
                separator = "ï¼Œ" if is_chinese else ", "
                feedback = f"{user_name}{separator}{feedback}"
            used_fallback = True
        
        # æ¸…ç†å‡½æ•°
        def clean_text(text: str) -> str:
            text = re.sub(r'[\U0001F300-\U0001FAFF\U00002700-\U000027BF]+', '', text)
            text = text.replace('ï¼', 'ã€‚').replace('!', '.')
            text = re.sub(r'\s+', ' ', text).strip()
            return text

        def clean_text_preserve_formatting(
            text: str,
            is_chinese: bool,
            should_adjust_paragraphs: bool,
        ) -> str:
            """
            ä¿ç•™ç”¨æˆ·æ’ç‰ˆï¼ˆæ¢è¡Œ/åˆ—è¡¨ï¼‰ï¼Œåªåšè½»åº¦æ¸…ç†ã€‚
            """
            text = re.sub(r'[\U0001F300-\U0001FAFF\U00002700-\U000027BF]+', '', text)
            text = text.replace('ï¼', 'ã€‚').replace('!', '.')
            text = text.replace('\r\n', '\n').replace('\r', '\n')
            lines = text.split('\n')
            cleaned_lines = []
            bullet_pattern = re.compile(r'^(\s*)([-*â€¢]|\d+[.)])\s*(.*)$')
            for line in lines:
                if not line.strip():
                    cleaned_lines.append("")
                    continue
                bullet_match = bullet_pattern.match(line)
                if bullet_match:
                    indent, marker, content = bullet_match.groups()
                    content = re.sub(r'\s+', ' ', content).strip()
                    cleaned_lines.append(f"{indent}{marker} {content}".rstrip())
                else:
                    leading_ws = re.match(r'^\s*', line).group(0)
                    content = line[len(leading_ws):]
                    content = re.sub(r'\s+', ' ', content).strip()
                    cleaned_lines.append(f"{leading_ws}{content}".rstrip())
            cleaned = "\n".join(cleaned_lines).strip()

            if not should_adjust_paragraphs:
                return cleaned

            # å¦‚æœåŒ…å«åˆ—è¡¨ï¼Œé¿å…è‡ªåŠ¨åˆå¹¶æ®µè½
            for line in cleaned.split("\n"):
                if bullet_pattern.match(line):
                    return cleaned

            paragraphs = re.split(r"\n\s*\n+", cleaned)
            if len(paragraphs) <= 1:
                return cleaned

            def sentence_count(paragraph: str) -> int:
                if is_chinese:
                    matches = re.findall(r"[ã€‚ï¼ï¼Ÿ!?ï¼›;]", paragraph)
                else:
                    matches = re.findall(r"[.!?;]", paragraph)
                return max(1, len(matches))

            def merge_text(a: str, b: str) -> str:
                if not a:
                    return b
                if is_chinese:
                    sep = ""
                else:
                    sep = "" if a.endswith((" ", "\n")) else " "
                return f"{a.rstrip()}{sep}{b.lstrip()}"

            # âœ… é¦–æ®µè‡³å°‘åŒ…å«3å¥ï¼Œé¿å…ç¬¬ä¸€å¥åæ–­æ®µ
            while len(paragraphs) > 1 and sentence_count(paragraphs[0]) < 3:
                paragraphs[0] = merge_text(paragraphs[0], paragraphs[1])
                paragraphs.pop(1)

            # âœ… åˆå¹¶è¿‡çŸ­æ®µè½ï¼ˆé¿å…ç©ºç™½æ„Ÿï¼‰
            min_chars = 60 if is_chinese else 90
            i = 1
            while i < len(paragraphs):
                if sentence_count(paragraphs[i]) < 2 or len(paragraphs[i]) < min_chars:
                    paragraphs[i - 1] = merge_text(paragraphs[i - 1], paragraphs[i])
                    paragraphs.pop(i)
                else:
                    i += 1

            return "\n\n".join(p.strip() for p in paragraphs)
        
        def trim_to_complete_sentences(text: str, max_len: int) -> str:
            if len(text) <= max_len:
                return text

            sentence_pattern = r"([ã€‚ï¼ï¼Ÿ.!?])(['\"\"ã€ã€)]?)\s*"
            last_end = None

            for match in re.finditer(sentence_pattern, text):
                end_pos = match.end()
                if end_pos <= max_len:
                    last_end = end_pos
                else:
                    break

            if last_end is not None:
                return text[:last_end].rstrip()

            for punct in ['ã€‚', '.', 'ï¼', '!', 'ï¼Ÿ', '?', 'ï¼›', ';']:
                idx = text.rfind(punct, 0, max_len + 1)
                if idx > max_len * 0.5:
                    return text[:idx + 1].rstrip()
            return text[:max_len].rstrip()
        
        # ä¿®æ­£æ ‡é¢˜
        title = clean_text(title)
        title = re.sub(r'[^\w\u4e00-\u9fff\s-]', '', title)
        title = re.sub(r'\s+', ' ', title).strip()
        
        if len(title) < self.LENGTH_LIMITS["title_min"]:
            title = "A Moment Captured" if any(ord(c) < 128 for c in original_text) else "å¿ƒæƒ…éšè®°"
        elif len(title) > self.LENGTH_LIMITS["title_max"]:
            max_len = self.LENGTH_LIMITS["title_max"]
            if ' ' in title and len(title) > max_len:
                words = title[:max_len].rsplit(' ', 1)
                title = words[0] if len(words[0]) > max_len * 0.6 else title[:max_len]
            else:
                title = title[:max_len]
        
        # ä¿®æ­£æ¶¦è‰²å†…å®¹
        original_has_linebreaks = "\n" in original_text
        original_has_list = bool(re.search(r"(?m)^\s*([-*â€¢]|\d+[.)])\s+", original_text))
        should_adjust_paragraphs = not original_has_linebreaks and not original_has_list
        polished = clean_text_preserve_formatting(
            polished,
            is_chinese,
            should_adjust_paragraphs,
        )
        max_polished_len = int(orig_len * self.LENGTH_LIMITS["polished_ratio"])
        
        # âœ… æ·»åŠ é•¿åº¦æ£€æŸ¥æ—¥å¿—
        print(f"ğŸ“Š æ¶¦è‰²å†…å®¹éªŒè¯: åŸå§‹é•¿åº¦={orig_len}, æ¶¦è‰²åé•¿åº¦={len(polished)}, æœ€å¤§å…è®¸é•¿åº¦={max_polished_len}")
        
        # âš ï¸ å¦‚æœæ¶¦è‰²åå†…å®¹æ˜æ˜¾å°‘äºåŸå§‹å†…å®¹ï¼ˆå°äº80%ï¼‰ï¼Œå¯èƒ½æ˜¯è¢«æˆªæ–­äº†ï¼Œä½¿ç”¨åŸå§‹å†…å®¹
        if len(polished) < orig_len * 0.8:
            print(f"âš ï¸ è­¦å‘Šï¼šæ¶¦è‰²åå†…å®¹æ˜æ˜¾å°‘äºåŸå§‹å†…å®¹ï¼ˆ{len(polished)} < {orig_len * 0.8}ï¼‰ï¼Œä½¿ç”¨åŸå§‹å†…å®¹")
            polished = original_text.strip()
        
        # åªæœ‰åœ¨è¶…è¿‡æœ€å¤§é•¿åº¦æ—¶æ‰æˆªæ–­ï¼ˆä½†è¿™ç§æƒ…å†µä¸åº”è¯¥å‘ç”Ÿï¼Œå› ä¸ºæç¤ºè¯è¦æ±‚â‰¤115%ï¼‰
        if len(polished) > max_polished_len:
            print(f"âš ï¸ æ¶¦è‰²åå†…å®¹è¶…è¿‡æœ€å¤§é•¿åº¦ï¼ˆ{len(polished)} > {max_polished_len}ï¼‰ï¼ŒæŒ‰å®Œæ•´å¥å­æˆªæ–­")
            polished = trim_to_complete_sentences(polished, max_polished_len)
        
        # ä¿®æ­£åé¦ˆ
        feedback = clean_text(feedback)
        
        # âœ… ä¿®å¤ #9 (2026-01-27): ç§»é™¤æœ€å°é•¿åº¦æ£€æŸ¥ï¼Œåªæ£€æŸ¥ç©ºå€¼
        # åŸå› ï¼šçŸ­åé¦ˆå¯èƒ½æ˜¯æœ€åˆé€‚çš„å›å¤ï¼Œä¸åº”è¢«é€šç”¨ fallback æ›¿æ¢
        if not feedback or not feedback.strip():
            print(f"âš ï¸ åé¦ˆä¸ºç©ºï¼Œä½¿ç”¨é™çº§")
            feedback = "æ„Ÿè°¢åˆ†äº«ä½ çš„è¿™ä¸€åˆ»ã€‚" if is_chinese else "Thanks for sharing this moment."
        
        # âœ… ç¡®ä¿åé¦ˆå§‹ç»ˆä»¥ç”¨æˆ·åå¼€å¤´ï¼ˆæ— è®ºæ˜¯ AI ç”Ÿæˆè¿˜æ˜¯ fallbackï¼‰
        if user_name and user_name.strip():
            # æ£€æŸ¥åé¦ˆæ˜¯å¦å·²ç»ä»¥ç”¨æˆ·åå¼€å¤´
            if not feedback.startswith(user_name):
                separator = "ï¼Œ" if is_chinese else ", "
                feedback = f"{user_name}{separator}{feedback}"
        
        if len(feedback) > self.LENGTH_LIMITS["feedback_max"]:
            print(f"ğŸ“ åé¦ˆè¿‡é•¿ï¼ŒæŒ‰å®Œæ•´å¥å­æˆªæ–­")
            feedback = trim_to_complete_sentences(feedback, self.LENGTH_LIMITS["feedback_max"])
        
        is_english = any(ord(c) < 128 for c in original_text[:50])
        default_feedback = "Thank you for sharing." if is_english else "æ„Ÿè°¢åˆ†äº«ã€‚"
        
        return {
            "title": title,
            "polished_content": polished or original_text,
            "feedback": feedback or default_feedback,
            "emotion_data": emotion_data # âœ… è¿”å›æƒ…ç»ªæ•°æ®
        }
    
    def _create_fallback_result(self, text: str, user_name: str = None) -> Dict[str, Any]:
        """
        åˆ›å»ºé™çº§ç»“æœ
        """
        
        print(f"âš ï¸ ä½¿ç”¨é™çº§æ–¹æ¡ˆ (user_name={user_name})")
        
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
        is_chinese = chinese_chars > len(text) * 0.2
        
        feedback = "æ„Ÿè°¢åˆ†äº«ã€‚" if is_chinese else "Thanks for sharing."
        if user_name and user_name.strip():
            separator = "ï¼Œ" if is_chinese else ", "
            feedback = f"{user_name}{separator}{feedback}"

        return {
            "title": "å¿ƒæƒ…éšè®°" if is_chinese else "A Moment Captured",
            "polished_content": text,
            "feedback": feedback,
            "emotion_data": {"emotion": "Reflective", "confidence": 0.5} # âœ… é»˜è®¤æƒ…ç»ª
        }
    
    # ========================================================================
    # å‘åå…¼å®¹æ–¹æ³•ï¼ˆä¿æŒä¸å˜ï¼‰
    # ========================================================================
    
    def polish_text(self, text: str) -> str:
        """æ¶¦è‰²æ–‡æœ¬ï¼ˆæ—§APIï¼‰"""
        result = self.polish_content_multilingual(text)
        return result["polished_content"]
    
    def generate_feedback(self, diary_content: str) -> str:
        """ç”Ÿæˆåé¦ˆï¼ˆæ—§APIï¼‰"""
        result = self.polish_content_multilingual(diary_content)
        return result["feedback"]


    # ========================================================================
    # ğŸ”¥ å›¾ç‰‡ä¸‹è½½å’Œç¼–ç ï¼ˆç”¨äºVision APIï¼‰
    # ========================================================================
    
    async def _download_and_encode_image(self, image_url: str) -> str:
        """
        ä¸‹è½½å›¾ç‰‡å¹¶è½¬æ¢ä¸ºbase64ç¼–ç ï¼ˆç”¨äºOpenAI Vision APIï¼‰
        
        Args:
            image_url: å›¾ç‰‡çš„URLï¼ˆS3 URLæˆ–HTTP URLï¼‰
        
        Returns:
            base64ç¼–ç çš„å›¾ç‰‡æ•°æ®
        """
        try:
            print(f"ğŸ“¥ ä¸‹è½½å›¾ç‰‡: {image_url[:50]}...")
            
            # âœ… Phase 1.1: ä½¿ç”¨ httpx.AsyncClient å¼‚æ­¥ä¸‹è½½ï¼ˆæå‡æ€§èƒ½ï¼‰
            async with httpx.AsyncClient(timeout=10.0) as client:
                response = await client.get(image_url)
                response.raise_for_status()
            
            # è½¬æ¢ä¸ºbase64
            image_base64 = base64.b64encode(response.content).decode('utf-8')
            
            print(f"âœ… å›¾ç‰‡ä¸‹è½½å¹¶ç¼–ç å®Œæˆï¼Œå¤§å°: {len(image_base64)} å­—ç¬¦")
            return image_base64
            
        except Exception as e:
            print(f"âŒ ä¸‹è½½å›¾ç‰‡å¤±è´¥: {e}")
            raise

# ğŸ¯ ä½¿ç”¨ç¤ºä¾‹
"""
# 1. åˆå§‹åŒ–æœåŠ¡
service = OpenAIService()

# 2. è¯­éŸ³è½¬æ–‡å­—ï¼ˆWhisperï¼‰
text = await service.transcribe_audio(audio_bytes, "recording.m4a")

# 3. å¹¶è¡Œå¤„ç†ï¼šæ¶¦è‰²ï¼ˆpolishï¼‰+ æƒ…ç»ªåˆ†æï¼ˆemotionï¼‰+ åé¦ˆï¼ˆfeedbackï¼‰
result = await service.polish_content_multilingual(text)

# 4. ä½¿ç”¨ç»“æœ
print(f"æ ‡é¢˜: {result['title']}")        # gpt-4o-mini (polish) ç”Ÿæˆ
print(f"å†…å®¹: {result['polished_content']}")  # gpt-4o-mini (polish) æ¶¦è‰²
print(f"åé¦ˆ: {result['feedback']}")      # gpt-4o (feedback) ç”Ÿæˆ

# 5. å›¾ç‰‡+æ–‡å­—å¤„ç†ï¼ˆæ–°åŠŸèƒ½ï¼‰
result = await service.polish_content_multilingual(
    text="ä»Šå¤©å»äº†å…¬å›­",
    image_urls=["https://s3.../image1.jpg", "https://s3.../image2.jpg"]
)
"""
