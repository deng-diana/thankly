/**
 * âœ… Phase 2: åˆ†å—å¹¶è¡Œä¸Šä¼ æœåŠ¡
 * 
 * Google Best Practice: å°†å¤§æ–‡ä»¶åˆ†æˆå¤šä¸ªå°å—å¹¶è¡Œä¸Šä¼ 
 * 
 * ä¼˜åŠ¿:
 * - å¹¶è¡Œä¸Šä¼ å¤šä¸ª chunksï¼Œå……åˆ†åˆ©ç”¨å¸¦å®½
 * - å•ä¸ª chunk å¤±è´¥å¯ä»¥å•ç‹¬é‡è¯•
 * - æ›´ç²¾ç¡®çš„è¿›åº¦æ˜¾ç¤º
 * - å¤§å¹…å‡å°‘æ€»ä¸Šä¼ æ—¶é—´
 * 
 * å·¥ä½œæµç¨‹:
 * 1. å½•éŸ³å®Œæˆåï¼Œç”Ÿæˆ session_id
 * 2. å°†éŸ³é¢‘æ–‡ä»¶åˆ†æˆå¤šä¸ª chunks
 * 3. ä¸ºæ¯ä¸ª chunk è·å–é¢„ç­¾å URL
 * 4. å¹¶è¡Œä¸Šä¼ æ‰€æœ‰ chunks
 * 5. è°ƒç”¨åç«¯åˆå¹¶å¹¶å¼€å§‹å¤„ç†
 */

import { API_BASE_URL } from "../config/aws-config";
import { getAccessToken } from "./authService";
import apiService from "./apiService";

// é…ç½®å¸¸é‡
const CHUNK_SIZE = 512 * 1024; // 512KB per chunk
const MAX_PARALLEL_UPLOADS = 3; // æœ€å¤šåŒæ—¶ä¸Šä¼  3 ä¸ª chunks
const CHUNK_UPLOAD_TIMEOUT = 30000; // 30 ç§’è¶…æ—¶
const MAX_RETRIES = 2; // æ¯ä¸ª chunk æœ€å¤šé‡è¯• 2 æ¬¡

// ç±»å‹å®šä¹‰
interface ChunkInfo {
  index: number;
  data: Blob;
  presignedUrl?: string;
  s3Key?: string;
  status: 'pending' | 'uploading' | 'completed' | 'failed';
  retryCount: number;
}

interface ChunkUploadProgress {
  totalChunks: number;
  completedChunks: number;
  percentage: number;
  currentSpeed?: number; // KB/s
}

interface ChunkUploadResult {
  taskId: string;
  audioUrl: string;
  totalChunks: number;
  uploadTimeMs: number;
}

/**
 * ç”Ÿæˆå”¯ä¸€çš„ session ID
 */
function generateSessionId(): string {
  return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, (c) => {
    const r = Math.random() * 16 | 0;
    const v = c === 'x' ? r : (r & 0x3 | 0x8);
    return v.toString(16);
  });
}

/**
 * å°†éŸ³é¢‘æ–‡ä»¶åˆ†å‰²æˆå¤šä¸ª chunks
 */
async function splitAudioIntoChunks(audioUri: string): Promise<Blob[]> {
  console.log("ğŸ“¦ å¼€å§‹åˆ†å‰²éŸ³é¢‘æ–‡ä»¶...");
  
  // è¯»å–éŸ³é¢‘æ–‡ä»¶
  const response = await fetch(audioUri);
  if (!response.ok) {
    throw new Error("æ— æ³•è¯»å–éŸ³é¢‘æ–‡ä»¶");
  }
  
  const blob = await response.blob();
  const totalSize = blob.size;
  const chunks: Blob[] = [];
  
  console.log(`  - æ–‡ä»¶å¤§å°: ${(totalSize / 1024 / 1024).toFixed(2)} MB`);
  
  // å¦‚æœæ–‡ä»¶å°äº CHUNK_SIZEï¼Œä¸éœ€è¦åˆ†å‰²
  if (totalSize <= CHUNK_SIZE) {
    console.log("  - æ–‡ä»¶è¾ƒå°ï¼Œæ— éœ€åˆ†å‰²");
    chunks.push(blob);
    return chunks;
  }
  
  // åˆ†å‰²æˆå¤šä¸ª chunks
  let offset = 0;
  while (offset < totalSize) {
    const end = Math.min(offset + CHUNK_SIZE, totalSize);
    const chunk = blob.slice(offset, end);
    chunks.push(chunk);
    offset = end;
  }
  
  console.log(`  - åˆ†å‰²æˆ ${chunks.length} ä¸ª chunks`);
  return chunks;
}

/**
 * åˆ›å»ºåˆ†å—ä¸Šä¼ ä¼šè¯
 */
async function createChunkSession(sessionId: string): Promise<void> {
  const accessToken = await getAccessToken();
  if (!accessToken) {
    throw new Error("æœªç™»å½•");
  }
  
  const formData = new FormData();
  formData.append("session_id", sessionId);
  
  const response = await fetch(`${API_BASE_URL}/diary/audio/chunk-session`, {
    method: "POST",
    headers: {
      Authorization: `Bearer ${accessToken}`,
    },
    body: formData,
  });
  
  if (!response.ok) {
    const errorText = await response.text().catch(() => "æœªçŸ¥é”™è¯¯");
    throw new Error(`åˆ›å»ºä¼šè¯å¤±è´¥: ${response.status} - ${errorText}`);
  }
  
  console.log("âœ… åˆ†å—ä¸Šä¼ ä¼šè¯åˆ›å»ºæˆåŠŸ");
}

/**
 * è·å–å•ä¸ª chunk çš„é¢„ç­¾å URL
 */
async function getChunkPresignedUrl(
  sessionId: string,
  chunkIndex: number
): Promise<{ presignedUrl: string; s3Key: string }> {
  const accessToken = await getAccessToken();
  if (!accessToken) {
    throw new Error("æœªç™»å½•");
  }
  
  const formData = new FormData();
  formData.append("session_id", sessionId);
  formData.append("chunk_index", chunkIndex.toString());
  formData.append("content_type", "audio/m4a");
  
  const response = await fetch(`${API_BASE_URL}/diary/audio/chunk-presigned-url`, {
    method: "POST",
    headers: {
      Authorization: `Bearer ${accessToken}`,
    },
    body: formData,
  });
  
  if (!response.ok) {
    throw new Error(`è·å–é¢„ç­¾åURLå¤±è´¥: ${response.status}`);
  }
  
  const data = await response.json();
  return {
    presignedUrl: data.presigned_url,
    s3Key: data.s3_key,
  };
}

/**
 * ä¸Šä¼ å•ä¸ª chunk åˆ° S3
 */
async function uploadChunk(
  chunk: Blob,
  presignedUrl: string,
  chunkIndex: number,
  onProgress?: (loaded: number, total: number) => void
): Promise<void> {
  return new Promise((resolve, reject) => {
    const xhr = new XMLHttpRequest();
    
    // è®¾ç½®è¶…æ—¶
    xhr.timeout = CHUNK_UPLOAD_TIMEOUT;
    
    // ç›‘å¬è¿›åº¦
    xhr.upload.onprogress = (event) => {
      if (event.lengthComputable && onProgress) {
        onProgress(event.loaded, event.total);
      }
    };
    
    // ç›‘å¬å®Œæˆ
    xhr.onload = () => {
      if (xhr.status === 200) {
        console.log(`âœ… Chunk ${chunkIndex} ä¸Šä¼ å®Œæˆ`);
        resolve();
      } else {
        reject(new Error(`Chunk ${chunkIndex} ä¸Šä¼ å¤±è´¥: HTTP ${xhr.status}`));
      }
    };
    
    // ç›‘å¬é”™è¯¯
    xhr.onerror = () => {
      reject(new Error(`Chunk ${chunkIndex} ç½‘ç»œé”™è¯¯`));
    };
    
    xhr.ontimeout = () => {
      reject(new Error(`Chunk ${chunkIndex} ä¸Šä¼ è¶…æ—¶`));
    };
    
    // å‘é€è¯·æ±‚
    xhr.open("PUT", presignedUrl);
    xhr.setRequestHeader("Content-Type", "audio/m4a");
    xhr.send(chunk);
  });
}

/**
 * å¹¶è¡Œä¸Šä¼ æ‰€æœ‰ chunks
 */
async function uploadChunksInParallel(
  sessionId: string,
  chunks: Blob[],
  onProgress?: (progress: ChunkUploadProgress) => void
): Promise<void> {
  console.log(`ğŸ“¤ å¼€å§‹å¹¶è¡Œä¸Šä¼  ${chunks.length} ä¸ª chunks...`);
  
  const chunkInfos: ChunkInfo[] = chunks.map((data, index) => ({
    index,
    data,
    status: 'pending' as const,
    retryCount: 0,
  }));
  
  let completedCount = 0;
  const totalChunks = chunks.length;
  
  // æ›´æ–°è¿›åº¦
  const updateProgress = () => {
    if (onProgress) {
      onProgress({
        totalChunks,
        completedChunks: completedCount,
        percentage: Math.round((completedCount / totalChunks) * 100),
      });
    }
  };
  
  // ä¸Šä¼ å•ä¸ª chunkï¼ˆå¸¦é‡è¯•ï¼‰
  const uploadWithRetry = async (chunkInfo: ChunkInfo): Promise<void> => {
    while (chunkInfo.retryCount <= MAX_RETRIES) {
      try {
        // è·å–é¢„ç­¾å URLï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
        if (!chunkInfo.presignedUrl) {
          const urlData = await getChunkPresignedUrl(sessionId, chunkInfo.index);
          chunkInfo.presignedUrl = urlData.presignedUrl;
          chunkInfo.s3Key = urlData.s3Key;
        }
        
        chunkInfo.status = 'uploading';
        
        // ä¸Šä¼ 
        await uploadChunk(
          chunkInfo.data,
          chunkInfo.presignedUrl,
          chunkInfo.index
        );
        
        chunkInfo.status = 'completed';
        completedCount++;
        updateProgress();
        return;
        
      } catch (error) {
        chunkInfo.retryCount++;
        console.warn(`âš ï¸ Chunk ${chunkInfo.index} ä¸Šä¼ å¤±è´¥ï¼Œé‡è¯• ${chunkInfo.retryCount}/${MAX_RETRIES}`);
        
        if (chunkInfo.retryCount > MAX_RETRIES) {
          chunkInfo.status = 'failed';
          throw error;
        }
        
        // é‡è¯•å‰ç­‰å¾…
        await new Promise(resolve => setTimeout(resolve, 1000 * chunkInfo.retryCount));
        // æ¸…é™¤é¢„ç­¾å URLï¼Œé‡æ–°è·å–
        chunkInfo.presignedUrl = undefined;
      }
    }
  };
  
  // ä½¿ç”¨å¹¶å‘æ± ä¸Šä¼ 
  const pool: Promise<void>[] = [];
  let currentIndex = 0;
  
  const startNext = async (): Promise<void> => {
    if (currentIndex >= chunkInfos.length) {
      return;
    }
    
    const chunkInfo = chunkInfos[currentIndex];
    currentIndex++;
    
    try {
      await uploadWithRetry(chunkInfo);
    } finally {
      // å®Œæˆåå¯åŠ¨ä¸‹ä¸€ä¸ª
      await startNext();
    }
  };
  
  // å¯åŠ¨åˆå§‹çš„å¹¶è¡Œä»»åŠ¡
  const initialCount = Math.min(MAX_PARALLEL_UPLOADS, chunkInfos.length);
  for (let i = 0; i < initialCount; i++) {
    pool.push(startNext());
  }
  
  // ç­‰å¾…æ‰€æœ‰å®Œæˆ
  await Promise.all(pool);
  
  // æ£€æŸ¥æ˜¯å¦æœ‰å¤±è´¥çš„
  const failedChunks = chunkInfos.filter(c => c.status === 'failed');
  if (failedChunks.length > 0) {
    throw new Error(`${failedChunks.length} ä¸ª chunks ä¸Šä¼ å¤±è´¥`);
  }
  
  console.log("âœ… æ‰€æœ‰ chunks ä¸Šä¼ å®Œæˆ");
}

/**
 * å®Œæˆåˆ†å—ä¸Šä¼ å¹¶åˆ›å»ºä»»åŠ¡
 */
async function completeChunkUpload(
  sessionId: string,
  chunkCount: number,
  duration: number,
  content?: string,
  imageUrls?: string[],
  expectImages?: boolean,
  userName?: string
): Promise<{ taskId: string; audioUrl: string }> {
  const accessToken = await getAccessToken();
  if (!accessToken) {
    throw new Error("æœªç™»å½•");
  }
  
  const headers: Record<string, string> = {
    Authorization: `Bearer ${accessToken}`,
  };
  
  if (userName) {
    headers["X-User-Name"] = userName;
  }
  
  const formData = new FormData();
  formData.append("session_id", sessionId);
  formData.append("chunk_count", chunkCount.toString());
  formData.append("duration", duration.toString());
  
  if (content && content.trim()) {
    formData.append("content", content.trim());
  }
  
  if (imageUrls && imageUrls.length > 0) {
    formData.append("image_urls", JSON.stringify(imageUrls));
    formData.append("expect_images", "false");
  } else if (expectImages) {
    formData.append("expect_images", "true");
  }
  
  const response = await fetch(`${API_BASE_URL}/diary/audio/chunk-complete`, {
    method: "POST",
    headers,
    body: formData,
  });
  
  if (!response.ok) {
    const errorText = await response.text().catch(() => "æœªçŸ¥é”™è¯¯");
    throw new Error(`å®Œæˆä¸Šä¼ å¤±è´¥: ${response.status} - ${errorText}`);
  }
  
  const data = await response.json();
  return {
    taskId: data.task_id,
    audioUrl: data.audio_url,
  };
}

/**
 * âœ… ä¸»å…¥å£ï¼šåˆ†å—ä¸Šä¼ éŸ³é¢‘å¹¶åˆ›å»ºä»»åŠ¡
 * 
 * è¿™æ˜¯ Phase 2 çš„æ ¸å¿ƒå‡½æ•°ï¼Œæ›¿ä»£åŸæœ‰çš„ uploadAudioAndCreateTask
 * 
 * @param audioUri - æœ¬åœ°éŸ³é¢‘æ–‡ä»¶ URI
 * @param duration - éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
 * @param onProgress - è¿›åº¦å›è°ƒï¼ˆ0-100ï¼‰
 * @param content - å¯é€‰çš„æ–‡å­—å†…å®¹
 * @param imageUrls - å¯é€‰çš„å›¾ç‰‡ URL åˆ—è¡¨
 * @param expectImages - æ˜¯å¦æœŸå¾…åç»­å›¾ç‰‡
 * @returns ä»»åŠ¡ä¿¡æ¯
 */
export async function uploadAudioWithChunks(
  audioUri: string,
  duration: number,
  onProgress?: (progress: number) => void,
  content?: string,
  imageUrls?: string[],
  expectImages?: boolean
): Promise<{ taskId: string; headers: Record<string, string> }> {
  console.log("ğŸš€ Phase 2: åˆ†å—å¹¶è¡Œä¸Šä¼ å¯åŠ¨");
  const startTime = Date.now();
  
  try {
    // Step 1: ç”Ÿæˆ session ID
    const sessionId = generateSessionId();
    console.log(`ğŸ“‹ Session ID: ${sessionId}`);
    
    // Step 2: åˆ›å»ºä¼šè¯
    await createChunkSession(sessionId);
    onProgress?.(5);
    
    // Step 3: åˆ†å‰²éŸ³é¢‘æ–‡ä»¶
    const chunks = await splitAudioIntoChunks(audioUri);
    onProgress?.(10);
    
    // Step 4: å¹¶è¡Œä¸Šä¼  chunks
    await uploadChunksInParallel(sessionId, chunks, (chunkProgress) => {
      // ä¸Šä¼ è¿›åº¦å  10% - 80%
      const uploadPercent = 10 + (chunkProgress.percentage * 0.7);
      onProgress?.(Math.round(uploadPercent));
    });
    onProgress?.(80);
    
    // Step 5: è·å–ç”¨æˆ·å
    const { getPreferredName } = await import("./authService");
    const preferredName = await getPreferredName();
    
    // Step 6: å®Œæˆä¸Šä¼ å¹¶åˆ›å»ºä»»åŠ¡
    const result = await completeChunkUpload(
      sessionId,
      chunks.length,
      duration,
      content,
      imageUrls,
      expectImages,
      preferredName || undefined
    );
    onProgress?.(100);
    
    const totalTime = Date.now() - startTime;
    console.log(`âœ… åˆ†å—ä¸Šä¼ å®Œæˆ: task_id=${result.taskId}, è€—æ—¶=${(totalTime / 1000).toFixed(1)}s`);
    
    // è¿”å›ä¸åŸ API å…¼å®¹çš„æ ¼å¼
    const accessToken = await getAccessToken();
    return {
      taskId: result.taskId,
      headers: {
        Authorization: `Bearer ${accessToken}`,
        ...(preferredName ? { "X-User-Name": preferredName } : {}),
      },
    };
    
  } catch (error: any) {
    console.error("âŒ åˆ†å—ä¸Šä¼ å¤±è´¥:", error);
    throw error;
  }
}

/**
 * æ£€æŸ¥æ˜¯å¦åº”è¯¥ä½¿ç”¨åˆ†å—ä¸Šä¼ 
 * 
 * ç­–ç•¥ï¼šæ–‡ä»¶å¤§äº 1MB æ—¶ä½¿ç”¨åˆ†å—ä¸Šä¼ 
 */
export async function shouldUseChunkUpload(audioUri: string): Promise<boolean> {
  try {
    const response = await fetch(audioUri);
    if (!response.ok) return false;
    
    const blob = await response.blob();
    const threshold = 1 * 1024 * 1024; // 1MB
    
    return blob.size > threshold;
  } catch {
    return false;
  }
}

export default {
  uploadAudioWithChunks,
  shouldUseChunkUpload,
};
